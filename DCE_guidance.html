<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.0.38">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Domenic Di Francesco, PhD, CEng">
<meta name="dcterms.date" content="2022-11-01">

<title>Data-Centric Engineering</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>


<script src="DCE_guidance_files/libs/clipboard/clipboard.min.js"></script>
<script src="DCE_guidance_files/libs/quarto-html/quarto.js"></script>
<script src="DCE_guidance_files/libs/quarto-html/popper.min.js"></script>
<script src="DCE_guidance_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="DCE_guidance_files/libs/quarto-html/anchor.min.js"></script>
<link href="DCE_guidance_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="DCE_guidance_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="DCE_guidance_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="DCE_guidance_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="DCE_guidance_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script src="DCE_guidance_files/libs/quarto-diagram/mermaid.min.js"></script>
<script src="DCE_guidance_files/libs/quarto-diagram/mermaid-init.js"></script>
<link href="DCE_guidance_files/libs/quarto-diagram/mermaid.css" rel="stylesheet">

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body>

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
  <nav id="TOC" role="doc-toc">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction"> <span class="header-section-number">1</span> Introduction</a>
  <ul class="collapse">
  <li><a href="#purpose-of-this-document" id="toc-purpose-of-this-document" class="nav-link" data-scroll-target="#purpose-of-this-document"> <span class="header-section-number">1.1</span> Purpose of this Document</a></li>
  <li><a href="#how-to-use-this-document" id="toc-how-to-use-this-document" class="nav-link" data-scroll-target="#how-to-use-this-document"> <span class="header-section-number">1.2</span> How to use this document</a></li>
  <li><a href="#some-other-published-guidance-for-engineers" id="toc-some-other-published-guidance-for-engineers" class="nav-link" data-scroll-target="#some-other-published-guidance-for-engineers"> <span class="header-section-number">1.3</span> Some other Published Guidance for Engineers</a></li>
  </ul></li>
  <li><a href="#uncertainty-in-the-built-environment" id="toc-uncertainty-in-the-built-environment" class="nav-link" data-scroll-target="#uncertainty-in-the-built-environment"> <span class="header-section-number">2</span> Uncertainty in the Built Environment</a></li>
  <li><a href="#quantifying-uncertainty" id="toc-quantifying-uncertainty" class="nav-link" data-scroll-target="#quantifying-uncertainty"> <span class="header-section-number">3</span> Quantifying Uncertainty</a>
  <ul class="collapse">
  <li><a href="#working-with-probability-distributions" id="toc-working-with-probability-distributions" class="nav-link" data-scroll-target="#working-with-probability-distributions"> <span class="header-section-number">3.1</span> Working with Probability Distributions</a></li>
  <li><a href="#multi-variate-distributions" id="toc-multi-variate-distributions" class="nav-link" data-scroll-target="#multi-variate-distributions"> <span class="header-section-number">3.2</span> Multi-Variate Distributions</a></li>
  <li><a href="#statistical-uncertainty" id="toc-statistical-uncertainty" class="nav-link" data-scroll-target="#statistical-uncertainty"> <span class="header-section-number">3.3</span> Statistical Uncertainty</a></li>
  <li><a href="#probabilistic-programming" id="toc-probabilistic-programming" class="nav-link" data-scroll-target="#probabilistic-programming"> <span class="header-section-number">3.4</span> Probabilistic Programming</a>
  <ul class="collapse">
  <li><a href="#introduction-1" id="toc-introduction-1" class="nav-link" data-scroll-target="#introduction-1"> <span class="header-section-number">3.4.1</span> Introduction</a></li>
  </ul></li>
  <li><a href="#sampling-outcomes" id="toc-sampling-outcomes" class="nav-link" data-scroll-target="#sampling-outcomes"> <span class="header-section-number">3.5</span> Sampling Outcomes</a></li>
  </ul></li>
  <li><a href="#supporting-decision-making" id="toc-supporting-decision-making" class="nav-link" data-scroll-target="#supporting-decision-making"> <span class="header-section-number">4</span> Supporting Decision Making</a>
  <ul class="collapse">
  <li><a href="#existing-challenges" id="toc-existing-challenges" class="nav-link" data-scroll-target="#existing-challenges"> <span class="header-section-number">4.1</span> Existing Challenges</a>
  <ul class="collapse">
  <li><a href="#decision-event-trees" id="toc-decision-event-trees" class="nav-link" data-scroll-target="#decision-event-trees"> <span class="header-section-number">4.1.1</span> Decision-Event Trees</a></li>
  <li><a href="#graphical-models-influence-diagrams" id="toc-graphical-models-influence-diagrams" class="nav-link" data-scroll-target="#graphical-models-influence-diagrams"> <span class="header-section-number">4.1.2</span> Graphical Models (Influence Diagrams)</a></li>
  </ul></li>
  <li><a href="#example-calculations" id="toc-example-calculations" class="nav-link" data-scroll-target="#example-calculations"> <span class="header-section-number">4.2</span> Example Calculations</a>
  <ul class="collapse">
  <li><a href="#expected-value-of-perfect-information" id="toc-expected-value-of-perfect-information" class="nav-link" data-scroll-target="#expected-value-of-perfect-information"> <span class="header-section-number">4.2.1</span> Expected Value of Perfect Information</a></li>
  <li><a href="#sensitivity-analysis-influence-of-prior-knowledge" id="toc-sensitivity-analysis-influence-of-prior-knowledge" class="nav-link" data-scroll-target="#sensitivity-analysis-influence-of-prior-knowledge"> <span class="header-section-number">4.2.2</span> Sensitivity Analysis: Influence of Prior Knowledge</a></li>
  <li><a href="#influence-diagram-representation" id="toc-influence-diagram-representation" class="nav-link" data-scroll-target="#influence-diagram-representation"> <span class="header-section-number">4.2.3</span> Influence Diagram Representation</a></li>
  <li><a href="#expected-value-of-imprecise-imperfect-information" id="toc-expected-value-of-imprecise-imperfect-information" class="nav-link" data-scroll-target="#expected-value-of-imprecise-imperfect-information"> <span class="header-section-number">4.2.4</span> Expected Value of Imprecise (Imperfect) Information:</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary"> <span class="header-section-number">5</span> Summary</a></li>
  <li><a href="#acknowledgements" id="toc-acknowledgements" class="nav-link" data-scroll-target="#acknowledgements"> <span class="header-section-number">6</span> Acknowledgements</a></li>
  </ul>
</nav>
</div>
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">Data-Centric Engineering</h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li><li><hr class="dropdown-divider"></li><li><a id="quarto-view-source" class="dropdown-item" href="javascript:void(0)" role="button">View Source</a></li></ul></div></div>
<p class="subtitle lead">Guidance on the Use of Probabilistic Methods for Identifying Data Requirements</p>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Domenic Di Francesco, PhD, CEng </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">November 1, 2022</p>
    </div>
  </div>
    
  </div>
  

</header>

<section id="introduction" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> Introduction</h1>
<section id="purpose-of-this-document" class="level2" data-number="1.1">
<h2 data-number="1.1" class="anchored" data-anchor-id="purpose-of-this-document"><span class="header-section-number">1.1</span> Purpose of this Document</h2>
<p>The various new methods of collecting and analysing data that are increasingly available to engineers can contribute to improvements in the safety and efficiency of the built environment. However, understanding the quantity and quality of data required will continue to be a challenge to engineers. For instance:</p>
<ul>
<li>Should sensing systems be retrofit to existing structures?</li>
<li>If so, how precise and how reliable do they need to be?</li>
<li>How can we value data from smart meters?</li>
<li>To what extent does measuring building occupancy help mitigate the risk of infection from airborne disease?</li>
</ul>
<p>The principles of data-centric engineering are not new. Engineers have always had to rely on empirical models that are supported by tests to demonstrate that systems are reliable and safe. However, given the recent advancements in the availability of free, open-source software tools for data analysis and statistical inference, there is an opportunity to improve engineering workflows. The guidance presented here is intended to be pragmatic and introductory. Example problems are presented alongside accompanying code implementations. There is a focus on answering meaningful questions, supporting decision making, and ensuring reproducible and reliable results.</p>
<p><q> Uncertainty accompanies our lives. Coherent modelling of uncertainties for decision-making is essential in engineering and related disciplines.</q></p>
<p><span class="citation" data-cites="Jordaan2005">(<a href="#ref-Jordaan2005" role="doc-biblioref">Jordaan 2005</a>)</span></p>
</section>
<section id="how-to-use-this-document" class="level2" data-number="1.2">
<h2 data-number="1.2" class="anchored" data-anchor-id="how-to-use-this-document"><span class="header-section-number">1.2</span> How to use this document</h2>
<p>This is a computational document that includes chunks of <code>Python</code>, <code>R</code>, and <code>Julia</code> code necessary to analyse the data, and solve the decision problems in the various examples. To achieve this, various libraries/packages have been used, and these will need to be installed and loaded for the code to run.</p>
<div id="chunk_load_packages" class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-1-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-1" role="tab" aria-controls="tabset-1-1" aria-selected="true" href="">Load Python Packages</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-1-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-2" role="tab" aria-controls="tabset-1-2" aria-selected="false" href="">Load R Packages</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-1-3-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-3" role="tab" aria-controls="tabset-1-3" aria-selected="false" href="">Load Julia Packages</a></li></ul>
<div id="chunk_load_packages" class="tab-content">
<div id="tabset-1-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-1-1-tab">
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> cmdstanpy, requests, os, multiprocessing, math</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np, pandas <span class="im">as</span> pd</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy <span class="im">import</span> stats</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</div>
<div id="tabset-1-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-1-2-tab">
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse); <span class="fu">library</span>(fitdistrplus); <span class="fu">library</span>(boot)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(cmdstanr); <span class="fu">library</span>(copula); <span class="fu">library</span>(ggthemes)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(lhs); <span class="fu">library</span>(parallel); <span class="fu">library</span>(TruncatedNormal)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</div>
<div id="tabset-1-3" class="tab-pane" role="tabpanel" aria-labelledby="tabset-1-3-tab">
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">using</span> <span class="bu">CSV</span>, <span class="bu">DataFrames</span>, <span class="bu">DataFramesMeta</span>, <span class="bu">Printf</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="im">using</span> <span class="bu">Random</span>, <span class="bu">Distributions</span>, <span class="bu">Bootstrap</span>, <span class="bu">Copulas</span>, <span class="bu">LatinHypercubeSampling</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="im">using</span> <span class="bu">JuMP</span>, <span class="bu">HiGHS</span>, <span class="bu">DecisionProgramming</span>, <span class="bu">Turing</span>, <span class="bu">LinearAlgebra</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</div>
</div>
</div>
<div class="callout-tip callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Tip: Loading packages
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>In <code>R</code>, <code>Python</code> and <code>Julia</code> packages first need to be installed. Guidance on installing packages can be found <a href="https://support.rstudio.com/hc/en-us/articles/201057987-Quick-list-of-useful-R-packages">here</a> (for <code>R</code>), <a href="https://pypi.org/project/pip/">here</a> (for <code>Python</code>), and <a href="https://docs.julialang.org/en/v1/stdlib/Pkg/">here</a> for <code>Julia</code>.</p>
<p>Packages only need to be installed once (unless they are uninstalled), but then need to be loaded each time you want to make direct use of the functions or data they contain. This document will not detail the workings of each package, but such information can be found online, for example <a href="https://pandas.pydata.org">here</a> is the website for the <code>Python</code> ‘pandas’ package.</p>
</div>
</div>
</div>
<p>In addition, some statistical models that have been written in the probabilistic programming language <code>Stan</code> have been used. The data used in the examples, as well as the code used for each exercise can be freely downloaded from this <a href="https://github.com/DomDF/DCE_guidance">public Github repository</a>.</p>
<p>Such calculations could also be performed using spreadsheet software. The primary reasons for not providing accompanying spreadsheet files to run the example calculations, are as follows:</p>
<ul>
<li>When running challenging simulations, or working with large amounts of data, spreadsheets may become unmanageably slow.</li>
<li>Spreadsheet software has reproducibility challenges. Data can be difficult to distinguish from calculated quantities, and the sequence of calculations can also be difficult to identify.</li>
<li>Calculations using spreadsheets are often unreliable. Errors <em>arise</em> in spreadsheets for many reasons, such as obscuring (or deleting) data, incorrect assumptions regarding data types, uninterpretable functions, and automatic filling. Errors often <em>remain</em> in spreadsheets due to the challenges associated with testing, documenting and version control.</li>
</ul>
<p>Some notable examples of high consequence spreadsheet errors are recorded by the European Spreadsheet Risks Interest Group <a href="http://www.eusprig.org">(EuSpRiG)</a> and further discussion on the incompatibility of spreadsheets and good data management (in the context of research) can be found in a presentation from Monash University, <a href="https://www.youtube.com/watch?v=-NuTlczV72Q&amp;t=35s">here</a>.</p>
</section>
<section id="some-other-published-guidance-for-engineers" class="level2" data-number="1.3">
<h2 data-number="1.3" class="anchored" data-anchor-id="some-other-published-guidance-for-engineers"><span class="header-section-number">1.3</span> Some other Published Guidance for Engineers</h2>
<ul>
<li>The UK Health &amp; Safety Executive produced a guidance document on the use of probabilistic methods in engineering <span class="citation" data-cites="HSE2002">(<a href="#ref-HSE2002" role="doc-biblioref"><strong>HSE2002?</strong></a>)</span>. This is perhaps the most similar to this document regarding the aim and intended use. It provides an overview of limitations of probabilistic methods, however many of the criticisms can be resolved (at least to some extent) using some of the computational approaches in this document.</li>
<li>BS 7910 is a widely used industrial standard for assessing damage in welded steel structures <span class="citation" data-cites="BSI2015">(<a href="#ref-BSI2015" role="doc-biblioref"><strong>BSI2015?</strong></a>)</span>. The evolution of this standard over recent decades is an interesting example of how more complex approaches have been gradually introduced to industry, in line with the increasing demands from structures, and increasing availability of computational resources to engineers. A recent addition has been Annex K, which considers probabilistic methods. However, evaluating the reliability of a damaged structure and completing a pass/fail type (deterministic) assessment using conservative inputs are two fundamentally different approaches. There is not currently sufficient guidance in this standard to model uncertainty in a helpful or meaningful way. Similarly, a guidance document for the nuclear industry <span class="citation" data-cites="NuclearWorkingGroup">(<a href="#ref-NuclearWorkingGroup" role="doc-biblioref"><strong>NuclearWorkingGroup?</strong></a>)</span> has similar limitations.</li>
<li>The most comprehensive guidance on modelling uncertainty in the built environment can be found in the probabilistic model code, developed by the joint committee of structural safety <span class="citation" data-cites="JCSS">(<a href="#ref-JCSS" role="doc-biblioref"><strong>JCSS?</strong></a>)</span>. This series of documents considers uncertainties in applied loads, material properties, measurements, and model predictions. Much of this guidance was incorporated in the COST Action TU1402 project case studies on quantifying the expected value of structural health monitoring systems <span class="citation" data-cites="COSTActionTU1402">(<a href="#ref-COSTActionTU1402" role="doc-biblioref"><strong>COSTActionTU1402?</strong></a>)</span>. This document is intended to provide some more interactive examples than those included by the JCSS, by including example code. It also addresses some of the challenges identified by the JCSS, specifically regarding characterisation of dependencies in multi-variate probabilistic models, and interpretation of results of structural reliability analysis.</li>
<li>As well as documents that are intended to be used in industry, there are also several engineering textbooks that introduce concepts in uncertainty quantification, and decision support in the context of engineering challenges <span class="citation" data-cites="Benjamin2014">(<a href="#ref-Faber2012" role="doc-biblioref"><strong>Faber2012?</strong></a>)</span>. These books all consider, to some extent, quantification of the expected value of data to engineers.</li>
</ul>
</section>
</section>
<section id="uncertainty-in-the-built-environment" class="level1" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> Uncertainty in the Built Environment</h1>
<p>Engineering standards acknowledge the presence of variability in the quantities they are dealing with, but do not always provide guidance on how to apply models of variability, particularly in supporting decision making. For example, repeated strength tests of specimens from the same material, using the same machine, in the same lab will produce differing, (though hopefully similar) results. Any decision on whether a material is safe to use must therefore account for this variability somehow.</p>
<p>Historically, structural engineers have used deterministic approaches to perform conservative assessments. In this example a <em>safe</em> or <em>characteristic</em> value of strength may be taken, such as the minimum from a set of measurements. The premise of this approach is that, if the lowest measurement meets a requirement, then it is expected to be OK. These kind of heuristics do not tell us how many tests are needed to be confident that the lowest measurement is representative, since each new measurement provides an opportunity to find a new lowest strength. As a result, unquantified and implicit margins of conservatism are introduced, making it very difficult to find the best estimates of risk that are required to justify spending consistently and coherently.</p>
<p>This can be resolved by using probability to formally quantify uncertainty, and various examples of this are presented in this document. Statistical models of variability can describe how many uncertain quantities can be dependent, how uncertainty can increase when making predictions over various time frames, and how uncertainty can decrease when new data becomes available. Uncertainty quantification therefore allows for many other types of analysis, such as identifying where, when and how additional data should be collected, which is the focus of this document.</p>
<p>While data will generally always provide some value, provided that it is relevant, it will not always represent a good investment. There are various costs associated with collecting engineering data, including hiring/purchasing specialised measurement equipment, the storage costs of high-volume streaming data, and occasionally the risk associated with exposing personnel to hazardous environments to collect data. Justifying these costs require engineers to link data collection to the improved decision making that it facilitates.</p>
<p>Without formal methods of uncertainty quantification, engineers may differ in opinion about data collection strategy. Quantitative approaches will be preferable because they are auditable. As demonstrated in the examples in this document, these approaches do not remove engineering input from this process, but rather include expert knowledge in a formal way. Unless both available data, and subject matter expertise are used to inform decisions, then some information is not being taken advantage of.</p>
</section>
<section id="quantifying-uncertainty" class="level1" data-number="3">
<h1 data-number="3"><span class="header-section-number">3</span> Quantifying Uncertainty</h1>
<p>As described in the below note, there are many appealing reasons to use probability to describe variability.</p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Thought: Using Probabilities
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>It has been proposed that since probability is the mathematical language of randomness, it should be used to model the uncertainties that arise <span class="citation" data-cites="Gelman2014">(<a href="#ref-Gelman2014" role="doc-biblioref">Gelman et al. 2014</a>)</span>. Another compelling argument is that the practical meaning of probability is intuitive. Probabilities can be assigned to possible (uncertain) outcomes in decision problems.</p>
<p>Understanding how to estimate these probabilities as well as how to use them allows for coherent and replicable (auditable) decision making. The statistics presented in this document are with the intention of providing this kind of pragmatic guidance.</p>
</div>
</div>
</div>
<p>There are many established probability distributions, and some reasonable question regarding their application in engineering calculations, include:</p>
<ul>
<li>Where do distributions come from?</li>
<li>When are they useful, or unhelpful in describing variability in engineering quantities?</li>
</ul>
<p>One common method of visualising of the Normal distribution is using a <a href="https://en.wikipedia.org/wiki/Galton_board">Galton board</a>. A number of beads hit a series of pegs as they fall to the base of the board. When they arrive at the base, they can be seen to approximate a Normal distribution. This can also be replicated using computer simulations, but in any case, it suggests that distribution functions are not arbitrary.</p>
<p>A similar example is presented in <span class="citation" data-cites="McElreath2019">(<a href="#ref-McElreath2019" role="doc-biblioref">McElreath 2020</a>)</span>, where the author counts the number of possible arrangements of items that are hidden under buckets. Because there are more ways to hide these items evenly under the buckets, this is considered the most likely outcome (without any additional information). Running simulations (or other experiments) using this example will produce a Uniform distribution.</p>
<p>Both the Galton board and hidden items example show how a distribution can represent the most likely outcome of some event(s). They are said to be <em>Max</em>imum <em>Ent</em>ropy (MaxEnt) solutions for those problems. Using this principle is often recommended for deciding on a statistical model with very limited information about the problem <span class="citation" data-cites="Jaynes2003">(<a href="#ref-Jaynes2003" role="doc-biblioref">Jaynes 2003</a>)</span>. Some mathematical proofs of various MaxEnt models are presented in <span class="citation" data-cites="Jordaan2005">(<a href="#ref-Jordaan2005" role="doc-biblioref">Jordaan 2005</a>)</span>.</p>
<p>More generally though, engineers may need to impose some additional features and constrains in their models (to represent their knowledge of the system being analysed). Probability distributions can then be considered as helpful tools to represent uncertainty. Prior predictive checks (see Section X) can be used to ensure that the selected distribution are resulting in appropriate results on an intuitive outcome scale.</p>
<section id="working-with-probability-distributions" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="working-with-probability-distributions"><span class="header-section-number">3.1</span> Working with Probability Distributions</h2>
<p>Modern programming languages have many functions for evaluating, integrating, sampling, and estimating parameters from probability distributions. The below examples show how <span class="math inline">\(10\)</span> independent samples can be drawn from a normal distribution, with a mean value of <span class="math inline">\(0\)</span> and a standard deviation of <span class="math inline">\(1\)</span>.</p>
<div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-2-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-1" role="tab" aria-controls="tabset-2-1" aria-selected="true" href="">Python (using SciPy)</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-2-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-2" role="tab" aria-controls="tabset-2-2" aria-selected="false" href="">R</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-2-3-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-3" role="tab" aria-controls="tabset-2-3" aria-selected="false" href="">Julia (using Distributions, Random)</a></li></ul>
<div class="tab-content">
<div id="tabset-2-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-2-1-tab">
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>stats.norm.rvs(size <span class="op">=</span> <span class="dv">10</span>, loc <span class="op">=</span> <span class="dv">0</span>, scale <span class="op">=</span> <span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>array([ 0.92326814,  1.0350539 ,  0.72822124,  1.07597249, -0.40602578,
        1.21285018,  0.73978325, -0.22831955, -1.04289276,  0.70313327])</code></pre>
</div>
</div>
</div>
<div id="tabset-2-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-2-2-tab">
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="fu">rnorm</span>(<span class="at">n =</span> <span class="dv">10</span>, <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code> [1]  0.08550655  0.60216297 -0.20969907  3.09873955  2.01296682 -1.04539500
 [7] -0.89053424 -0.66653247  0.35001124 -0.56725525</code></pre>
</div>
</div>
</div>
<div id="tabset-2-3" class="tab-pane" role="tabpanel" aria-labelledby="tabset-2-3-tab">
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="fu">Normal</span>(<span class="fl">0</span>, <span class="fl">1</span>) <span class="op">|&gt;</span> x <span class="op">-&gt;</span> <span class="fu">rand</span>(x, <span class="fl">10</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>10-element Vector{Float64}:
 -0.3560509440288681
  0.40228723234550806
  1.250173694709602
 -1.9249661716080106
  0.22724030538210024
 -0.43157394172547486
  0.17954092081473094
 -0.25023253088333125
  0.7843191528444862
 -1.620585340878406</code></pre>
</div>
</div>
</div>
</div>
</div>
<p>Many more samples are typically required for them to be considered a sufficient characterisation of the distribution. Various <em>variance reduction</em> methods have been developed, so that sampling problems can be solved using fewer samples, therefore requiring less computational effort. These include <em>importance sampling</em>, and <em>latin hypercube sampling</em>, and examples of the latter are presented below.</p>
<div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-3-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-3-1" role="tab" aria-controls="tabset-3-1" aria-selected="true" href="">Python (using SciPy)</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-3-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-3-2" role="tab" aria-controls="tabset-3-2" aria-selected="false" href="">R (using lhs)</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-3-3-tab" data-bs-toggle="tab" data-bs-target="#tabset-3-3" role="tab" aria-controls="tabset-3-3" aria-selected="false" href="">Julia (using LatinHypercubeSampling)</a></li></ul>
<div class="tab-content">
<div id="tabset-3-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-3-1-tab">
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> lhs(n_samples, dim <span class="op">=</span> <span class="dv">1</span>):</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>  probs <span class="op">=</span> stats.qmc.LatinHypercube(dim).random(n_samples)</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> probs</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>stats.norm.ppf(lhs(<span class="dv">10</span>), loc <span class="op">=</span> <span class="dv">0</span>, scale <span class="op">=</span> <span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>array([[-1.08218068],
       [-0.32658313],
       [-0.11237304],
       [ 0.19490564],
       [-0.73193094],
       [ 1.46998926],
       [ 0.66308655],
       [ 0.39172906],
       [-2.18376289],
       [ 1.04516428]])</code></pre>
</div>
</div>
</div>
<div id="tabset-3-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-3-2-tab">
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>lhs <span class="ot">&lt;-</span> <span class="cf">function</span>(n_samples, dim){</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">randomLHS</span>(<span class="at">n =</span> n_samples, <span class="at">k =</span> dim) </span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>(<span class="fu">lhs</span>(<span class="dv">10</span>, <span class="dv">1</span>) <span class="sc">|&gt;</span> <span class="fu">qnorm</span>(<span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="dv">1</span>))[,<span class="dv">1</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code> [1] -0.7559042  0.2730949 -0.3390298  0.1013449 -1.2123176  0.6225567
 [7] -1.4653633  1.1133565 -0.1929787  1.9974250</code></pre>
</div>
</div>
</div>
<div id="tabset-3-3" class="tab-pane" role="tabpanel" aria-labelledby="tabset-3-3-tab">
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="kw">function</span> <span class="fu">draw_lhs</span>(dist, n<span class="op">::</span><span class="dt">Int</span>)</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>    samples <span class="op">=</span> <span class="fu">randomLHC</span>(n <span class="op">+</span> <span class="fl">2</span>, <span class="fl">1</span>) <span class="op">|&gt;</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>        x <span class="op">-&gt;</span> <span class="fu">scaleLHC</span>(x, [(<span class="fl">0</span>, <span class="fl">1</span>)]) <span class="op">|&gt;</span></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>        x <span class="op">-&gt;</span> <span class="fu">quantile</span>(dist, x)[<span class="op">:</span>,<span class="fl">1</span>] <span class="op">|&gt;</span></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>        x <span class="op">-&gt;</span> <span class="fu">filter</span>(!<span class="fu">∈</span>((<span class="op">-</span><span class="cn">Inf</span>, <span class="cn">Inf</span>)), x)</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> samples</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a><span class="kw">end</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>draw_lhs (generic function with 1 method)</code></pre>
</div>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="fu">draw_lhs</span>(<span class="fu">Normal</span>(<span class="fl">0</span>, <span class="fl">1</span>), <span class="fl">10</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>10-element Vector{Float64}:
 -0.3487556955170447
  0.3487556955170447
  0.9084578685373853
  0.11418529432142821
 -0.11418529432142835
  0.6045853465832374
 -1.3351777361189363
  1.3351777361189363
 -0.6045853465832374
 -0.9084578685373852</code></pre>
</div>
</div>
</div>
</div>
</div>
<p>Latin hypercube sampling ensures more evenly spaced samples than standard (inverse-transform, Monte Carlo sampling) <span class="citation" data-cites="Olsson2003">(<a href="#ref-Olsson2003" role="doc-biblioref"><strong>Olsson2003?</strong></a>)</span>. The effect of this is shown in in <a href="#fig-it_lhs">Figure&nbsp;1</a>.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-it_lhs" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="DCE_guidance_files/figure-html/fig-it_lhs-1.png" class="img-fluid figure-img" width="672"></p>
<p></p><figcaption class="figure-caption">Figure 1: Effect of sample size on methods of approximating a standard normal distribution</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>Sampling from distributions converts mathematically challenging statistical problems to simpler data analysis problems. Consider the basic problem of structural reliability, where an engineer is tasked with identifying the probability of an uncertain load, <span class="math inline">\(L\)</span>, exceeding a components uncertain resistance, <span class="math inline">\(R\)</span>, to that load. This would represent the probability of the component failing, due to this load - a very important quantity for supporting inspection and maintenance decisions!</p>
<p><span class="math display">\[
\Pr(fail) = \Pr(L \geq R)
\]</span></p>
<p>The probability of failure defined by the convolution integral, which only has analytical solutions for some simple examples:</p>
<p><span class="math display">\[
\Pr(L \geq R) = \int_{L \geq R} \int f(r, s) \; dr \; ds
\]</span></p>
<p>Alternatively, the solution can be approximated by counting the number of samples from the load model that exceed samples from the resistance model. Each set of samples can be considered as a possible outcome (realisation) from the models, so the proportion of samples where the load exceeds the resistance therefore represents the probability of failure.</p>
<p>Using <code>Python</code>, <code>R</code> or <code>Julia</code>, it is now possible run millions of such simulations relatively quickly (though this will depend on the complexity of the load and resistance models), and this allows engineers to find solutions that could be difficult to obtain mathematically.</p>
<p>As a simple example, consider the series (or ‘weakest link’) arrangement of components in <a href="#fig-series_system">Figure&nbsp;2</a>.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-series_system" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p>
</p><pre class="mermaid" data-tooltip-selector="#mermaid-tooltip-1">graph LR
        START[ ] --- A[Component 1]
        A --- B[Component 2]
        B --- C[Component 3]
        C --- STOP[ ]

        style START fill:#FFFFFF, stroke:#FFFFFF;
        style STOP  fill:#FFFFFF, stroke:#FFFFFF;
          
</pre>
<div id="mermaid-tooltip-1" class="mermaidTooltip">

</div>
<p></p>
<p></p><figcaption class="figure-caption">Figure 2: Diagram of Structural Components in Series Connection</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>Such systems will fail when any of the components fail. If the below distributions describe the uncertainty in the applied loads and resistances, then it is possible the estimate the probability of failure by sampling from these distributions and evaluating the proportion of simulations associated with failure.</p>
<p><span class="math display">\[
R_{1} \sim Normal(\mu = 17, \sigma = 2)
\]</span></p>
<p><span class="math display">\[
R_{2} \sim Normal(\mu = 16, \sigma = 3/2)
\]</span></p>
<p><span class="math display">\[
R_{3} \sim LogNormal(log\mu = 2.7, log\sigma = 0.07)
\]</span></p>
<div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-4-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-4-1" role="tab" aria-controls="tabset-4-1" aria-selected="true" href="">Python (using SciPy)</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-4-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-4-2" role="tab" aria-controls="tabset-4-2" aria-selected="false" href="">R</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-4-3-tab" data-bs-toggle="tab" data-bs-target="#tabset-4-3" role="tab" aria-controls="tabset-4-3" aria-selected="false" href="">Julia (using Distributions, Random)</a></li></ul>
<div class="tab-content">
<div id="tabset-4-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-4-1-tab">
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="co"># TBC</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</div>
<div id="tabset-4-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-4-2-tab">
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="at">seed =</span> <span class="dv">240819</span>); n_samples <span class="ot">&lt;-</span> <span class="dv">10</span><span class="sc">^</span><span class="dv">6</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="co"># TBC</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</div>
<div id="tabset-4-3" class="tab-pane" role="tabpanel" aria-labelledby="tabset-4-3-tab">
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>L <span class="op">=</span> <span class="fu">Normal</span>(<span class="fl">10</span>, <span class="fl">2</span>)</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>R₁ <span class="op">=</span> <span class="fu">Normal</span>(<span class="fl">17</span>, <span class="fl">2</span>); R₂ <span class="op">=</span> <span class="fu">Normal</span>(<span class="fl">16</span>, <span class="fl">3</span><span class="op">/</span><span class="fl">2</span>); R₃ <span class="op">=</span> <span class="fu">LogNormal</span>(<span class="fl">2.70</span>, <span class="fl">0.07</span>)</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>prng <span class="op">=</span> <span class="fu">MersenneTwister</span>(<span class="fl">240819</span>); n_samples <span class="op">=</span> <span class="fl">10</span><span class="op">^</span><span class="fl">6</span></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>β_df <span class="op">=</span> <span class="fu">DataFrame</span>(R₁ <span class="op">=</span> <span class="fu">rand</span>(prng, R₁, n_samples), </span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>    R₂ <span class="op">=</span> <span class="fu">rand</span>(prng, R₂, n_samples),</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>    R₃ <span class="op">=</span> <span class="fu">rand</span>(prng, R₃, n_samples),</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>    L <span class="op">=</span> <span class="fu">rand</span>(prng, L, n_samples))</span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>β_df.fail <span class="op">=</span> (β_df.L <span class="op">.&gt;=</span> β_df.R₁) <span class="op">.|</span> (β_df.L <span class="op">.&gt;=</span> β_df.R₂) <span class="op">.|</span> (β_df.L <span class="op">.&gt;=</span> β_df.R₃) </span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a>pof <span class="op">=</span> <span class="fu">sum</span>(β_df.fail) <span class="op">/</span> n_samples</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>0.023803</code></pre>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="multi-variate-distributions" class="level2" data-number="3.2">
<h2 data-number="3.2" class="anchored" data-anchor-id="multi-variate-distributions"><span class="header-section-number">3.2</span> Multi-Variate Distributions</h2>
<p>In the above, the resistance parameters of the components are independent. This means that knowing that the resistance of Component A is relatively high, does not provide any information about the likely resistance of the other components. However, if the factors influencing the resistance were common, then a relatively high value for one component would suggest that a relatively high value for the other components were more likely. In such cases, this dependency should be accounted for in the probabilistic model.</p>
<p>One method for achieving this is to use copula functions <span class="citation" data-cites="copula">(<a href="#ref-copula" role="doc-biblioref">Hofert et al. 2022</a>)</span>. There are various types of copula, but in each case they describe the dependency between the different constituent (marginal) components of a multi-variate probabilistic model.</p>
<p>Copulas can be used to model complex dependency, for example weakly dependent at relatively low values and highly dependent at relatively high values (or vice versa). In this case a Gaussian copula is used, which can only model linear dependency using correlation coefficients <span class="math inline">\(\rho\)</span>. Note that copulas (including Gaussian copulas) can be used to describe dependency between parameters, for any uni-variate (marginal) distributions. The resulting distribution may not be possible to define, and use in calculations, without copulas.</p>
<p><span class="math display">\[
\rho_{R_{1}, R_{2}} = 0.8
\]</span></p>
<p><span class="math display">\[
\rho_{R_{1}, R_{3}} = 0.6
\]</span></p>
<p><span class="math display">\[
\rho_{R_{1}, R_{2}} = 0.4
\]</span></p>
<div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-5-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-5-1" role="tab" aria-controls="tabset-5-1" aria-selected="true" href="">Python (using SciPy)</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-5-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-5-2" role="tab" aria-controls="tabset-5-2" aria-selected="false" href="">R</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-5-3-tab" data-bs-toggle="tab" data-bs-target="#tabset-5-3" role="tab" aria-controls="tabset-5-3" aria-selected="false" href="">Julia (using Distributions, Random, Copulas)</a></li></ul>
<div class="tab-content">
<div id="tabset-5-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-5-1-tab">
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="co"># TBC</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</div>
<div id="tabset-5-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-5-2-tab">
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="at">seed =</span> <span class="dv">240819</span>); n_samples <span class="ot">&lt;-</span> <span class="dv">10</span><span class="sc">^</span><span class="dv">6</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="co"># TBC</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</div>
<div id="tabset-5-3" class="tab-pane" role="tabpanel" aria-labelledby="tabset-5-3-tab">
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="kw">function</span> <span class="fu">convert_logsd</span>(log_μ, log_σ)</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>    σ <span class="op">=</span> <span class="fu">exp</span>(log_μ <span class="op">+</span> <span class="fl">1</span><span class="op">/</span><span class="fl">2</span> <span class="op">*</span> log_σ<span class="op">^</span><span class="fl">2</span>) <span class="op">*</span> <span class="fu">sqrt</span>(<span class="fu">exp</span>(log_σ<span class="op">^</span><span class="fl">2</span>) <span class="op">-</span> <span class="fl">1</span>)</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span>(σ)</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">end</span></span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a><span class="kw">function</span> <span class="fu">convert_logmean</span>(log_μ, log_σ)</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>    μ <span class="op">=</span> <span class="fu">exp</span>(log_μ <span class="op">+</span> <span class="fl">1</span><span class="op">/</span><span class="fl">2</span> <span class="op">*</span> log_σ<span class="op">^</span><span class="fl">2</span>)</span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span>(μ)</span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a>    <span class="kw">end</span></span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a>ρ₁₂ <span class="op">=</span> <span class="fl">0.8</span>; ρ₁₃ <span class="op">=</span> <span class="fl">0.6</span>; ρ₂₃ <span class="op">=</span> <span class="fl">0.4</span></span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a>R₃_μ <span class="op">=</span> <span class="fu">convert_logmean</span>(<span class="fl">2.70</span>, <span class="fl">0.07</span>); R₃_σ <span class="op">=</span> <span class="fu">convert_logsd</span>(<span class="fl">2.70</span>, <span class="fl">0.07</span>)</span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a>Σ <span class="op">=</span> [R₁.σ<span class="op">^</span><span class="fl">2</span> ρ₁₂<span class="op">*</span>R₁.σ<span class="op">*</span>R₂.σ ρ₁₃<span class="op">*</span>R₁.σ<span class="op">*</span>R₃_σ</span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a>     ρ₁₂<span class="op">*</span>R₁.σ<span class="op">*</span>R₂.σ R₂.σ<span class="op">^</span><span class="fl">2</span> ρ₂₃<span class="op">*</span>R₂.σ<span class="op">*</span>R₃_σ</span>
<span id="cb24-17"><a href="#cb24-17" aria-hidden="true" tabindex="-1"></a>     ρ₁₃<span class="op">*</span>R₁.σ<span class="op">*</span>R₃_σ ρ₂₃<span class="op">*</span>R₂.σ<span class="op">*</span>R₃_σ R₃_σ<span class="op">^</span><span class="fl">2</span>]</span>
<span id="cb24-18"><a href="#cb24-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-19"><a href="#cb24-19" aria-hidden="true" tabindex="-1"></a>copula <span class="op">=</span> <span class="fu">GaussianCopula</span>(Σ)</span>
<span id="cb24-20"><a href="#cb24-20" aria-hidden="true" tabindex="-1"></a>MVR <span class="op">=</span> <span class="fu">SklarDist</span>(copula, (R₁, R₂, R₃))</span>
<span id="cb24-21"><a href="#cb24-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-22"><a href="#cb24-22" aria-hidden="true" tabindex="-1"></a>prng <span class="op">=</span> <span class="fu">MersenneTwister</span>(<span class="fl">240819</span>); n_samples <span class="op">=</span> <span class="fl">10</span><span class="op">^</span><span class="fl">6</span></span>
<span id="cb24-23"><a href="#cb24-23" aria-hidden="true" tabindex="-1"></a>mv_df <span class="op">=</span> <span class="fu">rand</span>(prng, MVR, n_samples) <span class="op">|&gt;</span> </span>
<span id="cb24-24"><a href="#cb24-24" aria-hidden="true" tabindex="-1"></a>    x <span class="op">-&gt;</span> <span class="fu">transpose</span>(x) <span class="op">|&gt;</span></span>
<span id="cb24-25"><a href="#cb24-25" aria-hidden="true" tabindex="-1"></a>    x <span class="op">-&gt;</span> <span class="fu">DataFrame</span>(x, [<span class="st">"R₁"</span>, <span class="st">"R₂"</span>, <span class="st">"R₃"</span>])</span>
<span id="cb24-26"><a href="#cb24-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-27"><a href="#cb24-27" aria-hidden="true" tabindex="-1"></a>pof <span class="op">=</span> <span class="fu">sum</span>((β_df.L <span class="op">.&gt;=</span> mv_df.R₁) <span class="op">.|</span> (β_df.L <span class="op">.&gt;=</span> mv_df.R₂) <span class="op">.|</span> (β_df.L <span class="op">.&gt;=</span> mv_df.R₃)) <span class="op">/</span> n_samples </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>0.019831</code></pre>
</div>
</div>
</div>
</div>
</div>
<p>Note that the probability of failure reduces when accounting for this dependency. Since failure is defined by the resistance of the components being lower than an applied load, ensuring that low resistances occur together result in fewer simulations that predict failure. Conversely, if multiple components were connected in parallel (where system failure requires all of the components to fail) increasing the dependency in the resistance properties increases the probability of failure as weak components occurring together is relatively more common with this model.</p>
<p>A comprehensive introduction to structural reliability methods is presented in <span class="citation" data-cites="Melchers2018">(<a href="#ref-Melchers2018" role="doc-biblioref">Melchers and Beck 2018</a>)</span>. This book also includes some perceived challenges which are discussed later in this document.</p>
</section>
<section id="statistical-uncertainty" class="level2" data-number="3.3">
<h2 data-number="3.3" class="anchored" data-anchor-id="statistical-uncertainty"><span class="header-section-number">3.3</span> Statistical Uncertainty</h2>
<p>So far this document has introduced the use of probabilistic models to describe uncertainty inherent to simple systems (sometimes called <em>aleatory</em> uncertainty). The second key source of uncertainty in engineering calculations is the statistical uncertainty associated with small, or otherwise imperfect datasets (sometimes called <em>epistemic</em> uncertainty).</p>
<p>This example considers how to interpret a set of measurements of material strength, accounting for statistical uncertainty. The data is presented in <a href="#tbl-strength_data">Table&nbsp;1</a>. This data can be downloaded using the below code, which also shows the first few rows.</p>
<div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-6-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-6-1" role="tab" aria-controls="tabset-6-1" aria-selected="true" href="">Python (using pandas)</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-6-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-6-2" role="tab" aria-controls="tabset-6-2" aria-selected="false" href="">R (using readr)</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-6-3-tab" data-bs-toggle="tab" data-bs-target="#tabset-6-3" role="tab" aria-controls="tabset-6-3" aria-selected="false" href="">Julia (using CSV, DataFrames)</a></li></ul>
<div class="tab-content">
<div id="tabset-6-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-6-1-tab">
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>strength_df <span class="op">=</span> pd.read_csv(filepath_or_buffer <span class="op">=</span> <span class="st">"data_files/strength_data.csv"</span>)</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>strength_df.head(n <span class="op">=</span> <span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>   id       yield     tensile
0   1  415.394479  590.806283
1   2  435.102535  680.617608
2   3  374.046293  683.524267</code></pre>
</div>
</div>
</div>
<div id="tabset-6-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-6-2-tab">
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>strength_df <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="at">file =</span> <span class="st">"data_files/strength_data.csv"</span>)</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>strength_df <span class="sc">|&gt;</span> <span class="fu">head</span>(<span class="at">n =</span> <span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 3 × 3
     id yield tensile
  &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;
1     1  415.    591.
2     2  435.    681.
3     3  374.    684.</code></pre>
</div>
</div>
</div>
<div id="tabset-6-3" class="tab-pane" role="tabpanel" aria-labelledby="tabset-6-3-tab">
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>strength_df <span class="op">=</span> CSV.<span class="fu">read</span>(<span class="st">"data_files/strength_data.csv"</span>, DataFrame)</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a><span class="fu">first</span>(strength_df, <span class="fl">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>3×3 DataFrame
 Row │ id     yield    tensile
     │ Int64  Float64  Float64
─────┼─────────────────────────
   1 │     1  415.394  590.806
   2 │     2  435.103  680.618
   3 │     3  374.046  683.524</code></pre>
</div>
</div>
</div>
</div>
</div>
<p>The results indicate some variability even though each row presents the result of the same test, using the same machine, on a tensile specimen from the same material. This variability can be attributed to:</p>
<ul>
<li><p><strong>Material heterogeneity</strong>. Manufacturing processes used to make structural steel results in local hard spots, laminations, inclusions and other anomalies that can locally influence the strength of the material. The presence of such anomalies in the microstructure of a testing specimen will influence the measured properties.</p></li>
<li><p><strong>Imperfect measurement data</strong>. There is no manufacturing process that creates perfectly homogeneous steel, and there is no measurement of an engineering quantity that will tell us everything we want to know. In this example, the machine used to perform the tests will output results with some precision, which has been quantified by the manufacturers.</p></li>
</ul>
<p>Shown here as a table:</p>
<div class="cell">
<div class="cell-output-display">
<div id="tbl-strength_data" class="anchored">
<table class="table table-sm table-striped">
<caption>Table 1: Tensile Test Data of Steel</caption>
<thead>
<tr class="header">
<th style="text-align: right;">Test ID</th>
<th style="text-align: right;">Yield Strength, MPa</th>
<th style="text-align: right;">Tensile Strength, MPa</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">1</td>
<td style="text-align: right;">415.3945</td>
<td style="text-align: right;">590.8063</td>
</tr>
<tr class="even">
<td style="text-align: right;">2</td>
<td style="text-align: right;">435.1025</td>
<td style="text-align: right;">680.6176</td>
</tr>
<tr class="odd">
<td style="text-align: right;">3</td>
<td style="text-align: right;">374.0463</td>
<td style="text-align: right;">683.5243</td>
</tr>
<tr class="even">
<td style="text-align: right;">4</td>
<td style="text-align: right;">401.6319</td>
<td style="text-align: right;">608.4174</td>
</tr>
<tr class="odd">
<td style="text-align: right;">5</td>
<td style="text-align: right;">365.7331</td>
<td style="text-align: right;">504.0710</td>
</tr>
<tr class="even">
<td style="text-align: right;">6</td>
<td style="text-align: right;">376.6799</td>
<td style="text-align: right;">519.8186</td>
</tr>
<tr class="odd">
<td style="text-align: right;">7</td>
<td style="text-align: right;">365.3381</td>
<td style="text-align: right;">624.4340</td>
</tr>
<tr class="even">
<td style="text-align: right;">8</td>
<td style="text-align: right;">396.7396</td>
<td style="text-align: right;">685.7945</td>
</tr>
<tr class="odd">
<td style="text-align: right;">9</td>
<td style="text-align: right;">376.4909</td>
<td style="text-align: right;">514.6392</td>
</tr>
<tr class="even">
<td style="text-align: right;">10</td>
<td style="text-align: right;">421.1487</td>
<td style="text-align: right;">771.7754</td>
</tr>
<tr class="odd">
<td style="text-align: right;">11</td>
<td style="text-align: right;">425.8122</td>
<td style="text-align: right;">568.4605</td>
</tr>
<tr class="even">
<td style="text-align: right;">12</td>
<td style="text-align: right;">352.4668</td>
<td style="text-align: right;">547.8975</td>
</tr>
<tr class="odd">
<td style="text-align: right;">13</td>
<td style="text-align: right;">393.4283</td>
<td style="text-align: right;">559.1092</td>
</tr>
<tr class="even">
<td style="text-align: right;">14</td>
<td style="text-align: right;">431.9654</td>
<td style="text-align: right;">647.9011</td>
</tr>
<tr class="odd">
<td style="text-align: right;">15</td>
<td style="text-align: right;">363.0708</td>
<td style="text-align: right;">589.4842</td>
</tr>
<tr class="even">
<td style="text-align: right;">16</td>
<td style="text-align: right;">393.3109</td>
<td style="text-align: right;">726.6864</td>
</tr>
<tr class="odd">
<td style="text-align: right;">17</td>
<td style="text-align: right;">379.4241</td>
<td style="text-align: right;">521.7981</td>
</tr>
<tr class="even">
<td style="text-align: right;">18</td>
<td style="text-align: right;">413.7369</td>
<td style="text-align: right;">600.7571</td>
</tr>
<tr class="odd">
<td style="text-align: right;">19</td>
<td style="text-align: right;">388.8842</td>
<td style="text-align: right;">546.4207</td>
</tr>
<tr class="even">
<td style="text-align: right;">20</td>
<td style="text-align: right;">342.2702</td>
<td style="text-align: right;">527.6821</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<p>There is a range of 92.8 MPa. There are many ways that this can be interpreted. Since no value was recorded less than 342 MPa, can it be assumed that lower yield strengths are not credible?</p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Thought: Dealing with variability
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Engineers need to incorporate uncertainty in quantities like material properties to ensure safety and efficiency. Using a <em>worst-case</em> or <em>conservative</em> value as as a threshold is convenient as it does not complicate the calculation, but it doesn’t fully solve the problem because there may not be an obvious threshold value to take. Using the lowest yield strength value measured so far may incentivise minimal testing, as the value will only decrease (or remain constant) as more data is collected.</p>
<p>One attempt to get around this, is provided in the guidance on identifying a suitable value of fracture toughness in a widely used structural integrity management standard <span class="citation" data-cites="BSI2015">(<a href="#ref-BSI2015" role="doc-biblioref"><strong>BSI2015?</strong></a>)</span>. It introduces the procedure for a Minimum Of Three Equivalent (MOTE), estimate. When <span class="math inline">\(3 \to 5\)</span> measurements are available, engineers are advised to take the lowest value, then the second lowest value of <span class="math inline">\(6 \to 10\)</span> measurements, and the third lowest of <span class="math inline">\(10 \to 15\)</span> values.</p>
<p>By running some simulations of fracture toughness tests, below, it can be shown that even by using the MOTE value, there is generally more uncertainty with fewer tests. This results in relatively higher probabilities of non-conservative values such as those greater than the mean (indicated by the dashed line in <a href="#fig-MOTE">Figure&nbsp;3</a>) being selected.</p>
<div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-7-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-7-1" role="tab" aria-controls="tabset-7-1" aria-selected="true" href="">Julia (using Distributions, Random)</a></li></ul>
<div class="tab-content">
<div id="tabset-7-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-7-1-tab">
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>true_strength <span class="op">=</span> <span class="fu">Normal</span>(<span class="fl">130</span>, <span class="fl">20</span>)</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a><span class="kw">function</span> <span class="fu">MOTE</span>(samples<span class="op">::</span><span class="dt">Vector{Float64}</span>)</span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a>    n <span class="op">=</span> <span class="fu">length</span>(samples)</span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> n <span class="op">&lt;</span> <span class="fl">3</span> <span class="op">||</span> n <span class="op">&gt;</span> <span class="fl">15</span></span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a>        <span class="fu">print</span>(<span class="st">"Between 3 and 15 samples required"</span>)</span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span> </span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a>        MOTE <span class="op">=</span> <span class="fu">sort</span>(samples)[<span class="fu">Int</span>(<span class="fu">ceil</span>(n<span class="op">/</span><span class="fl">5</span>))]</span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">end</span></span>
<span id="cb32-10"><a href="#cb32-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> MOTE</span>
<span id="cb32-11"><a href="#cb32-11" aria-hidden="true" tabindex="-1"></a><span class="kw">end</span></span>
<span id="cb32-12"><a href="#cb32-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-13"><a href="#cb32-13" aria-hidden="true" tabindex="-1"></a>MOTE_df <span class="op">=</span> <span class="fu">DataFrame</span>()</span>
<span id="cb32-14"><a href="#cb32-14" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="fl">100</span></span>
<span id="cb32-15"><a href="#cb32-15" aria-hidden="true" tabindex="-1"></a>    meas_strength <span class="op">=</span> <span class="fu">rand</span>(<span class="fu">MersenneTwister</span>(i), true_strength, <span class="fl">15</span>)</span>
<span id="cb32-16"><a href="#cb32-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j <span class="kw">in</span> <span class="fl">3</span><span class="op">:</span><span class="fu">length</span>(meas_strength)</span>
<span id="cb32-17"><a href="#cb32-17" aria-hidden="true" tabindex="-1"></a>        <span class="fu">append!</span>(MOTE_df, </span>
<span id="cb32-18"><a href="#cb32-18" aria-hidden="true" tabindex="-1"></a>                <span class="fu">DataFrame</span>(sim <span class="op">=</span> i, </span>
<span id="cb32-19"><a href="#cb32-19" aria-hidden="true" tabindex="-1"></a>                          n_tests <span class="op">=</span> j, </span>
<span id="cb32-20"><a href="#cb32-20" aria-hidden="true" tabindex="-1"></a>                          MOTE <span class="op">=</span> <span class="fu">MOTE</span>(meas_strength[begin<span class="op">:</span>j])))</span>
<span id="cb32-21"><a href="#cb32-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">end</span></span>
<span id="cb32-22"><a href="#cb32-22" aria-hidden="true" tabindex="-1"></a><span class="cf">end</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>Normal{Float64}(μ=130.0, σ=20.0)</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell">
<div class="cell-output-display">
<div id="fig-MOTE" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="DCE_guidance_files/figure-html/fig-MOTE-1.png" class="img-fluid figure-img" width="672"></p>
<p></p><figcaption class="figure-caption">Figure 3: Effect of Number of Tests on BS 7910 MOTE Estimate of Fracture Toughness</figcaption><p></p>
</figure>
</div>
</div>
</div>
</div>
</div>
</div>
<p>This variability can be approximated using probability distributions. Below, shows how a Normal distribution can be used to approximate the uncertainty in material strength, based on the data in <a href="#tbl-strength_data">Table&nbsp;1</a>.</p>
<div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-8-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-8-1" role="tab" aria-controls="tabset-8-1" aria-selected="true" href="">Python (using SciPy)</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-8-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-8-2" role="tab" aria-controls="tabset-8-2" aria-selected="false" href="">R (using fitdistrplus)</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-8-3-tab" data-bs-toggle="tab" data-bs-target="#tabset-8-3" role="tab" aria-controls="tabset-8-3" aria-selected="false" href="">Julia (using Distributions)</a></li></ul>
<div class="tab-content">
<div id="tabset-8-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-8-1-tab">
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>stats.norm.fit(data <span class="op">=</span> strength_df[<span class="st">'yield'</span>].values, method <span class="op">=</span> <span class="st">'MLE'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>(390.63377067499994, 26.256897184774186)</code></pre>
</div>
</div>
</div>
<div id="tabset-8-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-8-2-tab">
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="fu">fitdist</span>(<span class="at">data =</span> strength_df<span class="sc">$</span>yield, <span class="at">distr =</span> <span class="st">'norm'</span>, <span class="at">method =</span> <span class="st">'mle'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Fitting of the distribution ' norm ' by maximum likelihood 
Parameters:
     estimate Std. Error
mean 390.6338   5.871221
sd    26.2569   4.151580</code></pre>
</div>
</div>
</div>
<div id="tabset-8-3" class="tab-pane" role="tabpanel" aria-labelledby="tabset-8-3-tab">
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="fu">fit_mle</span>(Normal, strength_df.yield)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Normal{Float64}(μ=390.633770675, σ=26.25689718477418)</code></pre>
</div>
</div>
</div>
</div>
</div>
<p>These distribution parameters (mean, <span class="math inline">\(\mu\)</span> and standard deviation, <span class="math inline">\(\sigma\)</span>) represent those with the highest score (likelihood) of the range considered. If the standard deviation was any higher, the likelihood of any values near the mean would be reduced, and if it was any lower the likelihood of any data at the tails would be reduced. Similarly, if the mean was any higher, the likelihood of any lower values would be reduced. So there is a trade-off here, and maximum likelihood estimates will provide the values that maximise the product of the likelihoods (or the sum of the log-likelihoods) for the data that is being used to fit the distribution.</p>
<p>However, there may often not be a clear maximum likelihood, particularly when estimating distribution parameters from a small dataset. In these cases the <em>statistical</em> uncertainty results in many possible values being credible (or having a similar likelihood). These should not be dismissed, and certainly not before there is enough evidence for a model to be confident of it’s maximum likelihood estimates.</p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Thought: Collecting Data Reduces Uncertainty
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>The reason engineers pay for material tests, inspection activities and sensing systems is because the data that they provide can be used to estimate some uncertain quantity of interest. In general, the more data that is available, the less uncertainty will be associated with the prediction.</p>
<p>For instance, a linear model with a straight line that approximately goes through two or three points is much less compelling than a straight line that approximately goes through hundreds of points (when the errors are the same).</p>
<p>The uncertainty that is associated with limited amounts of data is often referred to as <em>statistical</em> or <em>epistemic</em> uncertainty. It is distinct from <em>aleatory</em> uncertainty, which is the variability that is inherent in the problem, no matter how many measurements are available.</p>
<p>Consider how the maximum likelihood estimates of distribution parameters in the above code chunk evolve, as more data is made available. As shown in <a href="#fig-MLE">Figure&nbsp;4</a>, the mean value changes significantly before converging, but the standard error does not diminish.</p>
<div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-9-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-9-1" role="tab" aria-controls="tabset-9-1" aria-selected="true" href="">R (using fitdistrplus)</a></li></ul>
<div class="tab-content">
<div id="tabset-9-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-9-1-tab">
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a>mle_df <span class="ot">&lt;-</span> <span class="fu">tibble</span>()</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(n <span class="cf">in</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">2</span>, <span class="at">to =</span> <span class="fu">nrow</span>(strength_df), <span class="at">by =</span> <span class="dv">1</span>)){</span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a>  available_data <span class="ot">&lt;-</span> strength_df<span class="sc">$</span>yield[<span class="dv">1</span><span class="sc">:</span>n]</span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a>  mle <span class="ot">&lt;-</span> <span class="fu">fitdist</span>(<span class="at">data =</span> available_data, <span class="at">distr =</span> <span class="st">'norm'</span>, <span class="at">method =</span> <span class="st">'mle'</span>)</span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a>  mle_df <span class="ot">&lt;-</span> <span class="fu">bind_rows</span>(mle_df, <span class="fu">tibble</span>(<span class="at">n_tests =</span> n, </span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a>                                     <span class="at">mean =</span> mle<span class="sc">$</span>estimate[<span class="dv">1</span>], <span class="at">sd =</span> mle<span class="sc">$</span>estimate[<span class="dv">2</span>],</span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a>                                     <span class="at">mean_se =</span> mle<span class="sc">$</span>sd[<span class="dv">1</span>], <span class="at">sd_se =</span> mle<span class="sc">$</span>sd[<span class="dv">2</span>]))</span>
<span id="cb40-8"><a href="#cb40-8" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<div class="cell-output-display">
<div id="fig-MLE" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="DCE_guidance_files/figure-html/fig-MLE-1.png" class="img-fluid figure-img" width="672"></p>
<p></p><figcaption class="figure-caption">Figure 4: Effect of Number of Tests on Maximum Likelihood Estimate of Distribution Parameters</figcaption><p></p>
</figure>
</div>
</div>
</div>
</div>
</div>
</div>
<p>A distribution based on the maximum likelihood estimates, which could be used for prediction, varies a lot. Rather than using point values of parameters that move around as more data becomes available, it is preferable to quantify the statistical uncertainty in these estimates so that the effect of collecting additional data can be accounted for, allowing for the identification of when it is expected to be worthwhile paying for more data.</p>
<p>The example calculations in this document, though presented in various levels of detail, are all based on the premise that collecting data reduces statistical uncertainty, and it is possible to check when this is (and is not) expected to be useful, by pushing the results through a decision analysis.</p>
</div>
</div>
</div>
<p>Statistical uncertainty in estimates of yield strength will be relatively high when only very few measurements are available. Maximum likelihood estimates will therefore not produce reliable predictions, since they could change significantly after including just a few more tests. It is especially important to understand this variability in cases like this to help distinguish a highly uncertain model with a highly informed model. Failing to do so can result in placing too much belief in a prediction, and so this distinction is important when using models for decision support.</p>
<p>One method of quantifying variability in a maximum likelihood estimate is to find confidence intervals. Confidence intervals can be obtained by repeating the calculation many times using different samples of the data, and identifying the range within which some proportion of results are contained in. The below code finds the 95% confidence intervals for the maximum likelihood estimate of the mean yield strength, based on the tensile test data in <a href="#tbl-strength_data">Table&nbsp;1</a>.</p>
<p>Some further detail on confidence intervals can be found in <span class="citation" data-cites="Gelman2020">(<a href="#ref-Gelman2020" role="doc-biblioref">Gelman, Hill, and Vehtari 2020</a>)</span>, but essentially, the below result should be interpreted as: in repeated experiments, the mean yield strength will lie somewhere within this range 95% of the time. How that fact can be used to support decision making is not clear, so this document considers a more intuitive method of describing this uncertainty.</p>
<div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-10-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-10-1" role="tab" aria-controls="tabset-10-1" aria-selected="true" href="">Python (using SciPy)</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-10-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-10-2" role="tab" aria-controls="tabset-10-2" aria-selected="false" href="">R (using boot)</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-10-3-tab" data-bs-toggle="tab" data-bs-target="#tabset-10-3" role="tab" aria-controls="tabset-10-3" aria-selected="false" href="">Julia (using Distributions, Bootstrap)</a></li></ul>
<div class="tab-content">
<div id="tabset-10-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-10-1-tab">
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>yield_data <span class="op">=</span> (strength_df[<span class="st">'yield'</span>].values,)</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_MLE_mean(data):</span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> stats.norm.fit(data <span class="op">=</span> data, method <span class="op">=</span> <span class="st">'MLE'</span>)[<span class="dv">0</span>]</span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a>bootstrap_mean <span class="op">=</span> stats.bootstrap(data <span class="op">=</span> yield_data, statistic <span class="op">=</span> get_MLE_mean, vectorized <span class="op">=</span> <span class="va">False</span>, </span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a>confidence_level <span class="op">=</span> <span class="fl">0.95</span>, n_resamples <span class="op">=</span> <span class="dv">1000</span>, method <span class="op">=</span> <span class="st">"basic"</span>)</span>
<span id="cb41-8"><a href="#cb41-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-9"><a href="#cb41-9" aria-hidden="true" tabindex="-1"></a>bootstrap_mean.confidence_interval</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>ConfidenceInterval(low=379.3259440017499, high=401.99877560787485)</code></pre>
</div>
</div>
</div>
<div id="tabset-10-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-10-2-tab">
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>get_MLE_mean <span class="ot">&lt;-</span> <span class="cf">function</span>(x, id) {<span class="fu">fitdist</span>(x[id], <span class="at">distr =</span> <span class="st">'norm'</span>)<span class="sc">$</span>estimate[<span class="dv">1</span>]}</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a>bootstrap_mean <span class="ot">&lt;-</span> strength_df<span class="sc">$</span>yield <span class="sc">|&gt;</span></span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">boot</span>(<span class="at">statistic =</span> get_MLE_mean, <span class="at">R =</span> <span class="dv">1000</span>) <span class="sc">|&gt;</span></span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">boot.ci</span>(<span class="at">conf =</span> <span class="fl">0.95</span>)</span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a>bootstrap_mean<span class="sc">$</span>basic <span class="sc">|&gt;</span> <span class="fu">as_tibble</span>() <span class="sc">|&gt;</span> </span>
<span id="cb43-8"><a href="#cb43-8" aria-hidden="true" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">select</span>(<span class="fu">c</span>(conf, V4, V5)) <span class="sc">|&gt;</span></span>
<span id="cb43-9"><a href="#cb43-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rename</span>(<span class="at">lower_bound =</span> V4, <span class="at">upper_bound =</span> V5)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 1 × 3
   conf lower_bound upper_bound
  &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;
1  0.95        379.        402.</code></pre>
</div>
</div>
</div>
<div id="tabset-10-3" class="tab-pane" role="tabpanel" aria-labelledby="tabset-10-3-tab">
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="kw">function</span> <span class="fu">get_MLE_mean</span>(data)</span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a>    Distributions.<span class="fu">fit_mle</span>(LogNormal, data).μ</span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a><span class="kw">end</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>get_MLE_mean (generic function with 1 method)</code></pre>
</div>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a><span class="fu">bootstrap</span>(get_MLE_mean, strength_df.yield, <span class="fu">BasicSampling</span>(<span class="fl">1_000</span>)) <span class="op">|&gt;</span></span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a>    x <span class="op">-&gt;</span> <span class="fu">confint</span>(x, <span class="fu">BasicConfInt</span>(<span class="fl">0.95</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>((5.965508668241968, 5.93686931073122, 5.993966098479889),)</code></pre>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="probabilistic-programming" class="level2" data-number="3.4">
<h2 data-number="3.4" class="anchored" data-anchor-id="probabilistic-programming"><span class="header-section-number">3.4</span> Probabilistic Programming</h2>
<section id="introduction-1" class="level3" data-number="3.4.1">
<h3 data-number="3.4.1" class="anchored" data-anchor-id="introduction-1"><span class="header-section-number">3.4.1</span> Introduction</h3>
<p>Probabilistic programming is used to describe a statistical model, and then automate the inference (estimation of the unknown and uncertain parameters) <span class="citation" data-cites="Rainforth2017">(<a href="#ref-Rainforth2017" role="doc-biblioref">Rainforth 2017</a>)</span>. Sometimes known as probabilistic machine learning <span class="citation" data-cites="Ghahramani2015">(<a href="#ref-Ghahramani2015" role="doc-biblioref">Ghahramani 2015</a>)</span>, inferring unknown parameters, while also accounting for the uncertainty, including statistical uncertainty, is a desirable characteristic of a calculation. One reason for this is because it can be used to demonstrate how additional data can reduce uncertainty, and this can be used as the basis for intelligently collecting data.</p>
<p>There are now many probabilistic programming languages available to engineers, but the one that is used in the examples in this document is <code>Stan</code>. The primary justification for this is that it runs a state of the art sampling algorithm, and (unlike many alternatives) it can be used with many other languages. In these examples, pre- and post-processing of data will be done in <code>R</code> and <code>Python</code>.</p>
<p>Firstly, loading the Stan model for quantifying uncertainty in material strength:</p>
<div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-11-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-11-1" role="tab" aria-controls="tabset-11-1" aria-selected="true" href="">Python</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-11-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-11-2" role="tab" aria-controls="tabset-11-2" aria-selected="false" href="">R</a></li></ul>
<div class="tab-content">
<div id="tabset-11-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-11-1-tab">
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a>strength_model <span class="op">=</span> cmdstanpy.CmdStanModel(stan_file <span class="op">=</span> <span class="st">"stan_models/yield_strength_model.stan"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>INFO:cmdstanpy:found newer exe file, not recompiling</code></pre>
</div>
</div>
</div>
<div id="tabset-11-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-11-2-tab">
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a>strength_model <span class="ot">&lt;-</span> <span class="fu">cmdstan_model</span>(<span class="at">stan_file =</span> <span class="st">"stan_models/yield_strength_model.stan"</span>, <span class="at">stanc_options =</span> <span class="fu">list</span>(<span class="st">"O1"</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</div>
</div>
</div>
<p>The data block in the <code>Stan</code> file indicates the data that it is expecting. In <code>Python</code> this data is provided to the <code>Stan</code> model in the form of a dictionary, and in <code>R</code> it is a list.</p>
<div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-12-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-12-1" role="tab" aria-controls="tabset-12-1" aria-selected="true" href="">Python</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-12-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-12-2" role="tab" aria-controls="tabset-12-2" aria-selected="false" href="">R</a></li></ul>
<div class="tab-content">
<div id="tabset-12-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-12-1-tab">
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a>strength_data <span class="op">=</span> {<span class="st">"n_strength"</span> : strength_df.shape[<span class="dv">0</span>], </span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a>                 <span class="st">"strength_meas"</span> : strength_df[<span class="st">"yield"</span>].values,</span>
<span id="cb52-3"><a href="#cb52-3" aria-hidden="true" tabindex="-1"></a>                 <span class="st">"error"</span> : <span class="dv">5</span>, <span class="st">"m_s"</span> : <span class="dv">350</span>, <span class="st">"sd_s"</span> : <span class="dv">50</span>, <span class="st">"rate_s"</span> : <span class="fl">0.1</span>}</span>
<span id="cb52-4"><a href="#cb52-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-5"><a href="#cb52-5" aria-hidden="true" tabindex="-1"></a>n_par <span class="op">=</span> multiprocessing.cpu_count()</span>
<span id="cb52-6"><a href="#cb52-6" aria-hidden="true" tabindex="-1"></a>n_chains <span class="op">=</span> <span class="dv">4</span><span class="op">;</span> n_draws <span class="op">=</span> <span class="dv">1000</span><span class="op">;</span> n_warmup <span class="op">=</span> <span class="dv">2000</span></span>
<span id="cb52-7"><a href="#cb52-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-8"><a href="#cb52-8" aria-hidden="true" tabindex="-1"></a>strength_fit <span class="op">=</span> strength_model.sample(data <span class="op">=</span> strength_data, seed <span class="op">=</span> <span class="dv">1234</span>, </span>
<span id="cb52-9"><a href="#cb52-9" aria-hidden="true" tabindex="-1"></a>                                     chains <span class="op">=</span> n_chains, parallel_chains <span class="op">=</span> n_par, </span>
<span id="cb52-10"><a href="#cb52-10" aria-hidden="true" tabindex="-1"></a>                                     iter_warmup <span class="op">=</span> n_warmup, iter_sampling <span class="op">=</span> n_draws)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</div>
<div id="tabset-12-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-12-2-tab">
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a>strength_data <span class="ot">=</span> <span class="fu">list</span>(<span class="at">n_strength =</span> <span class="fu">nrow</span>(strength_df),</span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a>                     <span class="at">strength_meas =</span> strength_df<span class="sc">$</span>yield,</span>
<span id="cb53-3"><a href="#cb53-3" aria-hidden="true" tabindex="-1"></a>                     <span class="at">error =</span> <span class="dv">3</span>,</span>
<span id="cb53-4"><a href="#cb53-4" aria-hidden="true" tabindex="-1"></a>                     <span class="at">m_s =</span> <span class="dv">350</span>, <span class="at">sd_s =</span> <span class="dv">50</span>, <span class="at">rate_s =</span> <span class="fl">0.1</span>)</span>
<span id="cb53-5"><a href="#cb53-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-6"><a href="#cb53-6" aria-hidden="true" tabindex="-1"></a>n_par <span class="ot">&lt;-</span> parallel<span class="sc">::</span><span class="fu">detectCores</span>()</span>
<span id="cb53-7"><a href="#cb53-7" aria-hidden="true" tabindex="-1"></a>n_chains <span class="ot">&lt;-</span> <span class="dv">4</span>; n_draws <span class="ot">&lt;-</span> <span class="dv">1000</span>; n_warmup <span class="ot">&lt;-</span> <span class="dv">2000</span></span>
<span id="cb53-8"><a href="#cb53-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-9"><a href="#cb53-9" aria-hidden="true" tabindex="-1"></a>strength_fit <span class="ot">&lt;-</span> strength_model<span class="sc">$</span><span class="fu">sample</span>(<span class="at">data =</span> strength_data, <span class="at">seed =</span> <span class="dv">1234</span>,</span>
<span id="cb53-10"><a href="#cb53-10" aria-hidden="true" tabindex="-1"></a>                                      <span class="at">chains =</span> n_chains, <span class="at">parallel_chains =</span> n_par, </span>
<span id="cb53-11"><a href="#cb53-11" aria-hidden="true" tabindex="-1"></a>                                      <span class="at">iter_warmup =</span> n_warmup, <span class="at">iter_sampling =</span> n_draws)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</div>
</div>
</div>
<p>This model estimates the mean and standard deviation of the strength together. It also accounts for some measurement uncertainty, which is simple to incorporate. The model can be described using statistical language, as shown below.</p>
<p>Firstly, the measured yield strength, <span class="math inline">\(\sigma_{Ym}\)</span> can be described as normally distributed with a mean equal to the true yield strength, <span class="math inline">\(\sigma_{Y}\)</span> plus some bias (which is assumed to be zero here), and a standard deviation, <span class="math inline">\(\epsilon\)</span>, which describes the variation from <span class="math inline">\(\sigma_{Y}\)</span>, due to the measurement process. Here, <span class="math inline">\(\epsilon\)</span> (or a similar measure) could be quoted from the tensile testing machine manufacturer, or the organisation that performed the testing. Note that in the above code, a value of <span class="math inline">\(5 MPa\)</span> has been used.</p>
<p><span class="math display">\[
\sigma_{Ym} \sim N(\sigma_{Y}, \epsilon)
\]</span></p>
<p>Secondly, <span class="math inline">\(\sigma_{Y}\)</span> is described as normally distributed, with a mean, <span class="math inline">\(\mu\)</span>, and a standard deviation, <span class="math inline">\(\sigma\)</span>.</p>
<p><span class="math display">\[
\sigma_{Y} \sim N(\mu, \sigma)
\]</span></p>
<p>This could be a fully defined model, but there is also ab opportunity to provide a starting point. Rather than requiring the model to narrow down it’s estimate from all possible values, engineers may wish to point it in a helpful direction since they will have some idea of what the measurements will be even before seeing them. Whilst acknowledging that there can be a lot of variation in the quality of structural steel, a yield strength of the order of hundreds of <span class="math inline">\(MPa\)</span> is far more credible than billions, or millions. Engineers may also want to constrain the values to be positive.</p>
<p>In this example, some <em>prior</em> models (starting points) for the mean and standard deviation of the yield strength are shown below. These, like all other details about the structure of this model, are a subjective feature, but sampling from these priors can be a helpful tool in agreeing suitable values <span class="citation" data-cites="Gabry2020">(<a href="#ref-Gabry2020" role="doc-biblioref"><strong>Gabry2020?</strong></a>)</span>. An example of this is provided later in this document.</p>
<p><span class="math display">\[
\mu \sim N(\mu = 350 MPa, \sigma = 50 MPa), \mu \ge 0 MPa
\]</span></p>
<p><span class="math display">\[
\sigma \sim \exp(\lambda = \frac{1}{10}), \sigma \ge 0 MPa
\]</span></p>
<p>Once the model has converged, samples can be drawn from the distribution of parameters (<span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span>). However, it is first necessary to extract (and process) the results. Below are some suggested methods of achieving this.</p>
<div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-13-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-13-1" role="tab" aria-controls="tabset-13-1" aria-selected="true" href="">Python</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-13-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-13-2" role="tab" aria-controls="tabset-13-2" aria-selected="false" href="">R</a></li></ul>
<div class="tab-content">
<div id="tabset-13-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-13-1-tab">
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Stan_Posterior:</span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, fit):</span>
<span id="cb54-3"><a href="#cb54-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fit <span class="op">=</span> fit</span>
<span id="cb54-4"><a href="#cb54-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.draws_per_chain <span class="op">=</span> <span class="va">self</span>.fit.draws().shape[<span class="dv">0</span>]</span>
<span id="cb54-5"><a href="#cb54-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.n_chains <span class="op">=</span> <span class="va">self</span>.fit.draws().shape[<span class="dv">1</span>]</span>
<span id="cb54-6"><a href="#cb54-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.n_pars <span class="op">=</span> <span class="va">self</span>.fit.draws().shape[<span class="dv">2</span>]</span>
<span id="cb54-7"><a href="#cb54-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.draws_tot <span class="op">=</span> <span class="va">self</span>.draws_per_chain <span class="op">*</span> <span class="va">self</span>.n_chains</span>
<span id="cb54-8"><a href="#cb54-8" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb54-9"><a href="#cb54-9" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> draws_df(<span class="va">self</span>):</span>
<span id="cb54-10"><a href="#cb54-10" aria-hidden="true" tabindex="-1"></a>        posterior_df <span class="op">=</span> pd.DataFrame(columns <span class="op">=</span> <span class="va">self</span>.fit.column_names <span class="op">+</span> (<span class="st">"Chain"</span>, <span class="st">"Iteration"</span>))</span>
<span id="cb54-11"><a href="#cb54-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> c <span class="kw">in</span> <span class="bu">range</span>(<span class="va">self</span>.n_chains):</span>
<span id="cb54-12"><a href="#cb54-12" aria-hidden="true" tabindex="-1"></a>            posterior_df <span class="op">=</span> pd.concat([posterior_df,</span>
<span id="cb54-13"><a href="#cb54-13" aria-hidden="true" tabindex="-1"></a>                      (pd.DataFrame(<span class="va">self</span>.fit.draws()[:,c,:], columns <span class="op">=</span> <span class="va">self</span>.fit.column_names).</span>
<span id="cb54-14"><a href="#cb54-14" aria-hidden="true" tabindex="-1"></a>                      assign(Chain <span class="op">=</span> <span class="st">"Chain </span><span class="sc">{}</span><span class="st">"</span>.<span class="bu">format</span>(<span class="dv">1</span> <span class="op">+</span> c),</span>
<span id="cb54-15"><a href="#cb54-15" aria-hidden="true" tabindex="-1"></a>                      Iteration <span class="op">=</span> <span class="dv">1</span> <span class="op">+</span> np.arange(<span class="va">self</span>.draws_per_chain)))])</span>
<span id="cb54-16"><a href="#cb54-16" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span>(posterior_df)</span>
<span id="cb54-17"><a href="#cb54-17" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb54-18"><a href="#cb54-18" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> tidy_draws_df(<span class="va">self</span>):</span>
<span id="cb54-19"><a href="#cb54-19" aria-hidden="true" tabindex="-1"></a>        posterior_df_tidy <span class="op">=</span> <span class="va">self</span>.draws_df().melt(id_vars <span class="op">=</span> (<span class="st">"Chain"</span>, <span class="st">"Iteration"</span>))</span>
<span id="cb54-20"><a href="#cb54-20" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span>(posterior_df_tidy)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>which allows for…</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a>strength_posterior <span class="op">=</span> Stan_Posterior(fit <span class="op">=</span> strength_fit)</span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a>strength_posterior_df <span class="op">=</span> strength_posterior.tidy_draws_df()</span>
<span id="cb55-4"><a href="#cb55-4" aria-hidden="true" tabindex="-1"></a>strength_posterior_df.tail(n <span class="op">=</span> <span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>          Chain Iteration            variable    value
119997  Chain 4       998  strength_post_pred  393.001
119998  Chain 4       999  strength_post_pred  360.261
119999  Chain 4      1000  strength_post_pred  388.726</code></pre>
</div>
</div>
</div>
<div id="tabset-13-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-13-2-tab">
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a>strength_data_df <span class="ot">&lt;-</span> DomDF<span class="sc">::</span><span class="fu">tidy_mcmc_draws</span>(<span class="at">cmdstan_fit =</span> strength_fit)</span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a><span class="fu">tail</span>(strength_data_df)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 6 × 4
  Parameter          Chain Iteration value
  &lt;chr&gt;              &lt;int&gt;     &lt;int&gt; &lt;dbl&gt;
1 strength_post_pred     4       995  371.
2 strength_post_pred     4       996  369.
3 strength_post_pred     4       997  349.
4 strength_post_pred     4       998  411.
5 strength_post_pred     4       999  412.
6 strength_post_pred     4      1000  401.</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-5-contents" aria-controls="callout-5" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Thought: Data vs.&nbsp;Information
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-5" class="callout-5-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>It is widely acknowledged that not all data are equally informative. Engineering data often consists of some indirect measurements of a complex physical phenomena, sometimes in challenging environments. As a result, it will always be associated with some precision, bias and reliability.</p>
<p>It may be necessary to conduct some calibration experiments to quantify these properties. Higher quality (more precise, less biased, more reliable) data will always be at least as useful as lower quality data, and will sometimes be worth paying much more for.</p>
<p>Risk based inspection standards (such as API 580) often acknowledge this difference in quality. A visual inspection is not considered as good as an ultrasonic inspection for damage, and is therefore recommended to be completed more frequently to manage risk. The calculations in this document account for data quality more accurately. Rather than relying on simple heuristics, statistical models are used to relate the information content to the raw data.</p>
</div>
</div>
</div>
<p>There are many alternative probabilistic programming languages available to engineers. One example is the <code>Turing</code> library, written for <code>Julia</code> users. The model can be specified using the <code>@model</code> macro, as shown below:</p>
<div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-14-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-14-1" role="tab" aria-controls="tabset-14-1" aria-selected="true" href="">Julia (using Turing)</a></li></ul>
<div class="tab-content">
<div id="tabset-14-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-14-1-tab">
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="pp">@model</span> <span class="kw">function</span> <span class="fu">yield_model</span>(yield_strength_meas<span class="op">::</span><span class="dt">Vector{Float64}</span>, ϵ<span class="op">::</span><span class="dt">Float64 </span><span class="op">=</span> <span class="fl">5.0</span>)</span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb59-3"><a href="#cb59-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Priors</span></span>
<span id="cb59-4"><a href="#cb59-4" aria-hidden="true" tabindex="-1"></a>    σ <span class="op">~</span> <span class="fu">Exponential</span>(<span class="fl">10</span>)</span>
<span id="cb59-5"><a href="#cb59-5" aria-hidden="true" tabindex="-1"></a>    μ <span class="op">~</span> <span class="fu">Normal</span>(<span class="fl">350</span>, <span class="fl">50</span>)</span>
<span id="cb59-6"><a href="#cb59-6" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb59-7"><a href="#cb59-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Gaussian model</span></span>
<span id="cb59-8"><a href="#cb59-8" aria-hidden="true" tabindex="-1"></a>    yield_strength <span class="op">~</span> <span class="fu">Normal</span>(μ, σ)</span>
<span id="cb59-9"><a href="#cb59-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-10"><a href="#cb59-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Relating yield strength to imprecise test data</span></span>
<span id="cb59-11"><a href="#cb59-11" aria-hidden="true" tabindex="-1"></a>    n_samples <span class="op">=</span> <span class="fu">length</span>(yield_strength)</span>
<span id="cb59-12"><a href="#cb59-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> n <span class="op">∈</span> n_samples</span>
<span id="cb59-13"><a href="#cb59-13" aria-hidden="true" tabindex="-1"></a>        yield_strength_meas[n] <span class="op">~</span> <span class="fu">Normal</span>(yield_strength, ϵ)</span>
<span id="cb59-14"><a href="#cb59-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">end</span></span>
<span id="cb59-15"><a href="#cb59-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-16"><a href="#cb59-16" aria-hidden="true" tabindex="-1"></a><span class="kw">end</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>yield_model (generic function with 3 methods)</code></pre>
</div>
</div>
<p>Which can then be run to generate a data frame of samples from the joint posterior distribution:</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb61"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a>n_draws <span class="op">=</span> <span class="fl">1000</span>; n_chains <span class="op">=</span> <span class="fl">4</span>; sampler <span class="op">=</span> <span class="fu">NUTS</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>NUTS{Turing.Essential.ForwardDiffAD{0}, (), AdvancedHMC.DiagEuclideanMetric}(-1, 0.65, 10, 1000.0, 0.0)</code></pre>
</div>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb63"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a>posterior_df <span class="op">=</span> <span class="fu">yield_model</span>(strength_df.yield) <span class="op">|&gt;</span></span>
<span id="cb63-2"><a href="#cb63-2" aria-hidden="true" tabindex="-1"></a>    x <span class="op">-&gt;</span> <span class="fu">sample</span>(x, sampler, <span class="fu">MCMCThreads</span>(), n_draws, n_chains) <span class="op">|&gt;</span></span>
<span id="cb63-3"><a href="#cb63-3" aria-hidden="true" tabindex="-1"></a>    x <span class="op">-&gt;</span> <span class="fu">DataFrame</span>(x) <span class="op">|&gt;</span></span>
<span id="cb63-4"><a href="#cb63-4" aria-hidden="true" tabindex="-1"></a>    x <span class="op">-&gt;</span> <span class="pp">@select</span>(x, <span class="op">:</span>chain, <span class="op">:</span>iteration, <span class="op">:</span>σ, <span class="op">:</span>μ)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>4000×4 DataFrame
  Row │ chain  iteration  σ         μ
      │ Int64  Int64      Float64   Float64
──────┼─────────────────────────────────────
    1 │     1        501   7.60388  414.031
    2 │     1        502  21.7568   410.287
    3 │     1        503   4.9074   411.312
    4 │     1        504   5.48725  410.706
    5 │     1        505   5.85818  416.116
    6 │     1        506  12.5036   410.475
    7 │     1        507  10.1901   412.924
    8 │     1        508  14.6782   395.908
  ⋮   │   ⋮        ⋮         ⋮         ⋮
 3994 │     4       1494  11.5036   419.176
 3995 │     4       1495  13.3807   406.22
 3996 │     4       1496  18.9634   393.053
 3997 │     4       1497   5.03992  419.225
 3998 │     4       1498   4.56622  418.551
 3999 │     4       1499   7.03583  408.227
 4000 │     4       1500  16.0588   434.611
                           3985 rows omitted</code></pre>
</div>
</div>
</div>
</div>
</div>
<p>The joint distribution of parameters can then be used to sample from predictive distributions of other quantities. Any subsequent structural reliability analysis using this distribution of yield strength will account for the statistical uncertainty due to the limited amount of test data. This additional uncertainty, particularly for probabilities of very low values of strength, may be a more principled approach for dealing with the so-called <em>tail-sensitivity problem</em> <span class="citation" data-cites="Melchers2018">(<a href="#ref-Palmer2012" role="doc-biblioref"><strong>Palmer2012?</strong></a>)</span>.</p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-6-contents" aria-controls="callout-6" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Thought: Statistical Uncertainty in Monte Carlo Sampling
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-6" class="callout-6-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Monte Carlo sampling of rare events, such as failure may require a large amount of simulations, only very few of which may predict failure. As proposed in <a href="https://eracons.com/resources/mcs-post-processing">this article</a>, statistical uncertainty can be accounted for in this estimate to provide a distribution of credible probabilities of failure, rather than a single maximum likelihood point.</p>
<p>This can be achieved using probabilistic programming, but this may require some re-scaling. Many MCMC sampling algorithms may find it challenging to sample from the very narrow distribution of probabilities of failure. All the values will be very small, the sampling will be highly sensitive to the parameters that govern the sampling. However, sampling from the negative index of <span class="math inline">\(\beta_{R}\)</span> will provide a more management scale, likely to be in the region of <span class="math inline">\(0\)</span> - <span class="math inline">\(10\)</span>. This could be further reparameterised if required, but would then lose some immediate interpretability.</p>
</div>
</div>
</div>
<p>The <code>Stan</code> and <code>Turing.jl</code> probabilistic models of yield strength defines a joint distribution of the mean and standard deviation of yield strength. This means that, as well as quantifying the uncertainty in both parameters, the inter-dependencies are also accounted for.</p>
<p>For instance, consider the samples from the <code>Stan</code> model in <a href="#fig-MCMC_post_sigmaY">Figure&nbsp;5</a>. All of the relatively low values of standard deviation (coloured in red) correspond to a narrow range of possible mean values, wheras the relatively high values (coloured in green) were sometimes associated with much higher or lower values for the mean. One way to rationalise this is that, whilst there is some uncertainty in the estimate of the mean value of yield strength, for low or high values to be consistent with the available data, they may need to be associated with a greater variance. A low standard deviation that was associated with a very low mean value would correspond to a narrow distribution that did not greatly overlap with the test data, which us why we do not see this combination in <a href="#fig-MCMC_post_sigmaY">Figure&nbsp;5</a>.</p>
<p>Being able to push these uncertainties and dependencies into predictions, is why modern probabilistic models can provide useful, informative results, even with small amounts of imperfect data.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-MCMC_post_sigmaY" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="DCE_guidance_files/figure-html/fig-MCMC_post_sigmaY-1.png" class="img-fluid figure-img" width="672"></p>
<p></p><figcaption class="figure-caption">Figure 5: Samples from Joint Distribution of Parameters in Probabilistic Yield Strength Model</figcaption><p></p>
</figure>
</div>
</div>
</div>
<!-- Heat loss (in $W$) through building elements, such as walls and windows (with cross-sectional area in $m^2$) is characterised a *U-value*, standardised to represent a $1 \deg K$ change in temperature. A low U-value indicates a better insultaed building element, that loses less heat. -->
<!-- For a wall, the $U$-value can be calculated using the below equation: -->
<!-- $$ -->
<!-- U = \dfrac{1}{\frac{1}{h_{i}} + \sum_{j = 1}^{J layers} \frac{s_{j}}{\lambda_{j}} + \frac{1}{h_{e}}} -->
<!-- $$ -->
<!-- ...where $s_{i}$ and $\lambda_{i}$ are the thickness and thermal conductivity of each layer in the wall, and $h_{i}$ and $h_{e}$ are respectively the internal and external convective heat transfer coefficients. -->
<!-- U-values are specified in building regulations [@PartL_2022]. For example for a new dwelling, the minimum U values for the roof, walls and floor are specified as $0.11$, $0.18$ and $0.13 W m^{-2} K^{-1}$, respectively. -->
<!-- U-values for new buildings are typically calculated using the above equation. However for retrofit of existing buildings it may be necessary to measure U-values, particularly if construction details are not known. -->
</section>
</section>
<section id="sampling-outcomes" class="level2" data-number="3.5">
<h2 data-number="3.5" class="anchored" data-anchor-id="sampling-outcomes"><span class="header-section-number">3.5</span> Sampling Outcomes</h2>
<p><em>Example of prior predictive sampling, and posterior predictive sampling for heat loss in buildings</em></p>
<p>Consider a test to better understand the performance of a sensing technology. One feature that may need to be characterised is the probability of detection. Here, small signals are generally less likely to be reliably detected by the sensor and signal processing. The relationship between the size of the input <span class="math inline">\(X\)</span> and the probability of detection, <span class="math inline">\(\Pr(det)\)</span> can be modelled using a logistic regression <span class="citation" data-cites="HSE2006">(<a href="#ref-Harding2008" role="doc-biblioref"><strong>Harding2008?</strong></a>)</span>, as shown below:</p>
<p><span class="math display">\[
\Pr(det)  = \dfrac{\exp(\alpha + \beta \times X)}{1 + \exp(\alpha + \beta \times X)}
\]</span></p>
<p>This model has the benefit of producing values between <span class="math inline">\(0\)</span> and <span class="math inline">\(1\)</span>, and the distribution parameters <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> describe how <span class="math inline">\(\Pr(det)\)</span> increases (or decreases) with input size, <span class="math inline">\(X\)</span>. If this was a new crack detection technology for use in inspections, <span class="math inline">\(X\)</span> may represent the extent (size) of a crack.</p>
<div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-15-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-15-1" role="tab" aria-controls="tabset-15-1" aria-selected="true" href="">R (using purrr, TruncatedNormal, tibble)</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-15-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-15-2" role="tab" aria-controls="tabset-15-2" aria-selected="false" href="">Python (using SciPy, NumPy, Math, Pandas)</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-15-3-tab" data-bs-toggle="tab" data-bs-target="#tabset-15-3" role="tab" aria-controls="tabset-15-3" aria-selected="false" href="">Julia (using Random, Distributions, DataFrames, DataFramesMeta)</a></li></ul>
<div class="tab-content">
<div id="tabset-15-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-15-1-tab">
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb65"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a>logistic_fun <span class="ot">&lt;-</span> <span class="cf">function</span>(alpha, beta, x){</span>
<span id="cb65-2"><a href="#cb65-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">exp</span>(alpha <span class="sc">+</span> beta <span class="sc">*</span> x) <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">+</span> <span class="fu">exp</span>(alpha <span class="sc">+</span> beta <span class="sc">*</span> x))</span>
<span id="cb65-3"><a href="#cb65-3" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb65-4"><a href="#cb65-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-5"><a href="#cb65-5" aria-hidden="true" tabindex="-1"></a>n_prior_samples <span class="ot">&lt;-</span> <span class="dv">100</span>; x_start <span class="ot">&lt;-</span> <span class="dv">0</span>; x_end <span class="ot">&lt;-</span> <span class="dv">5</span></span>
<span id="cb65-6"><a href="#cb65-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-7"><a href="#cb65-7" aria-hidden="true" tabindex="-1"></a>alpha_prior_mean <span class="ot">&lt;-</span> <span class="sc">-</span><span class="dv">3</span>; alpha_prior_sd <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">/</span><span class="dv">2</span></span>
<span id="cb65-8"><a href="#cb65-8" aria-hidden="true" tabindex="-1"></a>beta_prior_mean <span class="ot">&lt;-</span> <span class="dv">2</span>; beta_prior_sd <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb65-9"><a href="#cb65-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-10"><a href="#cb65-10" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="at">seed =</span> <span class="dv">1234</span>)</span>
<span id="cb65-11"><a href="#cb65-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-12"><a href="#cb65-12" aria-hidden="true" tabindex="-1"></a>prior_pred_df <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">alpha_prior =</span> <span class="fu">rnorm</span>(<span class="at">n =</span> n_prior_samples, <span class="at">mean =</span> alpha_prior_mean, <span class="at">sd =</span> alpha_prior_sd),</span>
<span id="cb65-13"><a href="#cb65-13" aria-hidden="true" tabindex="-1"></a>                        <span class="at">beta_prior =</span> <span class="fu">rtnorm</span>(<span class="at">n =</span> n_prior_samples, <span class="at">mu =</span> beta_prior_mean, <span class="at">sd =</span> beta_prior_sd, <span class="at">lb =</span> <span class="dv">0</span>, <span class="at">ub =</span> <span class="cn">Inf</span>), </span>
<span id="cb65-14"><a href="#cb65-14" aria-hidden="true" tabindex="-1"></a>                        <span class="at">X =</span> <span class="fu">seq</span>(<span class="at">from =</span> x_start, <span class="at">to =</span> x_end, <span class="at">length.out =</span> n_prior_samples)) <span class="sc">|&gt;</span></span>
<span id="cb65-15"><a href="#cb65-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">prior_Pr_det =</span> purrr<span class="sc">::</span><span class="fu">pmap</span>(<span class="at">.l =</span> <span class="fu">list</span>(alpha_prior, beta_prior, X),</span>
<span id="cb65-16"><a href="#cb65-16" aria-hidden="true" tabindex="-1"></a>                                    <span class="at">.f =</span> <span class="sc">~</span><span class="fu">logistic_fun</span>(..<span class="dv">1</span>, ..<span class="dv">2</span>, ..<span class="dv">3</span>)) <span class="sc">|&gt;</span> <span class="fu">unlist</span>())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</div>
<div id="tabset-15-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-15-2-tab">
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb66"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> logistic_fun(alpha, beta, x):</span>
<span id="cb66-2"><a href="#cb66-2" aria-hidden="true" tabindex="-1"></a>  logistic_x <span class="op">=</span> np.exp(alpha <span class="op">+</span> beta <span class="op">*</span> x) <span class="op">/</span> (<span class="dv">1</span> <span class="op">+</span> np.exp(alpha <span class="op">+</span> beta <span class="op">*</span> x))</span>
<span id="cb66-3"><a href="#cb66-3" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> logistic_x</span>
<span id="cb66-4"><a href="#cb66-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-5"><a href="#cb66-5" aria-hidden="true" tabindex="-1"></a>n_prior_samples <span class="op">=</span> <span class="dv">100</span><span class="op">;</span> x_start <span class="op">=</span> <span class="dv">0</span><span class="op">;</span> x_end <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb66-6"><a href="#cb66-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-7"><a href="#cb66-7" aria-hidden="true" tabindex="-1"></a>alpha_prior <span class="op">=</span> stats.norm.rvs(loc <span class="op">=</span> <span class="op">-</span><span class="dv">3</span>, scale <span class="op">=</span> <span class="dv">1</span><span class="op">/</span><span class="dv">2</span>, size <span class="op">=</span> n_prior_samples, random_state <span class="op">=</span> <span class="dv">1234</span>)</span>
<span id="cb66-8"><a href="#cb66-8" aria-hidden="true" tabindex="-1"></a>beta_prior <span class="op">=</span> stats.truncnorm.rvs(loc <span class="op">=</span> <span class="dv">2</span>, scale <span class="op">=</span> <span class="dv">1</span>, a <span class="op">=</span> <span class="dv">0</span>, b <span class="op">=</span> math.inf, size <span class="op">=</span> n_prior_samples, random_state <span class="op">=</span> <span class="dv">1234</span>)</span>
<span id="cb66-9"><a href="#cb66-9" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.linspace(start <span class="op">=</span> x_start, stop <span class="op">=</span> x_end, num <span class="op">=</span> n_prior_samples)</span>
<span id="cb66-10"><a href="#cb66-10" aria-hidden="true" tabindex="-1"></a>prior_Pr_det <span class="op">=</span> logistic_fun(alpha_prior, beta_prior, X)</span>
<span id="cb66-11"><a href="#cb66-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-12"><a href="#cb66-12" aria-hidden="true" tabindex="-1"></a>d <span class="op">=</span> {<span class="st">'X'</span>: X, <span class="st">'alpha_prior'</span>: alpha_prior, <span class="st">'beta_prior'</span>: beta_prior, <span class="st">'prior_Pr_det'</span>: prior_Pr_det}</span>
<span id="cb66-13"><a href="#cb66-13" aria-hidden="true" tabindex="-1"></a>prior_pred_df <span class="op">=</span> pd.DataFrame(data <span class="op">=</span> d)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</div>
<div id="tabset-15-3" class="tab-pane" role="tabpanel" aria-labelledby="tabset-15-3-tab">
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb67"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a><span class="kw">function</span> <span class="fu">logistic_fun</span>(α<span class="op">::</span><span class="dt">Float64</span>, β<span class="op">::</span><span class="dt">Float64</span>, X<span class="op">::</span><span class="dt">Float64</span>)</span>
<span id="cb67-2"><a href="#cb67-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="fu">exp</span>(α <span class="op">+</span> β <span class="op">*</span> X) <span class="op">/</span> (<span class="fl">1</span> <span class="op">+</span> <span class="fu">exp</span>(α <span class="op">+</span> β <span class="op">*</span> X))</span>
<span id="cb67-3"><a href="#cb67-3" aria-hidden="true" tabindex="-1"></a><span class="kw">end</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>logistic_fun (generic function with 1 method)</code></pre>
</div>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb69"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-2"><a href="#cb69-2" aria-hidden="true" tabindex="-1"></a><span class="fu">logistic_fun</span>(<span class="op">-</span><span class="fl">3.0</span>, <span class="fl">2.0</span>, <span class="fl">1.0</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>0.2689414213699951</code></pre>
</div>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb71"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-2"><a href="#cb71-2" aria-hidden="true" tabindex="-1"></a>n_prior_samples <span class="op">=</span> <span class="fl">100</span>; x_start <span class="op">=</span> <span class="fl">0</span>; x_end <span class="op">=</span> <span class="fl">5</span>; prng <span class="op">=</span> <span class="fu">MersenneTwister</span>(<span class="fl">1234</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>MersenneTwister(1234)</code></pre>
</div>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb73"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb73-1"><a href="#cb73-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb73-2"><a href="#cb73-2" aria-hidden="true" tabindex="-1"></a>α_pr <span class="op">=</span> <span class="fu">Normal</span>(<span class="op">-</span><span class="fl">3</span>, <span class="fl">1</span><span class="op">/</span><span class="fl">2</span>); β_pr <span class="op">=</span> <span class="fu">Normal</span>(<span class="fl">2</span>, <span class="fl">1</span>); x <span class="op">=</span> <span class="fu">LinRange</span>(x_start, x_end, n_prior_samples)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>100-element LinRange{Float64, Int64}:
 0.0,0.0505051,0.10101,0.151515,0.20202,…,4.79798,4.84848,4.89899,4.94949,5.0</code></pre>
</div>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb75"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-2"><a href="#cb75-2" aria-hidden="true" tabindex="-1"></a>prior_df <span class="op">=</span> <span class="fu">DataFrame</span>(X <span class="op">=</span> x,</span>
<span id="cb75-3"><a href="#cb75-3" aria-hidden="true" tabindex="-1"></a>                     α_pr <span class="op">=</span> <span class="fu">rand</span>(prng, α_pr, n_prior_samples),</span>
<span id="cb75-4"><a href="#cb75-4" aria-hidden="true" tabindex="-1"></a>                     β_pr <span class="op">=</span> <span class="fu">rand</span>(prng, β_pr, n_prior_samples)) <span class="op">|&gt;</span></span>
<span id="cb75-5"><a href="#cb75-5" aria-hidden="true" tabindex="-1"></a>    x <span class="op">-&gt;</span> <span class="pp">@rtransform</span>(x, <span class="op">:</span>prior_Pr_det <span class="op">=</span> <span class="fu">logistic_fun</span>(<span class="op">:</span>α_pr, <span class="op">:</span>β_pr, <span class="op">:</span>X))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>100×4 DataFrame
 Row │ X          α_pr      β_pr      prior_Pr_det
     │ Float64    Float64   Float64   Float64
─────┼─────────────────────────────────────────────
   1 │ 0.0        -2.56633  2.18398      0.0713373
   2 │ 0.0505051  -3.45087  0.723652     0.0318508
   3 │ 0.10101    -3.24724  3.03132      0.0501614
   4 │ 0.151515   -3.45146  1.0892       0.0360397
   5 │ 0.20202    -2.5678   2.7546       0.11802
   6 │ 0.252525   -1.89406  0.705253     0.152391
   7 │ 0.30303    -2.73359  1.69106      0.097867
   8 │ 0.353535   -3.13587  3.30668      0.122729
  ⋮  │     ⋮         ⋮         ⋮           ⋮
  94 │ 4.69697    -2.46719  1.35593      0.98019
  95 │ 4.74747    -2.30749  0.62069      0.654576
  96 │ 4.79798    -2.96002  1.79422      0.99649
  97 │ 4.84848    -3.41668  0.776617     0.586309
  98 │ 4.89899    -3.22162  2.98073      0.999989
  99 │ 4.94949    -3.83161  2.42738      0.999721
 100 │ 5.0        -3.26061  1.50775      0.986321
                                    85 rows omitted</code></pre>
</div>
</div>
</div>
</div>
</div>
<p>The reason for sampling from the priors of the parameters is to better understand their meaning in the context of the full model. It is not necessarily intuitive to find helpful values for <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> in the above logistic function, but there will be some intuition regarding what predictions from a probability of detection model will look like.</p>
<p>For instance, the plots in <a href="#fig-prior_pred_PoD">Figure&nbsp;6</a> show how higher variance priors (on the left) and lower variance, more informative priors (on the right) compare in their associated predictions after being pushed through the model. Some features of the predictions from the more informative priors include:</p>
<ul>
<li>The probability of detection increases as the size of the damage increases.</li>
<li>There remains significant uncertainty in the predictions, which is expected to decrease as data is added to the model.</li>
</ul>
<p>This kind of graphical check, where the results are shown on an understandable outcome scale, can be used to find helpful starting points for probabilistic models.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-prior_pred_PoD" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="DCE_guidance_files/figure-html/fig-prior_pred_PoD-1.png" class="img-fluid figure-img" width="672"></p>
<p></p><figcaption class="figure-caption">Figure 6: Prior Predictive Checks for a Probability of Detection Model</figcaption><p></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="supporting-decision-making" class="level1" data-number="4">
<h1 data-number="4"><span class="header-section-number">4</span> Supporting Decision Making</h1>
<section id="existing-challenges" class="level2" data-number="4.1">
<h2 data-number="4.1" class="anchored" data-anchor-id="existing-challenges"><span class="header-section-number">4.1</span> Existing Challenges</h2>
<p>Engineering analysis, whether it is a fracture mechanics assessment, a stress analysis, or an environmental forecast is completed with the intention of supporting decision making. And yet, these calculations are often performed separately from the underlying decision problem, and by a different team.</p>
<p>This interpretation of a calculation by a decision-maker can introduce subjective judgement that is not formally reported. As a result, it may be difficult to repeatedly arrive at the same decision (conditional on the same information), or even explain how the decision was made in an audit. This message is made in the below extract, in the context of pipeline engineering:</p>
<p><q> …you don’t need anything at all! You don’t need qualified engineers, you don’t need quality systems, you don’t need risk management, you don’t need safety audits, you don’t need inspections, you don’t need training. You don’t need anything! Until something happens… then you need everything…. Got the message?</q></p>
<p><span class="citation" data-cites="Hopkins2002">(<a href="#ref-Hopkins2002" role="doc-biblioref"><strong>Hopkins2002?</strong></a>)</span></p>
<p>The reason an engineer will recommend a higher strength than their <em>best estimate</em> of what will be required is they are accounting for the consequences of their best estimate being too low. The cost of an in-service failure will generally be much greater than the additional cost in design of upgrading the strength requirements. But how much higher the decision-maker chooses to go will depend on their perception of the magnitude of the consequences of the various outcomes, and the reliability of the stress analysis i.e.&nbsp;how uncertain is the prediction.</p>
<p>A decision analysis will not remove subjectivity, since the costs of the consequences may be different, depending on who is asked, and the analysis should reflect the beliefs of the personnel responsible for making the decision. However, what decision analysis does offer is the formalisation of propagating uncertain predictions from engineering models through various possible outcomes, so that expected consequences can be quantified, and decision alternatives can be ranked, in a transparent, and replicable way.</p>
<p>The decision problems that this document focusses on, is whether or not to pay to collect some data. The method is commonly described as <em>value of information</em>, but is also often referred to as <em>pre-posterior</em> analysis in engineering textbooks <span class="citation" data-cites="Benjamin2014">Melchers and Beck (<a href="#ref-Melchers2018" role="doc-biblioref">2018</a>)</span> and some statistics textbooks too <span class="citation" data-cites="Berger">(<a href="#ref-Berger" role="doc-biblioref"><strong>Berger?</strong></a>)</span>.</p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-7-contents" aria-controls="callout-7" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Thought: The Expected Value of Data …<em>Before</em> Collecting it
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-7" class="callout-7-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>A key challenge in estimating the expected value of a prospective data collection activity, is that it is performed before the data is available to include in models - the purpose of the analysis is to help decide whether it is worth collecting.</p>
<p>Instead, the method considers all of the information that will be available at the time of making this decision. Engineers will be able to predict, with some (and perhaps a lot of!) uncertainty, what they expect the value to be. They will also know, generally from the contractor, is the quality of data that will be provided. For instance, inspection technologies are calibrated by service providers before they are brought to market, and so along with a quotation, a performance specification can be provided explaining how precise the data will be.</p>
<p>A value of information analysis uses all of this available information and, in the context of the decision problem that the data is intended to support, quantifies on a meaningful, monetary scale, the expected value of the data to the engineer.</p>
</div>
</div>
</div>
<section id="decision-event-trees" class="level3" data-number="4.1.1">
<h3 data-number="4.1.1" class="anchored" data-anchor-id="decision-event-trees"><span class="header-section-number">4.1.1</span> Decision-Event Trees</h3>
<p>Decision problems can be represented as decision-event trees, such as the example shown in <a href="#fig-example_tree">Figure&nbsp;7</a>. It is conventional for decisions to be drawn as square nodes, uncertainties as round nodes, and costs/utilities as triangle or diamond nodes.</p>
<p>In <a href="#fig-example_tree">Figure&nbsp;7</a>, two arrows are drawn from the decision node, indicating that two decision alternatives are being considered. Either <span class="math inline">\(D1\)</span> or <span class="math inline">\(D2\)</span> can be selected, but not both. The two arrows emerging from each of the uncertain nodes mean that two outcomes, <span class="math inline">\(A\)</span> or <span class="math inline">\(B\)</span>, can occur. Since these are the only outcomes, the probabilities of each of them (conditional on the decision) must sum to give <span class="math inline">\(1\)</span>, i.e.&nbsp;<span class="math inline">\(\Pr(O = A | d = D1) + \Pr(O = B | d = D1) = 1\)</span>. Each outcome has a different utility, should it occur.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-example_tree" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p>
</p><pre class="mermaid" data-tooltip-selector="#mermaid-tooltip-2">flowchart LR
  d1[Decision] -- D1 --&gt; o1((Uncertain \noutcome, \nD1))
  d1[Decision] -- D2 --&gt; o2((Uncertain \noutcome,  \nD2))
  
  o1 --O = A --&gt; c1a{Utility, \nO = A, d = D1}
  o1 --O = B --&gt; c1b{Utility, \nO = B, d = D1}
  o2 --O = A--&gt; c2a{Utility, \nO = A, d = D2}
  o2 --O = B--&gt; c2b{Utility, \nO = B, d = D2}
  
</pre>
<div id="mermaid-tooltip-2" class="mermaidTooltip">

</div>
<p></p>
<p></p><figcaption class="figure-caption">Figure 7: Example Structure of a Decision-Event Tree</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>The expected utility associated with making decision <span class="math inline">\(d1\)</span>, <span class="math inline">\(\mathbb{E}\Big[ u(d1) \Big]\)</span> can be calculated as follows:</p>
<p><span class="math display">\[
\mathbb{E}\Big[ u(d1) \Big] = \Pr(O = A) * u(O = A, d = D1) + \Pr(O = B) * u(O = B, d = D1)
\]</span></p>
<p>Here, the utilities (or costs) are being weighted by the probabilities that they will occur. The expected utility associated with making decision <span class="math inline">\(D2\)</span> can be calculated in the same way, and the expected optimal decision will be the option that has the highest expected utility, or lowest expected cost.</p>
<!-- Formally, ... -->
<!-- $$ -->
<!-- a^{*} = \arg \max_{a \in A} E \Big[ u(a, \theta) \Big] -->
<!-- $$ -->
<!-- On the basis that the expected optimal action is selected, the expected utility is $E \Big[ u(a^{*}, \theta) \Big]$. -->
</section>
<section id="graphical-models-influence-diagrams" class="level3" data-number="4.1.2">
<h3 data-number="4.1.2" class="anchored" data-anchor-id="graphical-models-influence-diagrams"><span class="header-section-number">4.1.2</span> Graphical Models (Influence Diagrams)</h3>
<p>Approximating real engineering systems using decision-event trees will require many more nodes than those presented in <a href="#fig-example_tree">Figure&nbsp;7</a>. This would lead to very large diagrams. Consequently, they are often represented more concisely, using <em>influence diagrams</em>.</p>
<p>Influence diagrams do not show every possible event path graphically (rather, these are stored as tables behind each node.) An influence diagram representation of <a href="#fig-example_tree">Figure&nbsp;7</a> is shown in <a href="#fig-example_id">Figure&nbsp;8</a>.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-example_id" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p>
</p><pre class="mermaid" data-tooltip-selector="#mermaid-tooltip-3">flowchart LR
  d1[Decision] --&gt; o1((Uncertain \noutcome))
  d1 --&gt; c1{Utility}
  o1 --&gt; c1

</pre>
<div id="mermaid-tooltip-3" class="mermaidTooltip">

</div>
<p></p>
<p></p><figcaption class="figure-caption">Figure 8: Example Structure of an Influence Diagram</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>The arrows in an influence diagram are also causal (like in a Bayesian network). The arrows in <a href="#fig-example_id">Figure&nbsp;8</a> imply that the selected decision influences the uncertain outcome, and that the utility is conditional on both of these parameters. Drawing a useful influence diagram therefore requires some knowledge of the system that it is designed to represent.</p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-8-contents" aria-controls="callout-8" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Thought: Drawing Upon Engineering Know-How
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-8" class="callout-8-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Drawing a graphical model can simply follow on, from a description of an engineering system.</p>
<p>If tasked with describing a corrosion protection system as an influence diagram, to help identify whether a data collection activity is expected to be worthwhile, it would be recommended to consult a corrosion specialist.</p>
<p>If a pipeline integrity engineer provided the following, basic information about the protection system for external corrosion of a buried pipeline:</p>
<ul>
<li>The rate of corrosion will depend on the type of soil in which the pipeline is buried, amongst other factors.</li>
<li>The primary external protective system is a protective coating, which provides a physical barrier between the steel and the soil.</li>
<li>The pipeline is also protected by a Cathodic Protection (CP) system, which helps protect any exposed steel by ensuring it is sufficiently cathodic to prevent the oxidising corrosion reaction.</li>
<li>Insufficient current from the CP system will mean that exposed steel (for example at locations of coating damage) will corrode. Excessive current can lead to disbondment of the coating from pipeline surface, meaning there may be a corrosive environment between the pipeline and the coating, which is shielded from any CP protection.</li>
<li>A Direct Current Voltage Gradient (DCVG) survey, can provide us with some information about the presence of damage in the coating.</li>
</ul>
<p>This information can be shown graphically, using the influence diagram shown in <a href="#fig-id_cr">Figure&nbsp;9</a>. This representation allows for information on any of the uncertain parameter can be propagated through the network. It also describes how decision/actions can affect specific parameters in a model (and therefore also in the outcomes of interest, i.e.&nbsp;external corrosion rate).</p>
<p>Using a model to predict how a system will respond to various interventions, as facilitated by influence diagrams, is often described as the goal of <em>digital twins</em>.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-id_cr" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p>
</p><pre class="mermaid" data-tooltip-selector="#mermaid-tooltip-4">flowchart LR
 
  dcoat[Complete \nDCVG Survey?] --&gt; coat((Coating \nCondition))
  cp((CP \nPerformance)) --&gt; corr((Corrosion \nRate))
  coat --&gt; corr
  dcoat --&gt; ccoat{DCVG \n Costs}
  
  cp --&gt; ccp{CP costs}
  cp --&gt; coat
  
  soil((Soil Type)) --&gt; corr
  corr --&gt; ccorr{Corrosion \ncosts}
  
</pre>
<div id="mermaid-tooltip-4" class="mermaidTooltip">

</div>
<p></p>
<p></p><figcaption class="figure-caption">Figure 9: Influence Diagram Showing Factors Affecting Corrosion Rate of a Buried Pipeline</figcaption><p></p>
</figure>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
</section>
<section id="example-calculations" class="level2" data-number="4.2">
<h2 data-number="4.2" class="anchored" data-anchor-id="example-calculations"><span class="header-section-number">4.2</span> Example Calculations</h2>
<section id="expected-value-of-perfect-information" class="level3" data-number="4.2.1">
<h3 data-number="4.2.1" class="anchored" data-anchor-id="expected-value-of-perfect-information"><span class="header-section-number">4.2.1</span> Expected Value of Perfect Information</h3>
<section id="energy-generation-asset-portfolio" class="level4" data-number="4.2.1.1">
<h4 data-number="4.2.1.1" class="anchored" data-anchor-id="energy-generation-asset-portfolio"><span class="header-section-number">4.2.1.1</span> Energy Generation Asset Portfolio</h4>
<p>In designing an energy system for a region, using some combination of nearshore and offshore wind, and solar. The combination (portfolio) should be selected such that the some system requirements are met, namely:</p>
<ul>
<li>The minimum annual TWhrs of generation, <span class="math inline">\(\alpha\)</span> must be met.</li>
<li>Fewer than <span class="math inline">\(\gamma\)</span> GWhrs can be dropped below the threshold of <span class="math inline">\(\beta\)</span> GW</li>
</ul>
<p>This problem is based on (normalised) power time series data for the three assets, which are read below.</p>
<div id="chunk_load_packages" class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-16-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-16-1" role="tab" aria-controls="tabset-16-1" aria-selected="true" href="">Julia (using DataFrames)</a></li></ul>
<div id="chunk_load_packages" class="tab-content">
<div id="tabset-16-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-16-1-tab">
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb77"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true" tabindex="-1"></a>power_df <span class="op">=</span> CSV.<span class="fu">File</span>(<span class="st">"data_files/power_data.csv"</span>,</span>
<span id="cb77-2"><a href="#cb77-2" aria-hidden="true" tabindex="-1"></a>                    dateformat <span class="op">=</span> <span class="st">"dd-mm-yyyy HH:MM"</span>) <span class="op">|&gt;</span></span>
<span id="cb77-3"><a href="#cb77-3" aria-hidden="true" tabindex="-1"></a>  DataFrame <span class="op">|&gt;</span> x <span class="op">-&gt;</span> <span class="fu">rename</span>(x, <span class="op">:</span>Column1 <span class="op">=&gt;</span> <span class="op">:</span>time)</span>
<span id="cb77-4"><a href="#cb77-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb77-5"><a href="#cb77-5" aria-hidden="true" tabindex="-1"></a>α <span class="op">=</span> <span class="fl">10</span>; β <span class="op">=</span> <span class="fl">2</span>; γ <span class="op">=</span> <span class="fl">1</span> <span class="op">*</span> <span class="fl">0.1</span> <span class="op">*</span> <span class="fl">24</span> <span class="op">*</span> <span class="fl">365</span></span>
<span id="cb77-6"><a href="#cb77-6" aria-hidden="true" tabindex="-1"></a>assets <span class="op">=</span> <span class="fu">names</span>(power_df)[<span class="fl">2</span><span class="op">:</span><span class="kw">end</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Viewing the first few items…</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb78"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb78-1"><a href="#cb78-1" aria-hidden="true" tabindex="-1"></a><span class="fu">first</span>(power_df, <span class="fl">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>3×4 DataFrame
 Row │ time                 solar    offshore  nearshore
     │ String31             Float64  Float64   Float64
─────┼───────────────────────────────────────────────────
   1 │ 2018-01-01 00:00:00      0.0     0.817      0.815
   2 │ 2018-01-01 01:00:00      0.0     0.886      0.831
   3 │ 2018-01-01 02:00:00      0.0     0.952      0.814</code></pre>
</div>
</div>
</div>
</div>
</div>
<p>Due to land availability, solar power can only supply either <span class="math inline">\(0\%\)</span> or <span class="math inline">\(20\%\)</span> of the total capacity. Similarly, nearshore wind can only provide either <span class="math inline">\(0\%\)</span>, <span class="math inline">\(25\%\)</span> or <span class="math inline">\(50\%\)</span>. The offshore wind asset is sufficiently flexible to be able to provide the remaining capacity. This leads to <span class="math inline">\(6\)</span> competing strategies, which can be evaluated, subject to the aforementioned constraints to identify how much power each asset is required to provide for each option.</p>
<div id="chunk_load_packages" class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-17-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-17-1" role="tab" aria-controls="tabset-17-1" aria-selected="true" href="">Julia (using JuMP, HiGHS)</a></li></ul>
<div id="chunk_load_packages" class="tab-content">
<div id="tabset-17-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-17-1-tab">
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb80"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb80-1"><a href="#cb80-1" aria-hidden="true" tabindex="-1"></a>asset_norm_power_series <span class="op">=</span> [power_df.solar; </span>
<span id="cb80-2"><a href="#cb80-2" aria-hidden="true" tabindex="-1"></a>                           power_df.offshore; </span>
<span id="cb80-3"><a href="#cb80-3" aria-hidden="true" tabindex="-1"></a>                           power_df.nearshore] <span class="op">|&gt;</span></span>
<span id="cb80-4"><a href="#cb80-4" aria-hidden="true" tabindex="-1"></a>        x <span class="op">-&gt;</span> <span class="fu">reshape</span>(x, (<span class="fu">nrow</span>(power_df), <span class="fl">3</span>)) <span class="op">|&gt;</span></span>
<span id="cb80-5"><a href="#cb80-5" aria-hidden="true" tabindex="-1"></a>        x <span class="op">-&gt;</span> <span class="fu">transpose</span>(x)</span>
<span id="cb80-6"><a href="#cb80-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-7"><a href="#cb80-7" aria-hidden="true" tabindex="-1"></a>total_energies <span class="op">=</span> <span class="fu">sum</span>(asset_norm_power_series, dims <span class="op">=</span> <span class="fl">2</span>)</span>
<span id="cb80-8"><a href="#cb80-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-9"><a href="#cb80-9" aria-hidden="true" tabindex="-1"></a>strategies <span class="op">=</span> [[<span class="fl">0</span> <span class="fl">1</span> <span class="fl">0</span>],</span>
<span id="cb80-10"><a href="#cb80-10" aria-hidden="true" tabindex="-1"></a>              [<span class="fl">0</span> <span class="fl">0.75</span> <span class="fl">0.25</span>],</span>
<span id="cb80-11"><a href="#cb80-11" aria-hidden="true" tabindex="-1"></a>              [<span class="fl">0</span> <span class="fl">0.5</span> <span class="fl">0.5</span>],</span>
<span id="cb80-12"><a href="#cb80-12" aria-hidden="true" tabindex="-1"></a>              [<span class="fl">0.2</span> <span class="fl">0.8</span> <span class="fl">0</span>],</span>
<span id="cb80-13"><a href="#cb80-13" aria-hidden="true" tabindex="-1"></a>              [<span class="fl">0.2</span> <span class="fl">0.55</span> <span class="fl">0.25</span>],</span>
<span id="cb80-14"><a href="#cb80-14" aria-hidden="true" tabindex="-1"></a>              [<span class="fl">0.2</span> <span class="fl">0.3</span> <span class="fl">0.5</span>]]</span>
<span id="cb80-15"><a href="#cb80-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-16"><a href="#cb80-16" aria-hidden="true" tabindex="-1"></a>capacities <span class="op">=</span> <span class="fu">Vector</span><span class="dt">{Float64}</span>()</span>
<span id="cb80-17"><a href="#cb80-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-18"><a href="#cb80-18" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> strategy <span class="op">∈</span> strategies</span>
<span id="cb80-19"><a href="#cb80-19" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb80-20"><a href="#cb80-20" aria-hidden="true" tabindex="-1"></a>  energy_gen <span class="op">=</span> JuMP.<span class="fu">Model</span>(HiGHS.Optimizer)</span>
<span id="cb80-21"><a href="#cb80-21" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb80-22"><a href="#cb80-22" aria-hidden="true" tabindex="-1"></a>  <span class="pp">@variable</span>(energy_gen, capacity <span class="op">&gt;=</span> <span class="fl">0</span>)</span>
<span id="cb80-23"><a href="#cb80-23" aria-hidden="true" tabindex="-1"></a>  <span class="pp">@variable</span>(energy_gen, ϕ[i <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="fu">nrow</span>(power_df)] <span class="op">&gt;=</span> <span class="fl">0</span>)</span>
<span id="cb80-24"><a href="#cb80-24" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb80-25"><a href="#cb80-25" aria-hidden="true" tabindex="-1"></a>  <span class="pp">@constraints</span>(energy_gen, <span class="cf">begin</span></span>
<span id="cb80-26"><a href="#cb80-26" aria-hidden="true" tabindex="-1"></a>               capacity <span class="op">*</span> <span class="fu">*</span>(strategy, total_energies) <span class="op">.&gt;=</span> α <span class="op">*</span> <span class="fl">24</span> <span class="op">*</span> <span class="fl">365</span></span>
<span id="cb80-27"><a href="#cb80-27" aria-hidden="true" tabindex="-1"></a>               <span class="fu">sum</span>(ϕ) <span class="op">&lt;=</span> γ</span>
<span id="cb80-28"><a href="#cb80-28" aria-hidden="true" tabindex="-1"></a>               ϕ <span class="op">.&gt;=</span> β <span class="op">.-</span> <span class="fu">transpose</span>(capacity <span class="op">*</span> <span class="fu">*</span>(strategy, asset_norm_power_series))</span>
<span id="cb80-29"><a href="#cb80-29" aria-hidden="true" tabindex="-1"></a>               <span class="cf">end</span>)</span>
<span id="cb80-30"><a href="#cb80-30" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb80-31"><a href="#cb80-31" aria-hidden="true" tabindex="-1"></a>  <span class="pp">@objective</span>(energy_gen, Min, capacity)</span>
<span id="cb80-32"><a href="#cb80-32" aria-hidden="true" tabindex="-1"></a>  <span class="fu">optimize!</span>(energy_gen)</span>
<span id="cb80-33"><a href="#cb80-33" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb80-34"><a href="#cb80-34" aria-hidden="true" tabindex="-1"></a>  <span class="fu">append!</span>(capacities, [<span class="fu">value</span>(capacity)])</span>
<span id="cb80-35"><a href="#cb80-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-36"><a href="#cb80-36" aria-hidden="true" tabindex="-1"></a><span class="cf">end</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>The results of this optimisation problem are shown below:</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb81"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb81-1"><a href="#cb81-1" aria-hidden="true" tabindex="-1"></a>nₛ <span class="op">=</span> <span class="fu">length</span>(strategies)</span>
<span id="cb81-2"><a href="#cb81-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-3"><a href="#cb81-3" aria-hidden="true" tabindex="-1"></a>energy_df <span class="op">=</span> <span class="fu">DataFrame</span>(strategy <span class="op">=</span> [i for i <span class="op">∈</span> strategies],</span>
<span id="cb81-4"><a href="#cb81-4" aria-hidden="true" tabindex="-1"></a>                      solar_GW <span class="op">=</span> [(capacities <span class="op">.*</span> strategies)[i][<span class="fl">1</span>] for i <span class="op">∈</span> <span class="fl">1</span><span class="op">:</span>nₛ],</span>
<span id="cb81-5"><a href="#cb81-5" aria-hidden="true" tabindex="-1"></a>                      offshore_GW <span class="op">=</span> [(capacities <span class="op">.*</span> strategies)[i][<span class="fl">2</span>] for i <span class="op">∈</span> <span class="fl">1</span><span class="op">:</span>nₛ],</span>
<span id="cb81-6"><a href="#cb81-6" aria-hidden="true" tabindex="-1"></a>                      nearshore_GW <span class="op">=</span> [(capacities <span class="op">.*</span> strategies)[i][<span class="fl">3</span>] for i <span class="op">∈</span> <span class="fl">1</span><span class="op">:</span>nₛ])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>6×4 DataFrame
 Row │ strategy         solar_GW  offshore_GW  nearshore_GW
     │ Array…           Float64   Float64      Float64
─────┼──────────────────────────────────────────────────────
   1 │ [0.0 1.0 0.0]     0.0         36.9407        0.0
   2 │ [0.0 0.75 0.25]   0.0         13.2866        4.42887
   3 │ [0.0 0.5 0.5]     0.0          7.83643       7.83643
   4 │ [0.2 0.8 0.0]     5.17857     20.7143        0.0
   5 │ [0.2 0.55 0.25]   2.9393       8.08308       3.67413
   6 │ [0.2 0.3 0.5]     2.77064      4.15596       6.92661</code></pre>
</div>
</div>
</div>
</div>
</div>
<p>The different options can then be evaluated using forecast costs, to identify which option is expected to minimise costs. The uncertainty in forecast costs of the different assets are described by the below probabilistic models:</p>
<p><span class="math display">\[
C_{solar} \sim N(\mu = 125 \times 10^{6}, \sigma = 25 \times 10^{6})
\]</span></p>
<p>The prior model for the cost of wind power includes a correlation between nearshore and offshore assets i.e.&nbsp;in cases where the cost of generating offshore wind power is relatively high, the cost of generating nearshore wind is also expected to be higher (and vice versa).</p>
<p>Rather than use a copula model, a multivariate normal distribution can be used, since both marginal distributions are also normal, and there is no non-linear dependency to consider.</p>
<p><span class="math display">\[
C_{wind} \sim MVN \Bigg( \mu = \begin{pmatrix} \mu_{nearshore} \\ \mu_{offshore} \end{pmatrix}, \Sigma = \begin{pmatrix} \sigma_{nearshore}^2 &amp; \rho \cdot \sigma_{nearshore} \cdot \sigma_{offshore} \\ \rho \cdot \sigma_{nearshore} \cdot \sigma_{offshore} &amp;  \sigma_{offshore}^2 \end{pmatrix} \Bigg)
\]</span></p>
<p><span class="math display">\[
\mu_{nearshore}  = 275 \times 10^{6}, \: \mu_{offshore}  = 325 \times 10^{6}
\]</span></p>
<p><span class="math display">\[
\sigma_{nearshore}  = 75 \times 10^{6}, \: \sigma_{offshore}  = 75 \times 10^{6}
\]</span></p>
<p><span class="math display">\[
\rho = 0.6
\]</span></p>
<div id="chunk" class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-18-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-18-1" role="tab" aria-controls="tabset-18-1" aria-selected="true" href="">Julia</a></li></ul>
<div id="chunk" class="tab-content">
<div id="tabset-18-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-18-1-tab">
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb83"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb83-1"><a href="#cb83-1" aria-hidden="true" tabindex="-1"></a>mean_costs <span class="op">=</span> <span class="fu">Dict</span>(<span class="st">"solar"</span> <span class="op">=&gt;</span> <span class="fl">125.0</span> <span class="op">*</span> <span class="fl">10</span><span class="op">^</span><span class="fl">6</span>, <span class="st">"offshore"</span> <span class="op">=&gt;</span> <span class="fl">325.0</span> <span class="op">*</span> <span class="fl">10</span><span class="op">^</span><span class="fl">6</span>, <span class="st">"nearshore"</span> <span class="op">=&gt;</span> <span class="fl">275.0</span> <span class="op">*</span> <span class="fl">10</span><span class="op">^</span><span class="fl">6</span>)</span>
<span id="cb83-2"><a href="#cb83-2" aria-hidden="true" tabindex="-1"></a>sd_costs <span class="op">=</span> <span class="fu">Dict</span>(<span class="st">"solar"</span> <span class="op">=&gt;</span> <span class="fl">25.0</span> <span class="op">*</span> <span class="fl">10</span><span class="op">^</span><span class="fl">6</span>, <span class="st">"offshore"</span> <span class="op">=&gt;</span> <span class="fl">75.0</span> <span class="op">*</span> <span class="fl">10</span><span class="op">^</span><span class="fl">6</span>, <span class="st">"nearshore"</span> <span class="op">=&gt;</span> <span class="fl">75.0</span> <span class="op">*</span> <span class="fl">10</span><span class="op">^</span><span class="fl">6</span>)</span>
<span id="cb83-3"><a href="#cb83-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-4"><a href="#cb83-4" aria-hidden="true" tabindex="-1"></a><span class="kw">function</span> <span class="fu">get_prior_decision</span>(;input_df<span class="op">::</span><span class="dt">DataFrame</span>, mean_costs <span class="op">=</span> mean_costs)</span>
<span id="cb83-5"><a href="#cb83-5" aria-hidden="true" tabindex="-1"></a>  power_df <span class="op">=</span> input_df[!, <span class="fu">names</span>(input_df, <span class="dt">Float64</span>)]</span>
<span id="cb83-6"><a href="#cb83-6" aria-hidden="true" tabindex="-1"></a>  expected_costs <span class="op">=</span> <span class="fu">Vector</span><span class="dt">{Float64}</span>()</span>
<span id="cb83-7"><a href="#cb83-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-8"><a href="#cb83-8" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> row <span class="kw">in</span> <span class="fu">eachrow</span>(power_df)</span>
<span id="cb83-9"><a href="#cb83-9" aria-hidden="true" tabindex="-1"></a>    <span class="fu">append!</span>(expected_costs, <span class="fu">Vector</span><span class="dt">{Any}</span>(row) <span class="op">.*</span> [<span class="fu">get</span>(mean_costs, i, <span class="st">"unknown"</span>) for i <span class="kw">in</span> assets] <span class="op">|&gt;</span> x <span class="op">-&gt;</span> <span class="fu">sum</span>(x))</span>
<span id="cb83-10"><a href="#cb83-10" aria-hidden="true" tabindex="-1"></a>  <span class="cf">end</span></span>
<span id="cb83-11"><a href="#cb83-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-12"><a href="#cb83-12" aria-hidden="true" tabindex="-1"></a>  input_df[!, <span class="op">:</span>prior_costs] <span class="op">=</span> expected_costs</span>
<span id="cb83-13"><a href="#cb83-13" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb83-14"><a href="#cb83-14" aria-hidden="true" tabindex="-1"></a>  minimum_prior_cost <span class="op">=</span> <span class="fu">minimum</span>(input_df.prior_costs)</span>
<span id="cb83-15"><a href="#cb83-15" aria-hidden="true" tabindex="-1"></a>  prior_df <span class="op">=</span> <span class="pp">@subset</span>(input_df, <span class="op">:</span>prior_costs <span class="op">.==</span> minimum_prior_cost)</span>
<span id="cb83-16"><a href="#cb83-16" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb83-17"><a href="#cb83-17" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span>(prior_df)</span>
<span id="cb83-18"><a href="#cb83-18" aria-hidden="true" tabindex="-1"></a><span class="kw">end</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>The result is shown below:</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>1×5 DataFrame
 Row │ strategy       solar_GW  offshore_GW  nearshore_GW  prior_costs
     │ Array…         Float64   Float64      Float64       Float64
─────┼─────────────────────────────────────────────────────────────────
   1 │ [0.2 0.3 0.5]   2.77064      4.15596       6.92661    3.60184e9</code></pre>
</div>
</div>
</div>
</div>
</div>
<p>If forecasting models could be improved, so that the uncertainty could be removed, what would this mean for the expected cost of delivering the identified strategies? This question can be answered using a value of information analysis.</p>
<p>In this case, this is achieved by sampling from the prior distributions of costs. Here each sample provides an imagined result of a study to identify the costs more precisely. For each result the expected optimal strategy (and associated cost) is evaluated, and an average of the samples are required, to account for the various possible results of the study.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-prepost_id_energy_portfolio" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p>
</p><pre class="mermaid" data-tooltip-selector="#mermaid-tooltip-5">flowchart LR
  d0[System \ndesign] --&gt; ons((Nearshore wind \ngeneration))
  d0[System \ndesign] --&gt; oos((Offshore wind \ngeneration))
  d0[System \ndesign] --&gt; os((Solar \ngeneration))

  ons --&gt; c_s
  oos --&gt; c_s
  os --&gt; c_s 

  d1[Forecast \nmodel] --&gt; ec((Energy \nprices))
  ec --&gt; c_s{Implementation \ncosts}

  d1 --&gt; c_m{Modelling \ncosts}

</pre>
<div id="mermaid-tooltip-5" class="mermaidTooltip">

</div>
<p></p>
<p></p><figcaption class="figure-caption">Figure 10: Influence Diagram for Estimating the Expected Value of an Energy Forecasting Model</figcaption><p></p>
</figure>
</div>
</div>
</div>
<div id="chunk_load_packages" class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-19-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-19-1" role="tab" aria-controls="tabset-19-1" aria-selected="true" href="">Julia</a></li></ul>
<div id="chunk_load_packages" class="tab-content">
<div id="tabset-19-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-19-1-tab">
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb85"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb85-1"><a href="#cb85-1" aria-hidden="true" tabindex="-1"></a><span class="kw">function</span> <span class="fu">cov_mat_3_params</span>(sd_costs<span class="op">::</span><span class="dt">Vector{Float64}</span>, ρ<span class="op">::</span><span class="dt">Vector{Float64}</span>)</span>
<span id="cb85-2"><a href="#cb85-2" aria-hidden="true" tabindex="-1"></a>    C <span class="op">=</span> [sd_costs[<span class="fl">1</span>]<span class="op">^</span><span class="fl">2</span> ρ[<span class="fl">1</span>]<span class="op">*</span>sd_costs[<span class="fl">1</span>]<span class="op">*</span>sd_costs[<span class="fl">2</span>] ρ[<span class="fl">2</span>]<span class="op">*</span>sd_costs[<span class="fl">1</span>]<span class="op">*</span>sd_costs[<span class="fl">3</span>];</span>
<span id="cb85-3"><a href="#cb85-3" aria-hidden="true" tabindex="-1"></a>        ρ[<span class="fl">1</span>]<span class="op">*</span>sd_costs[<span class="fl">1</span>]<span class="op">*</span>sd_costs[<span class="fl">2</span>] sd_costs[<span class="fl">2</span>]<span class="op">^</span><span class="fl">2</span>  ρ[<span class="fl">3</span>]<span class="op">*</span>sd_costs[<span class="fl">3</span>]<span class="op">*</span>sd_costs[<span class="fl">3</span>];</span>
<span id="cb85-4"><a href="#cb85-4" aria-hidden="true" tabindex="-1"></a>        ρ[<span class="fl">2</span>]<span class="op">*</span>sd_costs[<span class="fl">1</span>]<span class="op">*</span>sd_costs[<span class="fl">3</span>] ρ[<span class="fl">3</span>]<span class="op">*</span>sd_costs[<span class="fl">3</span>]<span class="op">*</span>sd_costs[<span class="fl">3</span>] sd_costs[<span class="fl">3</span>]<span class="op">^</span><span class="fl">2</span>]</span>
<span id="cb85-5"><a href="#cb85-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> C</span>
<span id="cb85-6"><a href="#cb85-6" aria-hidden="true" tabindex="-1"></a><span class="kw">end</span></span>
<span id="cb85-7"><a href="#cb85-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb85-8"><a href="#cb85-8" aria-hidden="true" tabindex="-1"></a>prng <span class="op">=</span> <span class="fu">MersenneTwister</span>(<span class="fl">1234</span>)</span>
<span id="cb85-9"><a href="#cb85-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb85-10"><a href="#cb85-10" aria-hidden="true" tabindex="-1"></a><span class="kw">function</span> <span class="fu">get_prepost_decision</span>(;input_df<span class="op">::</span><span class="dt">DataFrame</span>, n_samples<span class="op">::</span><span class="dt">Int64</span>, mean_costs <span class="op">=</span> mean_costs, sd_costs <span class="op">=</span> sd_costs, ρ <span class="op">=</span> [<span class="fl">0</span>, <span class="fl">0</span>, <span class="fl">0.6</span>])</span>
<span id="cb85-11"><a href="#cb85-11" aria-hidden="true" tabindex="-1"></a>  power_df <span class="op">=</span> input_df[!, <span class="fu">names</span>(input_df, <span class="dt">Float64</span>)]</span>
<span id="cb85-12"><a href="#cb85-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb85-13"><a href="#cb85-13" aria-hidden="true" tabindex="-1"></a>  costs <span class="op">=</span> <span class="fu">MvNormal</span>([<span class="fu">get</span>(mean_costs, i, <span class="st">"unknown"</span>) for i <span class="kw">in</span> assets], </span>
<span id="cb85-14"><a href="#cb85-14" aria-hidden="true" tabindex="-1"></a>                 <span class="fu">cov_mat_3_params</span>([<span class="fu">get</span>(sd_costs, i, <span class="st">"unknown"</span>) for i <span class="kw">in</span> assets], ρ)) <span class="op">|&gt;</span></span>
<span id="cb85-15"><a href="#cb85-15" aria-hidden="true" tabindex="-1"></a>    x <span class="op">-&gt;</span> <span class="fu">rand</span>(prng, x, n_samples)</span>
<span id="cb85-16"><a href="#cb85-16" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb85-17"><a href="#cb85-17" aria-hidden="true" tabindex="-1"></a>  expected_costs <span class="op">=</span>  <span class="dt">Array</span>{<span class="dt">Float64</span>}[] <span class="op">|&gt;</span> x <span class="op">-&gt;</span> <span class="fu">reshape</span>(x, n_samples, <span class="fl">0</span>)</span>
<span id="cb85-18"><a href="#cb85-18" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb85-19"><a href="#cb85-19" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> row <span class="kw">in</span> <span class="fu">eachrow</span>(power_df)</span>
<span id="cb85-20"><a href="#cb85-20" aria-hidden="true" tabindex="-1"></a>    expected_costs <span class="op">=</span> <span class="fu">hcat</span>(expected_costs,</span>
<span id="cb85-21"><a href="#cb85-21" aria-hidden="true" tabindex="-1"></a>                          <span class="fu">*</span>(<span class="fu">Vector</span><span class="dt">{Float64}</span>(row) <span class="op">|&gt;</span> x <span class="op">-&gt;</span> <span class="fu">transpose</span>(x),</span>
<span id="cb85-22"><a href="#cb85-22" aria-hidden="true" tabindex="-1"></a>                          costs) <span class="op">|&gt;</span> x <span class="op">-&gt;</span> <span class="fu">transpose</span>(x))</span>
<span id="cb85-23"><a href="#cb85-23" aria-hidden="true" tabindex="-1"></a>  <span class="cf">end</span></span>
<span id="cb85-24"><a href="#cb85-24" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb85-25"><a href="#cb85-25" aria-hidden="true" tabindex="-1"></a>  prepost_df <span class="op">=</span> <span class="fu">DataFrame</span>(strat_opt <span class="op">=</span> <span class="dt">Int</span>[], exp_cost <span class="op">=</span> <span class="dt">Float64</span>[])</span>
<span id="cb85-26"><a href="#cb85-26" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb85-27"><a href="#cb85-27" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> i <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="fu">size</span>(expected_costs)[<span class="fl">1</span>]</span>
<span id="cb85-28"><a href="#cb85-28" aria-hidden="true" tabindex="-1"></a>      <span class="fu">append!</span>(prepost_df, </span>
<span id="cb85-29"><a href="#cb85-29" aria-hidden="true" tabindex="-1"></a>              <span class="fu">DataFrame</span>(strat_opt <span class="op">=</span> <span class="fu">argmin</span>(expected_costs[i, <span class="op">:</span>]),</span>
<span id="cb85-30"><a href="#cb85-30" aria-hidden="true" tabindex="-1"></a>                        exp_cost <span class="op">=</span> <span class="fu">minimum</span>(expected_costs[i, <span class="op">:</span>])))</span>
<span id="cb85-31"><a href="#cb85-31" aria-hidden="true" tabindex="-1"></a>  <span class="cf">end</span></span>
<span id="cb85-32"><a href="#cb85-32" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb85-33"><a href="#cb85-33" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span>(prepost_df)</span>
<span id="cb85-34"><a href="#cb85-34" aria-hidden="true" tabindex="-1"></a><span class="kw">end</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</div>
</div>
</div>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>100000×2 DataFrame
    Row │ strat_opt  exp_cost
        │ Int64      Float64
────────┼──────────────────────
      1 │         6  2.89427e9
      2 │         6  4.99741e9
      3 │         6  3.67811e9
      4 │         6  3.20859e9
      5 │         6  4.4217e9
      6 │         6  3.60653e9
      7 │         5  3.19492e9
      8 │         6  3.7343e9
   ⋮    │     ⋮          ⋮
  99994 │         6  3.78243e9
  99995 │         5  3.28909e9
  99996 │         6  4.31482e9
  99997 │         6  4.99683e9
  99998 │         6  2.86975e9
  99999 │         6  4.40865e9
 100000 │         5  3.29687e9
             99985 rows omitted</code></pre>
</div>
</div>
<p>Again, the expected value of perfect information is the difference between the expected prior and preposterior costs. In this case, it is estimated to be just over two million pounds:</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb87"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb87-1"><a href="#cb87-1" aria-hidden="true" tabindex="-1"></a>VoI <span class="op">=</span> prior_decision_df.prior_costs[<span class="fl">1</span>] <span class="op">.-</span> <span class="fu">mean</span>(prepost_decision_df.exp_cost)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb88"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb88-1"><a href="#cb88-1" aria-hidden="true" tabindex="-1"></a><span class="pp">@printf</span> <span class="st">"VoPI = GBP %.6e"</span> VoI</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>VoPI = GBP 2.020935e+06</code></pre>
</div>
</div>
<p>Recall that this represents the expected value of removing uncertainty in forecasting electricity generation costs for various technologies. It can therefore be interpreted as (an upper-bound estimate of) how much the project should be willing to invest in improving modelling of cost forecasting.</p>
<p>For the near-term planning of energy system asset development, the calculated expected value of perfect cost forecasting can inform the decision maker whether it is financially worthwhile to undertake an initial asset development contracting process, such as a <em>contract for difference auction</em>, prior to the design of the energy system. Such a contracting process would provide the system designer with exact information on the cost of the assets that would be developed, via the clearing price of the auction to which the developers agree, after which an informed decision on the optimal system design could be made, but would incur a significant time and administrative cost. For the long-term planning of future energy systems, this analysis can be used to determine whether and to what extent Research and Development (R&amp;D) and the purchase of expert opinion on future asset costs (either internal or contracted) should be used to assist the creation of energy system development strategies.</p>
<p>However, neither R&amp;D or the expert opinions of consultants provide perfect information on future costs, and determining models for their efficacy is required to identify a more realistic expected value of imperfect information, which will be lower than the value predicted here. This challenge is discussed in a different context in the below example.</p>
<!-- Therefore, a system designer will not be willing to pay the full EVPI for such improvements in the estimation of future costs, though if the EVPI is sufficiently large it may provide justification for taking such actions nonetheless. For these 'measurement actions' the EVPI may be used to assist a more qualitative judgement on their economic suitability. Though, expenditure on R&D projects also has the potential to reduce the future costs of renewable generation assets, providing additional advantage. -->
</section>
</section>
<section id="sensitivity-analysis-influence-of-prior-knowledge" class="level3" data-number="4.2.2">
<h3 data-number="4.2.2" class="anchored" data-anchor-id="sensitivity-analysis-influence-of-prior-knowledge"><span class="header-section-number">4.2.2</span> Sensitivity Analysis: Influence of Prior Knowledge</h3>
<section id="example-energy-use-in-buildings" class="level4" data-number="4.2.2.1">
<h4 data-number="4.2.2.1" class="anchored" data-anchor-id="example-energy-use-in-buildings"><span class="header-section-number">4.2.2.1</span> Example: Energy Use in Buildings</h4>
<p>Consider the problem of heating a residential building. Inefficiencies in ageing heaters can result in increased electricity costs to deliver energy requirements. This performance degradation can be mitigated by maintenance work.</p>
<p>The problem is described by the influence diagram in <a href="#fig-prior_id_heat_pumps">Figure&nbsp;11</a>. Here, heat pump parameters, <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> describe the degradation and improvements to the performance of a heat pump, respectively.</p>
<p>Heat pump efficiency, characterised by a Seasonal Performance Factor (SPF), is calculated based on how the system degrades with age (using <span class="math inline">\(\alpha\)</span>), and how maintenance activities can improve, or restore, the performance (using <span class="math inline">\(\beta\)</span>).</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-prior_id_heat_pumps" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p>
</p><pre class="mermaid" data-tooltip-selector="#mermaid-tooltip-6">flowchart LR
  d2[Maintenance \nfrequency] --&gt; o2((SPF))

  o0((Heating \nload)) --&gt; o1((SPF))
  o2(("#946;")) --&gt; o1((SPF))
  o3(("#945;")) --&gt; o1((SPF))

  o1 --&gt; c1{Electricity \ncost}
  d2 --&gt; c2{Maintenance \n cost}

</pre>
<div id="mermaid-tooltip-6" class="mermaidTooltip">

</div>
<p></p>
<p></p><figcaption class="figure-caption">Figure 11: Influence Diagram for Identifying Expected Optimal Maintenance Schedule of Heating System</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>The model that will be used is as follows:</p>
<p><span class="math display">\[
\beta = \frac{\beta_{A} * N_{m}^\gamma}{\beta_{B} + N_{m}^{\gamma}}
\]</span></p>
<p><span class="math display">\[
\alpha \sim N(\mu = 1.6 \times 10^{-2}, \sigma = 1.6 \times 10^{-3})
\]</span></p>
<p>Where: <span class="math inline">\(\beta_{A} = 0.05\)</span>, <span class="math inline">\(\beta_{B} = 2.5\)</span>, and <span class="math inline">\(\gamma = 1.4\)</span>. The cost of a heat pump is taken to be £<span class="math inline">\(110472.50\)</span>, and the cost of maintenance is equal to <span class="math inline">\(1\)</span>% of this cost, multiplied by the number of activities, <span class="math inline">\(N_{m}\)</span>.</p>
<p>The cost of electricity for the system, <span class="math inline">\(C_{e}\)</span> is calculated, using the heating load in kWh, <span class="math inline">\(L_{H}\)</span>, the price per kWh, in GBP <span class="math inline">\(p_{e}\)</span>, and the SPF:</p>
<p><span class="math display">\[
C_{e} = \frac{L_{H} \times p_{e}}{SPF}
\]</span></p>
<p>The inputs for the problem are defined below. These result in a decreasing efficacy of maintenance activities, when many are scheduled, see <a href="#fig-n_maint_beta">Figure&nbsp;12</a>.</p>
<div id="chunk_load_packages" class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-20-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-20-1" role="tab" aria-controls="tabset-20-1" aria-selected="true" href="">R</a></li></ul>
<div id="chunk_load_packages" class="tab-content">
<div id="tabset-20-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-20-1-tab">
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb90"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb90-1"><a href="#cb90-1" aria-hidden="true" tabindex="-1"></a>get_beta <span class="ot">&lt;-</span> <span class="cf">function</span>(n_maintenance){</span>
<span id="cb90-2"><a href="#cb90-2" aria-hidden="true" tabindex="-1"></a>  a <span class="ot">&lt;-</span> <span class="fl">0.05</span>; b <span class="ot">&lt;-</span> <span class="fl">2.5</span>; gamma <span class="ot">&lt;-</span> <span class="fl">1.4</span></span>
<span id="cb90-3"><a href="#cb90-3" aria-hidden="true" tabindex="-1"></a>  <span class="co"># a &lt;- 1/4; gamma &lt;- 2; b &lt;- 10</span></span>
<span id="cb90-4"><a href="#cb90-4" aria-hidden="true" tabindex="-1"></a>  (a <span class="sc">*</span> n_maintenance<span class="sc">^</span>gamma) <span class="sc">/</span> (b <span class="sc">+</span> n_maintenance<span class="sc">^</span>gamma)</span>
<span id="cb90-5"><a href="#cb90-5" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb90-6"><a href="#cb90-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb90-7"><a href="#cb90-7" aria-hidden="true" tabindex="-1"></a>n_samples <span class="ot">&lt;-</span> <span class="fl">1e3</span>; alpha <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="at">n =</span> n_samples, <span class="at">mean =</span> <span class="fl">1.6e-2</span>, <span class="at">sd =</span> <span class="fl">1.6e-3</span>)</span>
<span id="cb90-8"><a href="#cb90-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb90-9"><a href="#cb90-9" aria-hidden="true" tabindex="-1"></a>SPF_initial <span class="ot">&lt;-</span> <span class="dv">3</span></span>
<span id="cb90-10"><a href="#cb90-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb90-11"><a href="#cb90-11" aria-hidden="true" tabindex="-1"></a>max_n_maint <span class="ot">&lt;-</span> <span class="dv">12</span>; n_maint <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">0</span>, <span class="at">to =</span> max_n_maint, <span class="at">by =</span> <span class="dv">1</span>)</span>
<span id="cb90-12"><a href="#cb90-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb90-13"><a href="#cb90-13" aria-hidden="true" tabindex="-1"></a>heat_pump_cost_GBP <span class="ot">&lt;-</span> <span class="dv">441890</span><span class="sc">/</span><span class="dv">4</span>; heating_load_kWh <span class="ot">&lt;-</span> <span class="dv">1753914</span>; GBP_per_kWh <span class="ot">&lt;-</span> <span class="fl">0.51</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</div>
</div>
</div>
<div class="cell">
<div class="cell-output-display">
<div id="fig-n_maint_beta" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="DCE_guidance_files/figure-html/fig-n_maint_beta-1.png" class="img-fluid figure-img" width="672"></p>
<p></p><figcaption class="figure-caption">Figure 12: Effect of Increasing Number of Scheduled Maintenance Activities on Heat Pump Performance Improvement Factor</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>As shown in <a href="#fig-prior_heat_pump_decision">Figure&nbsp;13</a>, increasing the number of maintenance activities initially decreases the total cost (sum of electricity and maintenance costs), before no longer expecting to be worthwhile.</p>
<div class="cell">

</div>
<div id="chunk_load_packages" class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-21-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-21-1" role="tab" aria-controls="tabset-21-1" aria-selected="true" href="">R (using purrr)</a></li></ul>
<div id="chunk_load_packages" class="tab-content">
<div id="tabset-21-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-21-1-tab">
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb91"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb91-1"><a href="#cb91-1" aria-hidden="true" tabindex="-1"></a>prior_decision_df <span class="ot">&lt;-</span> <span class="cf">function</span>(n_maint_range){</span>
<span id="cb91-2"><a href="#cb91-2" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb91-3"><a href="#cb91-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tibble</span>(<span class="at">n_maint =</span> n_maint_range, <span class="at">alpha =</span> <span class="fu">list</span>(alpha)) <span class="sc">|&gt;</span></span>
<span id="cb91-4"><a href="#cb91-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">beta =</span> <span class="fu">get_beta</span>(<span class="at">n_maintenance =</span> n_maint),</span>
<span id="cb91-5"><a href="#cb91-5" aria-hidden="true" tabindex="-1"></a>         <span class="at">SPF =</span> SPF_initial,</span>
<span id="cb91-6"><a href="#cb91-6" aria-hidden="true" tabindex="-1"></a>         <span class="at">maint_cost =</span> n_maint <span class="sc">*</span> heat_pump_cost_GBP <span class="sc">*</span> <span class="fl">3e-2</span>,</span>
<span id="cb91-7"><a href="#cb91-7" aria-hidden="true" tabindex="-1"></a>         <span class="at">SPF_coeff =</span> <span class="fu">map2</span>(<span class="at">.x =</span> alpha, <span class="at">.y =</span> beta,</span>
<span id="cb91-8"><a href="#cb91-8" aria-hidden="true" tabindex="-1"></a>                          <span class="at">.f =</span> <span class="cf">function</span>(.x, .y){(<span class="dv">1</span> <span class="sc">-</span> .x) <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">+</span> .y)}),</span>
<span id="cb91-9"><a href="#cb91-9" aria-hidden="true" tabindex="-1"></a>         <span class="at">SPF =</span> <span class="fu">map2</span>(<span class="at">.x =</span> SPF, <span class="at">.y =</span> SPF_coeff,</span>
<span id="cb91-10"><a href="#cb91-10" aria-hidden="true" tabindex="-1"></a>                    <span class="at">.f =</span> <span class="cf">function</span>(.x, .y){<span class="fu">lag</span>(<span class="at">x =</span> .x, <span class="at">n =</span> <span class="dv">1</span>, <span class="at">default =</span> SPF_initial) <span class="sc">*</span> .y}),</span>
<span id="cb91-11"><a href="#cb91-11" aria-hidden="true" tabindex="-1"></a>         <span class="at">elec_cost =</span> <span class="fu">map</span>(<span class="at">.x =</span> SPF,</span>
<span id="cb91-12"><a href="#cb91-12" aria-hidden="true" tabindex="-1"></a>                         <span class="at">.f =</span> <span class="cf">function</span>(.x){GBP_per_kWh <span class="sc">*</span> heating_load_kWh <span class="sc">/</span> .x}),</span>
<span id="cb91-13"><a href="#cb91-13" aria-hidden="true" tabindex="-1"></a>         <span class="at">total_cost =</span> <span class="fu">map2</span>(<span class="at">.x =</span> elec_cost, <span class="at">.y =</span> maint_cost,</span>
<span id="cb91-14"><a href="#cb91-14" aria-hidden="true" tabindex="-1"></a>                           <span class="at">.f =</span> <span class="cf">function</span>(.x, .y){ .x <span class="sc">+</span> .y})) <span class="sc">|&gt;</span> </span>
<span id="cb91-15"><a href="#cb91-15" aria-hidden="true" tabindex="-1"></a>    <span class="fu">group_by</span>(n_maint) <span class="sc">|&gt;</span></span>
<span id="cb91-16"><a href="#cb91-16" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">exp_cost =</span> <span class="fu">mean</span>(<span class="fu">unlist</span>(total_cost))) <span class="sc">|&gt;</span></span>
<span id="cb91-17"><a href="#cb91-17" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ungroup</span>()</span>
<span id="cb91-18"><a href="#cb91-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb91-19"><a href="#cb91-19" aria-hidden="true" tabindex="-1"></a>  }</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</div>
</div>
</div>
<div class="cell">
<div class="cell-output-display">
<div id="fig-prior_heat_pump_decision" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="DCE_guidance_files/figure-html/fig-prior_heat_pump_decision-1.png" class="img-fluid figure-img" width="672"></p>
<p></p><figcaption class="figure-caption">Figure 13: Identification of Number of Expected Optimal Heat Pump Maintenance Activities</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>The expected optimal number of maintenance activities to schedule (that which is associated with the lowest expected cost) is 2, with an associated expected cost of £3.02^{5}.</p>
<p>How can a smart meter assist in solving this decision problem? As shown in <a href="#fig-prepost_id_heat_pumps">Figure&nbsp;14</a>, the data that a smart meter provides can be used to reduce uncertainty about the degradation parameter, <span class="math inline">\(\alpha\)</span>.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-prepost_id_heat_pumps" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p>
</p><pre class="mermaid" data-tooltip-selector="#mermaid-tooltip-7">flowchart LR
  d2[Maintenance \nfrequency] --&gt; o2((SPF))
  
  o4((Electical \nload)) --&gt; o3(("#945;"))

  o2(("#946;")) --&gt; o1((SPF))
  o3 --&gt; o1((SPF))
  o0((Heating \nload)) --&gt; o3

  o1 --&gt; c1{Electricity \ncost}
  d2 --&gt; c2{Maintenance \ncost}

  d3[Smart \nmeter] --&gt; c3{Meter \ncost}
  d3 --&gt; o4

</pre>
<div id="mermaid-tooltip-7" class="mermaidTooltip">

</div>
<p></p>
<p></p><figcaption class="figure-caption">Figure 14: Influence Diagram for Estimating the Expected Value of Smart Meters</figcaption><p></p>
</figure>
</div>
</div>
</div>
<div id="chunk_load_packages" class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-22-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-22-1" role="tab" aria-controls="tabset-22-1" aria-selected="true" href="">R (using purrr)</a></li></ul>
<div id="chunk_load_packages" class="tab-content">
<div id="tabset-22-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-22-1-tab">
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb92"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb92-1"><a href="#cb92-1" aria-hidden="true" tabindex="-1"></a>prepost_decision_df <span class="ot">&lt;-</span> <span class="cf">function</span>(n_maint_range){</span>
<span id="cb92-2"><a href="#cb92-2" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb92-3"><a href="#cb92-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tibble</span>(<span class="at">alpha =</span> alpha, <span class="at">n_maint =</span> <span class="fu">list</span>(n_maint_range)) <span class="sc">|&gt;</span></span>
<span id="cb92-4"><a href="#cb92-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">beta =</span> <span class="fu">map</span>(<span class="at">.x =</span> n_maint, </span>
<span id="cb92-5"><a href="#cb92-5" aria-hidden="true" tabindex="-1"></a>                    <span class="at">.f =</span> <span class="cf">function</span>(.x){<span class="fu">get_beta</span>(.x)}),</span>
<span id="cb92-6"><a href="#cb92-6" aria-hidden="true" tabindex="-1"></a>         <span class="at">SPF =</span> SPF_initial,</span>
<span id="cb92-7"><a href="#cb92-7" aria-hidden="true" tabindex="-1"></a>         <span class="at">maint_cost =</span> <span class="fu">map</span>(<span class="at">.x =</span> n_maint,</span>
<span id="cb92-8"><a href="#cb92-8" aria-hidden="true" tabindex="-1"></a>                          <span class="at">.f =</span> <span class="cf">function</span>(.x) {.x <span class="sc">*</span> heat_pump_cost_GBP <span class="sc">*</span> <span class="fl">1e-2</span>}),</span>
<span id="cb92-9"><a href="#cb92-9" aria-hidden="true" tabindex="-1"></a>         <span class="at">SPF_coeff =</span> <span class="fu">map2</span>(<span class="at">.x =</span> alpha, <span class="at">.y =</span> beta,</span>
<span id="cb92-10"><a href="#cb92-10" aria-hidden="true" tabindex="-1"></a>                          <span class="at">.f =</span> <span class="cf">function</span>(.x, .y){(<span class="dv">1</span> <span class="sc">-</span> .x) <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">+</span> .y)}),</span>
<span id="cb92-11"><a href="#cb92-11" aria-hidden="true" tabindex="-1"></a>         <span class="at">SPF =</span> <span class="fu">map2</span>(<span class="at">.x =</span> SPF, <span class="at">.y =</span> SPF_coeff,</span>
<span id="cb92-12"><a href="#cb92-12" aria-hidden="true" tabindex="-1"></a>                    <span class="at">.f =</span> <span class="cf">function</span>(.x, .y){</span>
<span id="cb92-13"><a href="#cb92-13" aria-hidden="true" tabindex="-1"></a>                      <span class="fu">lag</span>(<span class="at">x =</span> .x, <span class="at">n =</span> <span class="dv">1</span>, <span class="at">default =</span> SPF_initial) <span class="sc">*</span> .y}),</span>
<span id="cb92-14"><a href="#cb92-14" aria-hidden="true" tabindex="-1"></a>         <span class="at">elec_cost =</span> <span class="fu">map</span>(<span class="at">.x =</span> SPF,</span>
<span id="cb92-15"><a href="#cb92-15" aria-hidden="true" tabindex="-1"></a>                         <span class="at">.f =</span> <span class="cf">function</span>(.x){GBP_per_kWh <span class="sc">*</span> heating_load_kWh <span class="sc">/</span> .x}),</span>
<span id="cb92-16"><a href="#cb92-16" aria-hidden="true" tabindex="-1"></a>         <span class="at">total_cost =</span> <span class="fu">map2</span>(<span class="at">.x =</span> elec_cost, <span class="at">.y =</span> maint_cost,</span>
<span id="cb92-17"><a href="#cb92-17" aria-hidden="true" tabindex="-1"></a>                           <span class="at">.f =</span> <span class="cf">function</span>(.x, .y){ .x <span class="sc">+</span> .y})) <span class="sc">|&gt;</span></span>
<span id="cb92-18"><a href="#cb92-18" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">exp_cost =</span> <span class="fu">map</span>(<span class="at">.x =</span> total_cost, </span>
<span id="cb92-19"><a href="#cb92-19" aria-hidden="true" tabindex="-1"></a>                          <span class="at">.f =</span> <span class="cf">function</span>(.x) {<span class="fu">min</span>(<span class="fu">unlist</span>(.x))}),</span>
<span id="cb92-20"><a href="#cb92-20" aria-hidden="true" tabindex="-1"></a>           <span class="at">exp_cost =</span> <span class="fu">unlist</span>(exp_cost))</span>
<span id="cb92-21"><a href="#cb92-21" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</div>
</div>
</div>
<div class="cell">

</div>
<p>In <a href="#fig-voi_smart_meter_alpha_sensitivity">Figure&nbsp;15</a> the effect of the prior variance on <span class="math inline">\(\alpha\)</span> is shown. Moving from left to right along the x-axis indicates an increase in prior uncertainty about how the heat pumps will degrade. The less well this is known, the more value there is expected to be in collecting data from a smart meter.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-voi_smart_meter_alpha_sensitivity" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="DCE_guidance_files/figure-html/fig-voi_smart_meter_alpha_sensitivity-1.png" class="img-fluid figure-img" width="672"></p>
<p></p><figcaption class="figure-caption">Figure 15: Effect of Prior Uncertainty on Expected Value of Smart Meter Data</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>The above examples have used bespoke code to represent the decision that needed to be solved. Though this can be helpful for prototyping initial calculations, small changes to the problem may require large amounts of code to be re-written.</p>
</section>
</section>
<section id="influence-diagram-representation" class="level3" data-number="4.2.3">
<h3 data-number="4.2.3" class="anchored" data-anchor-id="influence-diagram-representation"><span class="header-section-number">4.2.3</span> Influence Diagram Representation</h3>
<section id="example-a-measuring-temperature-for-forecasting-crop-sales" class="level4" data-number="4.2.3.1">
<h4 data-number="4.2.3.1" class="anchored" data-anchor-id="example-a-measuring-temperature-for-forecasting-crop-sales"><span class="header-section-number">4.2.3.1</span> Example A: Measuring Temperature for Forecasting Crop Sales</h4>
<p>An environment for growing various produce, such as the underground farm project <span class="citation" data-cites="Ward2022">(<a href="#ref-Ward2022" role="doc-biblioref"><strong>Ward2022?</strong></a>)</span>, requires monitoring of features that will impact crop survival. Being able to forecast availability of crops is important when agreeing future sales.</p>
<p>In this challenge, a buyer is willing to purchase at one of multiple levels. In response, the operator can agree to sell at one of these levels (earning payment for sufficient delivery, or paying a penalty if insufficient crops are available), or to not engage with the market at this time (at no risk, with no reward).</p>
<p>A model predicting crop availability from the local temperature can be linked to this decision making under uncertainty problem, as shown in the influence diagram in <a href="#fig-prior_id_farm">Figure&nbsp;16</a>.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-prior_id_farm" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p>
</p><pre class="mermaid" data-tooltip-selector="#mermaid-tooltip-8">flowchart LR
  
  t((Estimated \nTemperature)) --&gt; c((Crop \nAvailability))
  d2[Sales \nCommitment] --&gt;  c1{Utility}
  c --&gt; c1

</pre>
<div id="mermaid-tooltip-8" class="mermaidTooltip">

</div>
<p></p>
<p></p><figcaption class="figure-caption">Figure 16: Influence Diagram for Identifying Expected Optimal Crop Sales Commitment</figcaption><p></p>
</figure>
</div>
</div>
</div>
<div id="chunk_load_packages" class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-23-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-23-1" role="tab" aria-controls="tabset-23-1" aria-selected="true" href="">Julia</a></li></ul>
<div id="chunk_load_packages" class="tab-content">
<div id="tabset-23-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-23-1-tab">
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb93"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb93-1"><a href="#cb93-1" aria-hidden="true" tabindex="-1"></a>delivery_options <span class="op">=</span> <span class="fu">Dict</span>(<span class="st">"Option_0"</span> <span class="op">=&gt;</span> <span class="fl">0</span>, <span class="st">"Option_1"</span> <span class="op">=&gt;</span> <span class="fl">0.5</span>, <span class="st">"Option_2"</span> <span class="op">=&gt;</span> <span class="fl">0.75</span>)</span>
<span id="cb93-2"><a href="#cb93-2" aria-hidden="true" tabindex="-1"></a>delivery_states <span class="op">=</span> <span class="fu">keys</span>(delivery_options) <span class="op">|&gt;</span> x <span class="op">-&gt;</span> <span class="fu">collect</span>(x)</span>
<span id="cb93-3"><a href="#cb93-3" aria-hidden="true" tabindex="-1"></a>delivery_values <span class="op">=</span> [delivery_options[state] for state <span class="kw">in</span> delivery_states]</span>
<span id="cb93-4"><a href="#cb93-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-5"><a href="#cb93-5" aria-hidden="true" tabindex="-1"></a>survival_states <span class="op">=</span> [<span class="st">"met"</span>, <span class="st">"not_met"</span>]</span>
<span id="cb93-6"><a href="#cb93-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-7"><a href="#cb93-7" aria-hidden="true" tabindex="-1"></a>rewards <span class="op">=</span> <span class="fu">Dict</span>(<span class="st">"Option_0"</span> <span class="op">=&gt;</span> <span class="fl">0</span>, <span class="st">"Option_1"</span> <span class="op">=&gt;</span> <span class="fl">0.4</span>, <span class="st">"Option_2"</span> <span class="op">=&gt;</span> <span class="fl">0.6</span>)</span>
<span id="cb93-8"><a href="#cb93-8" aria-hidden="true" tabindex="-1"></a>reward_states <span class="op">=</span> delivery_states; reward_values <span class="op">=</span>  [rewards[state] for state <span class="kw">in</span> reward_states]</span>
<span id="cb93-9"><a href="#cb93-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-10"><a href="#cb93-10" aria-hidden="true" tabindex="-1"></a>penalties <span class="op">=</span> <span class="fu">Dict</span>(<span class="st">"Option_0"</span> <span class="op">=&gt;</span> <span class="fl">0</span>, <span class="st">"Option_1"</span> <span class="op">=&gt;</span> <span class="op">-</span><span class="fl">0.5</span>, <span class="st">"Option_2"</span> <span class="op">=&gt;</span> <span class="op">-</span><span class="fl">1</span>)</span>
<span id="cb93-11"><a href="#cb93-11" aria-hidden="true" tabindex="-1"></a>penalty_states <span class="op">=</span> delivery_states; penalty_values <span class="op">=</span>  [penalties[state] for state <span class="kw">in</span> penalty_states]</span>
<span id="cb93-12"><a href="#cb93-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-13"><a href="#cb93-13" aria-hidden="true" tabindex="-1"></a><span class="kw">function</span> <span class="fu">crop_survival</span>(Temp, α <span class="op">=</span> <span class="fl">4</span>, β <span class="op">=</span> <span class="op">-</span><span class="fl">1</span><span class="op">/</span><span class="fl">5</span>)</span>
<span id="cb93-14"><a href="#cb93-14" aria-hidden="true" tabindex="-1"></a>    survival <span class="op">=</span> <span class="fl">1</span> <span class="op">/</span> (<span class="fl">1</span> <span class="op">+</span> <span class="fu">exp</span>(<span class="fu">-</span>(α <span class="op">+</span> β <span class="op">*</span> Temp)))</span>
<span id="cb93-15"><a href="#cb93-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> survival</span>
<span id="cb93-16"><a href="#cb93-16" aria-hidden="true" tabindex="-1"></a><span class="kw">end</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</div>
</div>
</div>
<p>The <a href="https://gamma-opt.github.io/DecisionProgramming.jl/stable/">DecisionProgramming.jl</a> Julia library includes intuitive syntax for creating an influence diagram, and populating the nodes with the appropriate probability, utility and decision inputs. Expected optimal actions can then be identified using one of many compatible solvers. Note that the <a href="https://jump.dev">JuMP.jl</a> library used here, was also used to solve the optimisation problem in the energy generation problem.</p>
<div id="chunk_load_packages" class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-24-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-24-1" role="tab" aria-controls="tabset-24-1" aria-selected="true" href="">Julia (using DecisionProgramming, JuMP, HiGHS)</a></li></ul>
<div id="chunk_load_packages" class="tab-content">
<div id="tabset-24-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-24-1-tab">
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb94"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb94-1"><a href="#cb94-1" aria-hidden="true" tabindex="-1"></a><span class="kw">function</span> <span class="fu">get_exp_u</span>(S, optimiser)</span>
<span id="cb94-2"><a href="#cb94-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-3"><a href="#cb94-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Initialise influence diagram</span></span>
<span id="cb94-4"><a href="#cb94-4" aria-hidden="true" tabindex="-1"></a>    crop_delivery <span class="op">=</span> <span class="fu">InfluenceDiagram</span>()</span>
<span id="cb94-5"><a href="#cb94-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-6"><a href="#cb94-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create structure of influence diagram</span></span>
<span id="cb94-7"><a href="#cb94-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">add_node!</span>(crop_delivery, <span class="fu">DecisionNode</span>(<span class="st">"Delivery"</span>, [], delivery_states))</span>
<span id="cb94-8"><a href="#cb94-8" aria-hidden="true" tabindex="-1"></a>    <span class="fu">add_node!</span>(crop_delivery, <span class="fu">ChanceNode</span>(<span class="st">"Survival"</span>, [<span class="st">"Delivery"</span>], survival_states))</span>
<span id="cb94-9"><a href="#cb94-9" aria-hidden="true" tabindex="-1"></a>    <span class="fu">add_node!</span>(crop_delivery, <span class="fu">ValueNode</span>(<span class="st">"Pay"</span>, [<span class="st">"Survival"</span>, <span class="st">"Delivery"</span>]))</span>
<span id="cb94-10"><a href="#cb94-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-11"><a href="#cb94-11" aria-hidden="true" tabindex="-1"></a>    <span class="fu">generate_arcs!</span>(crop_delivery)</span>
<span id="cb94-12"><a href="#cb94-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-13"><a href="#cb94-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate probabilities for meeting delivery levels</span></span>
<span id="cb94-14"><a href="#cb94-14" aria-hidden="true" tabindex="-1"></a>    pr_S <span class="op">=</span> [<span class="fu">sum</span>(S <span class="op">.&gt;</span> delivery_values[i]) <span class="op">/</span> <span class="fu">length</span>(S) for i <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="fu">length</span>(delivery_values)]</span>
<span id="cb94-15"><a href="#cb94-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-16"><a href="#cb94-16" aria-hidden="true" tabindex="-1"></a>    Pr_S <span class="op">=</span> <span class="fu">ProbabilityMatrix</span>(crop_delivery, <span class="st">"Survival"</span>)</span>
<span id="cb94-17"><a href="#cb94-17" aria-hidden="true" tabindex="-1"></a>    U_p <span class="op">=</span> <span class="fu">UtilityMatrix</span>(crop_delivery, <span class="st">"Pay"</span>)</span>
<span id="cb94-18"><a href="#cb94-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-19"><a href="#cb94-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Assigning probabilities and utilities to diagram</span></span>
<span id="cb94-20"><a href="#cb94-20" aria-hidden="true" tabindex="-1"></a>    Pr_S[<span class="op">:</span>, <span class="st">"met"</span>] <span class="op">=</span> pr_S</span>
<span id="cb94-21"><a href="#cb94-21" aria-hidden="true" tabindex="-1"></a>    Pr_S[<span class="op">:</span>, <span class="st">"not_met"</span>] <span class="op">=</span> <span class="fl">1</span> <span class="op">.-</span> pr_S</span>
<span id="cb94-22"><a href="#cb94-22" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb94-23"><a href="#cb94-23" aria-hidden="true" tabindex="-1"></a>    U_p[<span class="st">"met"</span>, <span class="op">:</span>] <span class="op">=</span> reward_values</span>
<span id="cb94-24"><a href="#cb94-24" aria-hidden="true" tabindex="-1"></a>    U_p[<span class="st">"not_met"</span>, <span class="op">:</span>] <span class="op">=</span> penalty_values</span>
<span id="cb94-25"><a href="#cb94-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-26"><a href="#cb94-26" aria-hidden="true" tabindex="-1"></a>    <span class="fu">add_probabilities!</span>(crop_delivery, <span class="st">"Survival"</span>, Pr_S)</span>
<span id="cb94-27"><a href="#cb94-27" aria-hidden="true" tabindex="-1"></a>    <span class="fu">add_utilities!</span>(crop_delivery, <span class="st">"Pay"</span>, U_p)</span>
<span id="cb94-28"><a href="#cb94-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-29"><a href="#cb94-29" aria-hidden="true" tabindex="-1"></a>    <span class="fu">generate_diagram!</span>(crop_delivery)</span>
<span id="cb94-30"><a href="#cb94-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-31"><a href="#cb94-31" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Define and run solver</span></span>
<span id="cb94-32"><a href="#cb94-32" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> JuMP.<span class="fu">Model</span>(optimiser)</span>
<span id="cb94-33"><a href="#cb94-33" aria-hidden="true" tabindex="-1"></a>    z <span class="op">=</span> <span class="fu">DecisionVariables</span>(model, crop_delivery)</span>
<span id="cb94-34"><a href="#cb94-34" aria-hidden="true" tabindex="-1"></a>    EV <span class="op">=</span> <span class="fu">expected_value</span>(model, crop_delivery, <span class="fu">PathCompatibilityVariables</span>(model, crop_delivery, z))</span>
<span id="cb94-35"><a href="#cb94-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-36"><a href="#cb94-36" aria-hidden="true" tabindex="-1"></a>    <span class="pp">@objective</span>(model, Max, EV)</span>
<span id="cb94-37"><a href="#cb94-37" aria-hidden="true" tabindex="-1"></a>    <span class="fu">optimize!</span>(model)</span>
<span id="cb94-38"><a href="#cb94-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-39"><a href="#cb94-39" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Process results</span></span>
<span id="cb94-40"><a href="#cb94-40" aria-hidden="true" tabindex="-1"></a>    Z <span class="op">=</span> <span class="fu">DecisionStrategy</span>(z)</span>
<span id="cb94-41"><a href="#cb94-41" aria-hidden="true" tabindex="-1"></a>    U_dist <span class="op">=</span> <span class="fu">UtilityDistribution</span>(crop_delivery, Z)</span>
<span id="cb94-42"><a href="#cb94-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-43"><a href="#cb94-43" aria-hidden="true" tabindex="-1"></a>    exp_opt_decision <span class="op">=</span> <span class="fu">DataFrame</span>(Exp_Utility <span class="op">=</span> <span class="fu">dot</span>(U_dist.p, U_dist.u),</span>
<span id="cb94-44"><a href="#cb94-44" aria-hidden="true" tabindex="-1"></a>                             Action <span class="op">=</span> delivery_states[<span class="fu">argmax</span>(Z.Z_d[<span class="fl">1</span>])])</span>
<span id="cb94-45"><a href="#cb94-45" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb94-46"><a href="#cb94-46" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> exp_opt_decision</span>
<span id="cb94-47"><a href="#cb94-47" aria-hidden="true" tabindex="-1"></a><span class="kw">end</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>get_exp_u (generic function with 1 method)</code></pre>
</div>
</div>
<p>The prior model of temperature is a Normal distribution with a mean of <span class="math inline">\(10^{\circ} C\)</span> and a standard deviation of <span class="math inline">\(5 ^{\circ} C\)</span>. This continuous model has been discretised by drawing <span class="math inline">\(1000\)</span> samples using the Latin Hypercube method.</p>
<p><span class="math display">\[
T\_{prior} \sim N(\mu = 10, \sigma = 5)
\]</span></p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb96"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb96-1"><a href="#cb96-1" aria-hidden="true" tabindex="-1"></a>prior_temp <span class="op">=</span> <span class="fu">Normal</span>(<span class="fl">10</span>, <span class="fl">5</span>)</span>
<span id="cb96-2"><a href="#cb96-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb96-3"><a href="#cb96-3" aria-hidden="true" tabindex="-1"></a><span class="kw">function</span> <span class="fu">draw_lhs</span>(dist, n<span class="op">::</span><span class="dt">Int</span>; reprod<span class="op">::</span><span class="dt">Int </span><span class="op">=</span> <span class="fl">240819</span>)</span>
<span id="cb96-4"><a href="#cb96-4" aria-hidden="true" tabindex="-1"></a>    <span class="bu">Random</span>.<span class="fu">seed!</span>(reprod)</span>
<span id="cb96-5"><a href="#cb96-5" aria-hidden="true" tabindex="-1"></a>    samples <span class="op">=</span> <span class="fu">randomLHC</span>(n <span class="op">+</span> <span class="fl">2</span>, <span class="fl">1</span>) <span class="op">|&gt;</span></span>
<span id="cb96-6"><a href="#cb96-6" aria-hidden="true" tabindex="-1"></a>        x <span class="op">-&gt;</span> <span class="fu">scaleLHC</span>(x, [(<span class="fl">0</span>, <span class="fl">1</span>)]) <span class="op">|&gt;</span></span>
<span id="cb96-7"><a href="#cb96-7" aria-hidden="true" tabindex="-1"></a>        x <span class="op">-&gt;</span> <span class="fu">quantile</span>(dist, x)[<span class="op">:</span>,<span class="fl">1</span>] <span class="op">|&gt;</span></span>
<span id="cb96-8"><a href="#cb96-8" aria-hidden="true" tabindex="-1"></a>        x <span class="op">-&gt;</span> <span class="fu">filter</span>(!<span class="fu">∈</span>((<span class="op">-</span><span class="cn">Inf</span>, <span class="cn">Inf</span>)), x) <span class="op">|&gt;</span></span>
<span id="cb96-9"><a href="#cb96-9" aria-hidden="true" tabindex="-1"></a>        x <span class="op">-&gt;</span> [x[i] for i <span class="op">∈</span> <span class="fl">1</span><span class="op">:</span><span class="fu">length</span>(x) if <span class="fu">abs</span>(x[i]) <span class="op">&gt;=</span> <span class="fl">10</span><span class="op">^-</span><span class="fl">10</span>]</span>
<span id="cb96-10"><a href="#cb96-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> samples</span>
<span id="cb96-11"><a href="#cb96-11" aria-hidden="true" tabindex="-1"></a><span class="kw">end</span></span>
<span id="cb96-12"><a href="#cb96-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb96-13"><a href="#cb96-13" aria-hidden="true" tabindex="-1"></a>temp_df <span class="op">=</span> <span class="fu">DataFrame</span>(temp <span class="op">=</span> <span class="fu">draw_lhs</span>(prior_temp, <span class="fl">1_000</span>)) <span class="op">|&gt;</span></span>
<span id="cb96-14"><a href="#cb96-14" aria-hidden="true" tabindex="-1"></a>    x <span class="op">-&gt;</span> <span class="pp">@rtransform</span>(x, <span class="op">:</span>surv <span class="op">=</span> <span class="fu">crop_survival</span>(<span class="op">:</span>temp)) <span class="op">|&gt;</span></span>
<span id="cb96-15"><a href="#cb96-15" aria-hidden="true" tabindex="-1"></a>    x <span class="op">-&gt;</span> <span class="pp">@orderby</span>(x, <span class="op">:</span>temp)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>The expected optimal action, conditional on the influence diagram representation of the decision problem, and the prior model of temperature can then be calculated:</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb97"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb97-1"><a href="#cb97-1" aria-hidden="true" tabindex="-1"></a><span class="fu">get_exp_u</span>(temp_df.surv, HiGHS.Optimizer)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Running HiGHS 1.3.0 [date: 1970-01-01, git hash: e5004072b-dirty]
Copyright (c) 2022 ERGO-Code under MIT licence terms
Presolving model
5 rows, 8 cols, 16 nonzeros
4 rows, 7 cols, 14 nonzeros
4 rows, 4 cols, 8 nonzeros
2 rows, 3 cols, 5 nonzeros
0 rows, 0 cols, 0 nonzeros
Presolve: Optimal

Solving report
  Status            Optimal
  Primal bound      0.380200005829
  Dual bound        0.380200005829
  Gap               0% (tolerance: 0.01%)
  Solution status   feasible
                    0.380200005829 (objective)
                    0 (bound viol.)
                    0 (int. viol.)
                    0 (row viol.)
  Timing            0.00 (total)
                    0.00 (presolve)
                    0.00 (postsolve)
  Nodes             0
  LP iterations     0 (total)
                    0 (strong br.)
                    0 (separation)
                    0 (heuristics)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1×2 DataFrame
 Row │ Exp_Utility  Action
     │ Float64      String
─────┼───────────────────────
   1 │      0.3802  Option_1</code></pre>
</div>
</div>
</div>
</div>
</div>
<p>Considering the option of installing devices to measure the temperature (as shown in <a href="#fig-prepost_id_farm">Figure&nbsp;17</a>), requires the influence diagram to be solved many times (for each hypothesised outcome). The average expected utility over each of the subsequent decision analyses can then be compared to the expected prior utility, to find the expected value of (perfect) temperature measurements, in the context of supporting the crop sales decision.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-prepost_id_farm" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p>
</p><pre class="mermaid" data-tooltip-selector="#mermaid-tooltip-9">flowchart LR
  
  d1[Measure \nTemperature] --&gt; t((Estimated \nTemperature)) 
  t --&gt; c((Crop \nAvailability))
  d2[Sales \nCommitment] --&gt;  c1{Utility}
  c --&gt; c1

</pre>
<div id="mermaid-tooltip-9" class="mermaidTooltip">

</div>
<p></p>
<p></p><figcaption class="figure-caption">Figure 17: Influence Diagram for Calculating Expected Value of Temperature Data</figcaption><p></p>
</figure>
</div>
</div>
</div>
<div id="chunk_load_packages" class="panel-tabset">
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb100"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb100-1"><a href="#cb100-1" aria-hidden="true" tabindex="-1"></a>measure_df <span class="op">=</span> <span class="fu">DataFrame</span>()</span>
<span id="cb100-2"><a href="#cb100-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> s_meas <span class="kw">in</span> temp_df.surv</span>
<span id="cb100-3"><a href="#cb100-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">append!</span>(measure_df, <span class="fu">get_exp_u</span>(s_meas, HiGHS.Optimizer))</span>
<span id="cb100-4"><a href="#cb100-4" aria-hidden="true" tabindex="-1"></a><span class="cf">end</span></span>
<span id="cb100-5"><a href="#cb100-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-6"><a href="#cb100-6" aria-hidden="true" tabindex="-1"></a>prior_utility <span class="op">=</span> <span class="fu">get_exp_u</span>(temp_df.surv, HiGHS.Optimizer).Exp_Utility[<span class="fl">1</span>]</span>
<span id="cb100-7"><a href="#cb100-7" aria-hidden="true" tabindex="-1"></a>prepost_utility <span class="op">=</span> <span class="fu">mean</span>(measure_df.Exp_Utility)</span>
<span id="cb100-8"><a href="#cb100-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-9"><a href="#cb100-9" aria-hidden="true" tabindex="-1"></a>VoPI <span class="op">=</span> prepost_utility <span class="op">-</span> prior_utility</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb101"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb101-1"><a href="#cb101-1" aria-hidden="true" tabindex="-1"></a><span class="pp">@printf</span> <span class="st">"VoPI = %.4f"</span> VoPI</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>VoPI = 0.1744</code></pre>
</div>
</div>
</div>
</section>
<section id="example-b-verification-of-a-digital-twin-for-maintenance-planning" class="level4" data-number="4.2.3.2">
<h4 data-number="4.2.3.2" class="anchored" data-anchor-id="example-b-verification-of-a-digital-twin-for-maintenance-planning"><span class="header-section-number">4.2.3.2</span> Example B: Verification of a Digital Twin for Maintenance Planning</h4>
<p>Another source of data that can be considered, is that which is obtained from verifying an existing model. There may be many reasons to complete such a study, such as to demonstrate compliance with a quality standard, or to obtain some certification, and though these can also be quantified and incorporated, this example will only consider the benefits in terms of risk management.</p>
<p>The source of value of verification studies arises from the propagation of the reduced uncertainty through a decision analysis i.e.&nbsp;the information from verification studies facilitate improved risk management.</p>
<p>Consider the representation in <a href="#fig-dt_id">Figure&nbsp;18</a> of the decision problem regarding whether to send maintenance personnel to investigate a component. An investigation includes the repair of any defect(s), and is expected to be worthwhile if the cost of the activity is less than that associated with the risk of failure. The state/condition of the component can be estimated based on the knowledge of the operations engineers, as well as data from a digital twin, which is being used in this context to support a condition assessment.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-dt_id" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p>
</p><pre class="mermaid" data-tooltip-selector="#mermaid-tooltip-10">flowchart LR
  d1[Maintenance \nPlan]  --&gt; o1((Component \nCondition))
  o2((Digital \nTwin Data))  --&gt; o1
  d2[Verification Plan \nfor Digital Twin] --&gt; o1
  d2 --&gt; o2

  d1 --&gt; c1{Maintenance \nCost} 
  o1  --&gt; c2{Failure \nRisk}
  
</pre>
<div id="mermaid-tooltip-10" class="mermaidTooltip">

</div>
<p></p>
<p></p><figcaption class="figure-caption">Figure 18: Influence Diagram of Maintenance Decision Problem</figcaption><p></p>
</figure>
</div>
</div>
</div>
<div class="cell">
<div class="cell-output-display">
<div id="tbl-model_inputs" class="anchored">
<table class="table table-sm table-striped">
<caption>Table 2: Key Inputs for Decision Analysis</caption>
<thead>
<tr class="header">
<th style="text-align: left;">Input</th>
<th style="text-align: right;">Value</th>
<th style="text-align: left;">Units</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">probability of defect</td>
<td style="text-align: right;">1.5e-01</td>
<td style="text-align: left;">NA</td>
</tr>
<tr class="even">
<td style="text-align: left;">cost of investigation</td>
<td style="text-align: right;">1.0e+05</td>
<td style="text-align: left;">$</td>
</tr>
<tr class="odd">
<td style="text-align: left;">cost of shut-down</td>
<td style="text-align: right;">2.0e+05</td>
<td style="text-align: left;">$</td>
</tr>
<tr class="even">
<td style="text-align: left;">cost of component failure</td>
<td style="text-align: right;">5.0e+05</td>
<td style="text-align: left;">$</td>
</tr>
<tr class="odd">
<td style="text-align: left;">probability of failure of defective component</td>
<td style="text-align: right;">5.0e-01</td>
<td style="text-align: left;">NA</td>
</tr>
<tr class="even">
<td style="text-align: left;">probability of failure of undamaged component</td>
<td style="text-align: right;">1.0e-04</td>
<td style="text-align: left;">NA</td>
</tr>
<tr class="odd">
<td style="text-align: left;">probability of failure during shut-down</td>
<td style="text-align: right;">1.0e-06</td>
<td style="text-align: left;">NA</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<div id="chunk_load_packages" class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-26-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-26-1" role="tab" aria-controls="tabset-26-1" aria-selected="true" href="">Julia</a></li></ul>
<div id="chunk_load_packages" class="tab-content">
<div id="tabset-26-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-26-1-tab">
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb103"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb103-1"><a href="#cb103-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set up decision inputs</span></span>
<span id="cb103-2"><a href="#cb103-2" aria-hidden="true" tabindex="-1"></a>maint_options <span class="op">=</span> <span class="fu">Dict</span>(<span class="st">"no_action"</span> <span class="op">=&gt;</span> <span class="fl">1</span>, <span class="st">"investigate"</span> <span class="op">=&gt;</span> <span class="fl">10</span><span class="op">^-</span><span class="fl">2</span>, <span class="st">"shut_down"</span> <span class="op">=&gt;</span> <span class="fl">10</span><span class="op">^-</span><span class="fl">4</span>)</span>
<span id="cb103-3"><a href="#cb103-3" aria-hidden="true" tabindex="-1"></a>maint_states <span class="op">=</span> <span class="fu">keys</span>(maint_options) <span class="op">|&gt;</span> x <span class="op">-&gt;</span> <span class="fu">collect</span>(x)</span>
<span id="cb103-4"><a href="#cb103-4" aria-hidden="true" tabindex="-1"></a>maint_values <span class="op">=</span> [maint_options[state] for state <span class="kw">in</span> maint_states]</span>
<span id="cb103-5"><a href="#cb103-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb103-6"><a href="#cb103-6" aria-hidden="true" tabindex="-1"></a>dt_output_states <span class="op">=</span> [<span class="st">"defect"</span>, <span class="st">"no_defect"</span>]</span>
<span id="cb103-7"><a href="#cb103-7" aria-hidden="true" tabindex="-1"></a>condition_states <span class="op">=</span> [<span class="st">"failure"</span>, <span class="st">"survival"</span>]</span>
<span id="cb103-8"><a href="#cb103-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb103-9"><a href="#cb103-9" aria-hidden="true" tabindex="-1"></a>pr_defect <span class="op">=</span> <span class="fl">0.15</span>; pr_fail_defect <span class="op">=</span> <span class="fl">0.5</span>; pr_fail_undamaged <span class="op">=</span> <span class="fl">10</span><span class="op">^-</span><span class="fl">2</span></span>
<span id="cb103-10"><a href="#cb103-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb103-11"><a href="#cb103-11" aria-hidden="true" tabindex="-1"></a>cost_inv <span class="op">=</span> <span class="fl">100_000</span>; cost_shutdown <span class="op">=</span> <span class="fl">200_000</span>; cost_failure <span class="op">=</span> <span class="fl">500_000</span></span>
<span id="cb103-12"><a href="#cb103-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb103-13"><a href="#cb103-13" aria-hidden="true" tabindex="-1"></a>n_samples <span class="op">=</span> <span class="fl">1_000</span>; prior_β <span class="op">=</span> <span class="fu">Beta</span>(<span class="fl">6</span>, <span class="fl">2</span>)</span>
<span id="cb103-14"><a href="#cb103-14" aria-hidden="true" tabindex="-1"></a>reliabilities <span class="op">=</span> <span class="fu">draw_lhs</span>(prior_β, n_samples)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</div>
</div>
</div>
<div id="chunk_load_packages" class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-27-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-27-1" role="tab" aria-controls="tabset-27-1" aria-selected="true" href="">Julia (using DecisionProgramming, JuMP, HiGHS)</a></li></ul>
<div id="chunk_load_packages" class="tab-content">
<div id="tabset-27-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-27-1-tab">
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb104"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb104-1"><a href="#cb104-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb104-2"><a href="#cb104-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialise influence diagram</span></span>
<span id="cb104-3"><a href="#cb104-3" aria-hidden="true" tabindex="-1"></a><span class="kw">function</span> <span class="fu">create_id</span>(β<span class="op">::</span><span class="dt">Float64</span>)</span>
<span id="cb104-4"><a href="#cb104-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb104-5"><a href="#cb104-5" aria-hidden="true" tabindex="-1"></a>    maint_dec <span class="op">=</span> <span class="fu">InfluenceDiagram</span>()</span>
<span id="cb104-6"><a href="#cb104-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb104-7"><a href="#cb104-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create structure of influence diagram</span></span>
<span id="cb104-8"><a href="#cb104-8" aria-hidden="true" tabindex="-1"></a>    <span class="fu">add_node!</span>(maint_dec, <span class="fu">DecisionNode</span>(<span class="st">"Maintenance"</span>, [], maint_states))</span>
<span id="cb104-9"><a href="#cb104-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb104-10"><a href="#cb104-10" aria-hidden="true" tabindex="-1"></a>    <span class="fu">add_node!</span>(maint_dec, <span class="fu">ChanceNode</span>(<span class="st">"DT_output"</span>, [], dt_output_states))</span>
<span id="cb104-11"><a href="#cb104-11" aria-hidden="true" tabindex="-1"></a>    <span class="fu">add_node!</span>(maint_dec, <span class="fu">ChanceNode</span>(<span class="st">"Condition"</span>, [<span class="st">"DT_output"</span>, <span class="st">"Maintenance"</span>], condition_states))</span>
<span id="cb104-12"><a href="#cb104-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb104-13"><a href="#cb104-13" aria-hidden="true" tabindex="-1"></a>    <span class="fu">add_node!</span>(maint_dec, <span class="fu">ValueNode</span>(<span class="st">"Fail_risk"</span>, [<span class="st">"Condition"</span>]))</span>
<span id="cb104-14"><a href="#cb104-14" aria-hidden="true" tabindex="-1"></a>    <span class="fu">add_node!</span>(maint_dec, <span class="fu">ValueNode</span>(<span class="st">"Maint_cost"</span>, [<span class="st">"Maintenance"</span>]))</span>
<span id="cb104-15"><a href="#cb104-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb104-16"><a href="#cb104-16" aria-hidden="true" tabindex="-1"></a>    <span class="fu">generate_arcs!</span>(maint_dec)</span>
<span id="cb104-17"><a href="#cb104-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb104-18"><a href="#cb104-18" aria-hidden="true" tabindex="-1"></a>    Pr_DT <span class="op">=</span> <span class="fu">ProbabilityMatrix</span>(maint_dec, <span class="st">"DT_output"</span>)</span>
<span id="cb104-19"><a href="#cb104-19" aria-hidden="true" tabindex="-1"></a>    Pr_C <span class="op">=</span> <span class="fu">ProbabilityMatrix</span>(maint_dec, <span class="st">"Condition"</span>)</span>
<span id="cb104-20"><a href="#cb104-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb104-21"><a href="#cb104-21" aria-hidden="true" tabindex="-1"></a>    U_M <span class="op">=</span> <span class="fu">UtilityMatrix</span>(maint_dec, <span class="st">"Maint_cost"</span>)</span>
<span id="cb104-22"><a href="#cb104-22" aria-hidden="true" tabindex="-1"></a>    U_f <span class="op">=</span> <span class="fu">UtilityMatrix</span>(maint_dec, <span class="st">"Fail_risk"</span>)</span>
<span id="cb104-23"><a href="#cb104-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb104-24"><a href="#cb104-24" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate probabilities of detection and failure</span></span>
<span id="cb104-25"><a href="#cb104-25" aria-hidden="true" tabindex="-1"></a>    pr_defect_detected <span class="op">=</span> (pr_defect <span class="op">*</span> β) <span class="op">+</span> (<span class="fl">1</span> <span class="op">-</span> pr_defect) <span class="op">*</span> (<span class="fl">1</span> <span class="op">-</span> β)</span>
<span id="cb104-26"><a href="#cb104-26" aria-hidden="true" tabindex="-1"></a>    pr_fail_det <span class="op">=</span> pr_fail_defect <span class="op">*</span> β <span class="op">+</span> pr_fail_undamaged <span class="op">*</span> (<span class="fl">1</span> <span class="op">-</span> β)</span>
<span id="cb104-27"><a href="#cb104-27" aria-hidden="true" tabindex="-1"></a>    pr_fail_nodet <span class="op">=</span> pr_fail_undamaged <span class="op">*</span> β <span class="op">+</span> pr_fail_defect <span class="op">*</span> (<span class="fl">1</span> <span class="op">-</span> β)</span>
<span id="cb104-28"><a href="#cb104-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb104-29"><a href="#cb104-29" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Assign probabilities and utilities to nodes</span></span>
<span id="cb104-30"><a href="#cb104-30" aria-hidden="true" tabindex="-1"></a>    Pr_DT[<span class="st">"defect"</span>] <span class="op">=</span> pr_defect_detected</span>
<span id="cb104-31"><a href="#cb104-31" aria-hidden="true" tabindex="-1"></a>    Pr_DT[<span class="st">"no_defect"</span>] <span class="op">=</span> <span class="fl">1</span> <span class="op">-</span> pr_defect_detected</span>
<span id="cb104-32"><a href="#cb104-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb104-33"><a href="#cb104-33" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> maint_states</span>
<span id="cb104-34"><a href="#cb104-34" aria-hidden="true" tabindex="-1"></a>        Pr_C[<span class="st">"defect"</span>, <span class="op">:</span>, <span class="st">"failure"</span>] <span class="op">=</span> pr_fail_det <span class="op">*</span> [maint_options[i] for i <span class="kw">in</span> maint_states]</span>
<span id="cb104-35"><a href="#cb104-35" aria-hidden="true" tabindex="-1"></a>        Pr_C[<span class="st">"defect"</span>, <span class="op">:</span>, <span class="st">"survival"</span>] <span class="op">=</span> <span class="fl">1</span> <span class="op">.-</span> pr_fail_det <span class="op">*</span> [maint_options[i] for i <span class="kw">in</span> maint_states]</span>
<span id="cb104-36"><a href="#cb104-36" aria-hidden="true" tabindex="-1"></a>        Pr_C[<span class="st">"no_defect"</span>, <span class="op">:</span>, <span class="st">"failure"</span>] <span class="op">=</span> pr_fail_nodet <span class="op">*</span> [maint_options[i] for i <span class="kw">in</span> maint_states]</span>
<span id="cb104-37"><a href="#cb104-37" aria-hidden="true" tabindex="-1"></a>        Pr_C[<span class="st">"no_defect"</span>, <span class="op">:</span>, <span class="st">"survival"</span>] <span class="op">=</span> <span class="fl">1</span> <span class="op">.-</span> pr_fail_nodet <span class="op">*</span> [maint_options[i] for i <span class="kw">in</span> maint_states]</span>
<span id="cb104-38"><a href="#cb104-38" aria-hidden="true" tabindex="-1"></a>    <span class="cf">end</span></span>
<span id="cb104-39"><a href="#cb104-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb104-40"><a href="#cb104-40" aria-hidden="true" tabindex="-1"></a>    U_M[<span class="st">"no_action"</span>] <span class="op">=</span> <span class="fl">0</span>; U_M[<span class="st">"investigate"</span>] <span class="op">=</span> cost_inv; U_M[<span class="st">"shut_down"</span>] <span class="op">=</span> cost_shutdown</span>
<span id="cb104-41"><a href="#cb104-41" aria-hidden="true" tabindex="-1"></a>    U_f[<span class="st">"survival"</span>] <span class="op">=</span> <span class="fl">0</span>; U_f[<span class="st">"failure"</span>] <span class="op">=</span> cost_failure</span>
<span id="cb104-42"><a href="#cb104-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb104-43"><a href="#cb104-43" aria-hidden="true" tabindex="-1"></a>    <span class="fu">add_probabilities!</span>(maint_dec, <span class="st">"DT_output"</span>, Pr_DT)</span>
<span id="cb104-44"><a href="#cb104-44" aria-hidden="true" tabindex="-1"></a>    <span class="fu">add_probabilities!</span>(maint_dec, <span class="st">"Condition"</span>, Pr_C)</span>
<span id="cb104-45"><a href="#cb104-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb104-46"><a href="#cb104-46" aria-hidden="true" tabindex="-1"></a>    <span class="fu">add_utilities!</span>(maint_dec, <span class="st">"Maint_cost"</span>, U_M)</span>
<span id="cb104-47"><a href="#cb104-47" aria-hidden="true" tabindex="-1"></a>    <span class="fu">add_utilities!</span>(maint_dec, <span class="st">"Fail_risk"</span>, U_f)</span>
<span id="cb104-48"><a href="#cb104-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb104-49"><a href="#cb104-49" aria-hidden="true" tabindex="-1"></a>    <span class="fu">generate_diagram!</span>(maint_dec)</span>
<span id="cb104-50"><a href="#cb104-50" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb104-51"><a href="#cb104-51" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> maint_dec</span>
<span id="cb104-52"><a href="#cb104-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb104-53"><a href="#cb104-53" aria-hidden="true" tabindex="-1"></a><span class="kw">end</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>create_id (generic function with 1 method)</code></pre>
</div>
</div>
<p>Then the following function solves the influence diagram (identifies the expected optimal action and costs).</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb106"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb106-1"><a href="#cb106-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Solve the influence diagram</span></span>
<span id="cb106-2"><a href="#cb106-2" aria-hidden="true" tabindex="-1"></a><span class="kw">function</span> <span class="fu">solve_id</span>(; β<span class="op">::</span><span class="dt">Float64</span>, optimiser<span class="op">::</span><span class="dt">DataType </span><span class="op">=</span> HiGHS.Optimizer)</span>
<span id="cb106-3"><a href="#cb106-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-4"><a href="#cb106-4" aria-hidden="true" tabindex="-1"></a>    maint_dec <span class="op">=</span> <span class="fu">create_id</span>(β)</span>
<span id="cb106-5"><a href="#cb106-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-6"><a href="#cb106-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Define and run solver</span></span>
<span id="cb106-7"><a href="#cb106-7" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> JuMP.<span class="fu">Model</span>(optimiser)</span>
<span id="cb106-8"><a href="#cb106-8" aria-hidden="true" tabindex="-1"></a>    z <span class="op">=</span> <span class="fu">DecisionVariables</span>(model, maint_dec)</span>
<span id="cb106-9"><a href="#cb106-9" aria-hidden="true" tabindex="-1"></a>    EV <span class="op">=</span> <span class="fu">expected_value</span>(model, maint_dec, <span class="fu">PathCompatibilityVariables</span>(model, maint_dec, z))</span>
<span id="cb106-10"><a href="#cb106-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-11"><a href="#cb106-11" aria-hidden="true" tabindex="-1"></a>    <span class="pp">@objective</span>(model, Min, EV)</span>
<span id="cb106-12"><a href="#cb106-12" aria-hidden="true" tabindex="-1"></a>    <span class="fu">optimize!</span>(model)</span>
<span id="cb106-13"><a href="#cb106-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-14"><a href="#cb106-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Process results</span></span>
<span id="cb106-15"><a href="#cb106-15" aria-hidden="true" tabindex="-1"></a>    Z <span class="op">=</span> <span class="fu">DecisionStrategy</span>(z)</span>
<span id="cb106-16"><a href="#cb106-16" aria-hidden="true" tabindex="-1"></a>    U_dist <span class="op">=</span> <span class="fu">UtilityDistribution</span>(maint_dec, Z)</span>
<span id="cb106-17"><a href="#cb106-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-18"><a href="#cb106-18" aria-hidden="true" tabindex="-1"></a>    opt_df <span class="op">=</span> <span class="fu">DataFrame</span>(β <span class="op">=</span> β,</span>
<span id="cb106-19"><a href="#cb106-19" aria-hidden="true" tabindex="-1"></a>        u_opt <span class="op">=</span> <span class="fu">dot</span>(U_dist.p, U_dist.u),</span>
<span id="cb106-20"><a href="#cb106-20" aria-hidden="true" tabindex="-1"></a>        a_opt <span class="op">=</span> maint_states[<span class="fu">argmax</span>(Z.Z_d[<span class="fl">1</span>])])</span>
<span id="cb106-21"><a href="#cb106-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-22"><a href="#cb106-22" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> opt_df</span>
<span id="cb106-23"><a href="#cb106-23" aria-hidden="true" tabindex="-1"></a><span class="kw">end</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb107"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb107-1"><a href="#cb107-1" aria-hidden="true" tabindex="-1"></a><span class="fu">solve_id</span>(β <span class="op">=</span> <span class="fl">0.8</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>To consider the additional cost associated with the epistemic uncertainty in the digital twin reliability, a <em>value of information</em> calculation can be completed. Since we are quantifying the expected value of a verification that has not yet been completed, we must consider the range of possible results. The prior model of reliability describes what we expect a verification activity to find, and simulating possible results (and evaluating their impact of an expected optimal maintenance decision) can be used to quantify the expected value of verification in this context.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb108"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb108-1"><a href="#cb108-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulating many possible outcomes from the verification</span></span>
<span id="cb108-2"><a href="#cb108-2" aria-hidden="true" tabindex="-1"></a>verif_df <span class="op">=</span> <span class="fu">DataFrame</span>()</span>
<span id="cb108-3"><a href="#cb108-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> βᵣ <span class="kw">in</span> reliabilities</span>
<span id="cb108-4"><a href="#cb108-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">append!</span>(verif_df, <span class="fu">solve_id</span>(β <span class="op">=</span> βᵣ))</span>
<span id="cb108-5"><a href="#cb108-5" aria-hidden="true" tabindex="-1"></a><span class="cf">end</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>As shown in <strong>?@fig-voi_results</strong>, in instances where a verification study identifies a relatively high reliability of the digital twin, this can be used to justify deferral of a site investigation of a component. Whereas in instances where a relatively low reliability is identified, an investigation is still justified. For this particular scenario, a shut-down was never found to be the expected optimal action, despite the reduced probability of failure due to the high cost of implementation.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb109"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb109-1"><a href="#cb109-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb109-2"><a href="#cb109-2" aria-hidden="true" tabindex="-1"></a>prior_cost <span class="op">=</span> <span class="fu">solve_id</span>(β <span class="op">=</span> <span class="fu">mean</span>(reliabilities)).u_opt[<span class="fl">1</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Running HiGHS 1.3.0 [date: 1970-01-01, git hash: e5004072b-dirty]
Copyright (c) 2022 ERGO-Code under MIT licence terms
Presolving model
5 rows, 15 cols, 30 nonzeros
4 rows, 6 cols, 12 nonzeros
2 rows, 5 cols, 9 nonzeros
0 rows, 0 cols, 0 nonzeros
Presolve: Optimal

Solving report
  Status            Optimal
  Primal bound      101059.914509
  Dual bound        101059.914509
  Gap               0% (tolerance: 0.01%)
  Solution status   feasible
                    101059.914509 (objective)
                    0 (bound viol.)
                    0 (int. viol.)
                    0 (row viol.)
  Timing            0.00 (total)
                    0.00 (presolve)
                    0.00 (postsolve)
  Nodes             0
  LP iterations     0 (total)
                    0 (strong br.)
                    0 (separation)
                    0 (heuristics)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>101059.9145093234</code></pre>
</div>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb112"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb112-1"><a href="#cb112-1" aria-hidden="true" tabindex="-1"></a>prepost_cost <span class="op">=</span> verif_df.u_opt <span class="op">|&gt;</span> x <span class="op">-&gt;</span> <span class="fu">mean</span>(x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>90814.02187335781</code></pre>
</div>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb114"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb114-1"><a href="#cb114-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb114-2"><a href="#cb114-2" aria-hidden="true" tabindex="-1"></a>VoI <span class="op">=</span> prior_cost <span class="op">-</span> prepost_cost</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>10245.892635965589</code></pre>
</div>
</div>
</div>
</div>
</div>
</section>
</section>
<section id="expected-value-of-imprecise-imperfect-information" class="level3" data-number="4.2.4">
<h3 data-number="4.2.4" class="anchored" data-anchor-id="expected-value-of-imprecise-imperfect-information"><span class="header-section-number">4.2.4</span> Expected Value of Imprecise (Imperfect) Information:</h3>
<section id="example-inspecting-for-corrosion" class="level4" data-number="4.2.4.1">
<h4 data-number="4.2.4.1" class="anchored" data-anchor-id="example-inspecting-for-corrosion"><span class="header-section-number">4.2.4.1</span> Example: Inspecting for Corrosion</h4>
<p>One method of estimating corrosion growth rates is by comparing repeated measurements of damage at sites of active corrosion. In this example, inspection data for <span class="math inline">\(10\)</span> sites of corrosion can be analysed, so that future degradation can be forecast. Predicting when these locations will fail will inform the decision of whether to invest in repairs. An influence diagram representation of this challenge is shown in <a href="#fig-prepost_id_voi">Figure&nbsp;19</a>.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-prepost_id_voi" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p>
</p><pre class="mermaid" data-tooltip-selector="#mermaid-tooltip-11">flowchart LR

    v[Inspect \nAnomaly 4] --&gt; c((Estimated \nCorrosion Rate))
    c --&gt; C_f{Failure \nRisk}

    m[Repair \nPlan] --&gt; C_f
    
    m --&gt; C_m{Repair \nCosts}

</pre>
<div id="mermaid-tooltip-11" class="mermaidTooltip">

</div>
<p></p>
<p></p><figcaption class="figure-caption">Figure 19: Influence Diagram for Identifying Expected Optimal Repair Plan for Corroding Structure</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>The available inspection data is loaded in the below <code>Python</code> code. As well as the measurement, identifiers for the inspection, and anomaly are listed. Note that the second inspection was not completed at anomaly <span class="math inline">\(4\)</span>. Sometimes inspections cannot be completed due to time, weather (or other safety constraints). In this case, this instance is labelled as missing data.</p>
<div id="chunk_load_packages" class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-28-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-28-1" role="tab" aria-controls="tabset-28-1" aria-selected="true" href="">Python (using Pandas)</a></li></ul>
<div id="chunk_load_packages" class="tab-content">
<div id="tabset-28-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-28-1-tab">
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb116"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb116-1"><a href="#cb116-1" aria-hidden="true" tabindex="-1"></a>insp_data <span class="op">=</span> pd.read_csv(<span class="st">"data_files/inspection_data.csv"</span>)</span>
<span id="cb116-2"><a href="#cb116-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb116-3"><a href="#cb116-3" aria-hidden="true" tabindex="-1"></a>years <span class="op">=</span> insp_data.t.unique()</span>
<span id="cb116-4"><a href="#cb116-4" aria-hidden="true" tabindex="-1"></a>insps <span class="op">=</span> insp_data.inspection.unique()</span>
<span id="cb116-5"><a href="#cb116-5" aria-hidden="true" tabindex="-1"></a>locations <span class="op">=</span> insp_data.location.unique()</span>
<span id="cb116-6"><a href="#cb116-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb116-7"><a href="#cb116-7" aria-hidden="true" tabindex="-1"></a>insp_data.head(n <span class="op">=</span> <span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>   t  depth_mm inspection  anomaly_id  location  sizing_uncertainty  missing
0  0      4.17          A           1         1                 0.5        0
1  0      3.62          A           2         1                 0.5        0
2  0     11.01          A           3         1                 0.5        0</code></pre>
</div>
</div>
</div>
</div>
</div>
<p>A <code>Stan</code> model has been written that estimates the corrosion growth rate, in <span class="math inline">\(mm/year\)</span> for this population as the difference in the measured extent (depth) of the damage in <span class="math inline">\(mm\)</span>, divided by the time interval between the measurements, in <span class="math inline">\(years\)</span>. This probabilistic estimate is then use to forecast future growth for a defined time window, so that the probabilities of failure for each of the anomalies can be calculated, for the purpose of identifying where repairs are expected to be required.</p>
<p>The model is set loaded below, along with some options for the sampling.</p>
<div id="chunk_load_packages" class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-29-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-29-1" role="tab" aria-controls="tabset-29-1" aria-selected="true" href="">Python (using CmdStanPy)</a></li></ul>
<div id="chunk_load_packages" class="tab-content">
<div id="tabset-29-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-29-1-tab">
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb118"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb118-1"><a href="#cb118-1" aria-hidden="true" tabindex="-1"></a>n_chains <span class="op">=</span> <span class="dv">4</span><span class="op">;</span> n_warmup <span class="op">=</span> <span class="dv">2000</span><span class="op">;</span> n_draws <span class="op">=</span> <span class="bu">int</span>(<span class="dv">1000</span><span class="op">/</span>n_chains)</span>
<span id="cb118-2"><a href="#cb118-2" aria-hidden="true" tabindex="-1"></a>cgr_model <span class="op">=</span> cmdstanpy.CmdStanModel(stan_file <span class="op">=</span> <span class="st">"stan_models/corr_fp_md_c.stan"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>INFO:cmdstanpy:found newer exe file, not recompiling</code></pre>
</div>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb120"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb120-1"><a href="#cb120-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> lnorm_params(mu, sigma):</span>
<span id="cb120-2"><a href="#cb120-2" aria-hidden="true" tabindex="-1"></a>    sdlog <span class="op">=</span> math.sqrt(math.log(<span class="dv">1</span> <span class="op">+</span> sigma<span class="op">**</span><span class="dv">2</span> <span class="op">/</span> mu<span class="op">**</span><span class="dv">2</span>))</span>
<span id="cb120-3"><a href="#cb120-3" aria-hidden="true" tabindex="-1"></a>    meanlog <span class="op">=</span> math.log(mu) <span class="op">-</span> <span class="fl">0.5</span> <span class="op">*</span> sdlog<span class="op">**</span><span class="dv">2</span></span>
<span id="cb120-4"><a href="#cb120-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {<span class="st">"sdlog"</span> : sdlog, <span class="st">"meanlog"</span> : meanlog}</span>
<span id="cb120-5"><a href="#cb120-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb120-6"><a href="#cb120-6" aria-hidden="true" tabindex="-1"></a>prior_depth_params <span class="op">=</span> lnorm_params(<span class="dv">10</span>, <span class="dv">6</span>)</span>
<span id="cb120-7"><a href="#cb120-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb120-8"><a href="#cb120-8" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> gen_model_data(inspection_df):</span>
<span id="cb120-9"><a href="#cb120-9" aria-hidden="true" tabindex="-1"></a>  model_data <span class="op">=</span> {</span>
<span id="cb120-10"><a href="#cb120-10" aria-hidden="true" tabindex="-1"></a>  <span class="st">"N"</span>: inspection_df.shape[<span class="dv">0</span>],</span>
<span id="cb120-11"><a href="#cb120-11" aria-hidden="true" tabindex="-1"></a>  <span class="st">"n_A"</span>: inspection_df.anomaly_id.nunique(),</span>
<span id="cb120-12"><a href="#cb120-12" aria-hidden="true" tabindex="-1"></a>  <span class="st">"n_M"</span>: inspection_df.missing.<span class="bu">sum</span>(),</span>
<span id="cb120-13"><a href="#cb120-13" aria-hidden="true" tabindex="-1"></a>  <span class="st">"ID"</span>: inspection_df.anomaly_id,</span>
<span id="cb120-14"><a href="#cb120-14" aria-hidden="true" tabindex="-1"></a>  <span class="st">"depth_i1"</span>: inspection_df[inspection_df.t <span class="op">==</span> years[<span class="dv">0</span>]].depth_mm,</span>
<span id="cb120-15"><a href="#cb120-15" aria-hidden="true" tabindex="-1"></a>  <span class="st">"depth_i2"</span>: inspection_df[inspection_df.t <span class="op">==</span> years[<span class="dv">1</span>]].depth_mm,</span>
<span id="cb120-16"><a href="#cb120-16" aria-hidden="true" tabindex="-1"></a>  <span class="st">"error_i1"</span>: inspection_df[inspection_df.inspection <span class="op">==</span> insps[<span class="dv">0</span>]].sizing_uncertainty,</span>
<span id="cb120-17"><a href="#cb120-17" aria-hidden="true" tabindex="-1"></a>  <span class="st">"error_i2"</span>: inspection_df[inspection_df.inspection <span class="op">==</span> insps[<span class="dv">1</span>]].sizing_uncertainty,</span>
<span id="cb120-18"><a href="#cb120-18" aria-hidden="true" tabindex="-1"></a>  <span class="st">"d_years"</span>: years.<span class="bu">max</span>() <span class="op">-</span> years.<span class="bu">min</span>(),</span>
<span id="cb120-19"><a href="#cb120-19" aria-hidden="true" tabindex="-1"></a>  <span class="st">"ex_1"</span>: inspection_df[inspection_df.t <span class="op">==</span> years[<span class="dv">0</span>]].missing,</span>
<span id="cb120-20"><a href="#cb120-20" aria-hidden="true" tabindex="-1"></a>  <span class="st">"ex_2"</span>: inspection_df[inspection_df.t <span class="op">==</span> years[<span class="dv">1</span>]].missing,</span>
<span id="cb120-21"><a href="#cb120-21" aria-hidden="true" tabindex="-1"></a>  <span class="st">"mu_mu_beta"</span>: <span class="dv">1</span>, <span class="st">"sigma_mu_beta"</span>: <span class="dv">1</span>, <span class="st">"rate_sigma_beta"</span>: <span class="dv">1</span>,</span>
<span id="cb120-22"><a href="#cb120-22" aria-hidden="true" tabindex="-1"></a>  <span class="st">"mu_depth_imp"</span>: prior_depth_params[<span class="st">"meanlog"</span>],</span>
<span id="cb120-23"><a href="#cb120-23" aria-hidden="true" tabindex="-1"></a>  <span class="st">"sigma_depth_imp"</span>: prior_depth_params[<span class="st">"sdlog"</span>]}</span>
<span id="cb120-24"><a href="#cb120-24" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span>(model_data)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</div>
</div>
</div>
<p>The below functions are used to extract results from the model:</p>
<div id="chunk_load_packages" class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-30-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-30-1" role="tab" aria-controls="tabset-30-1" aria-selected="true" href="">Python (using NumPy, Pandas, CmdStanPy)</a></li></ul>
<div id="chunk_load_packages" class="tab-content">
<div id="tabset-30-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-30-1-tab">
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb121"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb121-1"><a href="#cb121-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> corrosion_model(data):</span>
<span id="cb121-2"><a href="#cb121-2" aria-hidden="true" tabindex="-1"></a>  cgr_posterior <span class="op">=</span> Stan_Posterior(cgr_model.sample(data <span class="op">=</span> data, </span>
<span id="cb121-3"><a href="#cb121-3" aria-hidden="true" tabindex="-1"></a>                                                  seed <span class="op">=</span> <span class="dv">240819</span>, </span>
<span id="cb121-4"><a href="#cb121-4" aria-hidden="true" tabindex="-1"></a>                                                  iter_warmup <span class="op">=</span> n_warmup, </span>
<span id="cb121-5"><a href="#cb121-5" aria-hidden="true" tabindex="-1"></a>                                                  iter_sampling <span class="op">=</span> n_draws, </span>
<span id="cb121-6"><a href="#cb121-6" aria-hidden="true" tabindex="-1"></a>                                                  chains <span class="op">=</span> <span class="dv">4</span>, </span>
<span id="cb121-7"><a href="#cb121-7" aria-hidden="true" tabindex="-1"></a>                                                  parallel_chains <span class="op">=</span> multiprocessing.cpu_count()))</span>
<span id="cb121-8"><a href="#cb121-8" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span>(cgr_posterior.draws_df())</span>
<span id="cb121-9"><a href="#cb121-9" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb121-10"><a href="#cb121-10" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_costs(insp_df, results_df, t <span class="op">=</span> <span class="fl">12.7</span>, cost_repair <span class="op">=</span> <span class="dv">10</span><span class="op">**</span><span class="dv">4</span>, cost_fail <span class="op">=</span> <span class="dv">10</span><span class="op">**</span><span class="dv">5</span>):</span>
<span id="cb121-11"><a href="#cb121-11" aria-hidden="true" tabindex="-1"></a>  PoF_df <span class="op">=</span> pd.DataFrame(data <span class="op">=</span> {<span class="st">"anomaly"</span>: insp_df.anomaly_id.unique()})</span>
<span id="cb121-12"><a href="#cb121-12" aria-hidden="true" tabindex="-1"></a>  PoF <span class="op">=</span> []<span class="op">;</span> cost <span class="op">=</span> []<span class="op">;</span> action <span class="op">=</span> []</span>
<span id="cb121-13"><a href="#cb121-13" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> i <span class="kw">in</span> insp_df.anomaly_id.unique():</span>
<span id="cb121-14"><a href="#cb121-14" aria-hidden="true" tabindex="-1"></a>      <span class="bu">id</span> <span class="op">=</span> <span class="st">"depth_true_i2["</span> <span class="op">+</span> <span class="bu">str</span>(i) <span class="op">+</span> <span class="st">"]"</span></span>
<span id="cb121-15"><a href="#cb121-15" aria-hidden="true" tabindex="-1"></a>      depth <span class="op">=</span> np.array(results_df[<span class="bu">id</span>] <span class="op">+</span> results_df[<span class="st">"CGR_pp"</span>])</span>
<span id="cb121-16"><a href="#cb121-16" aria-hidden="true" tabindex="-1"></a>      PoF.append((depth <span class="op">&gt;=</span> t).<span class="bu">sum</span>() <span class="op">/</span> <span class="bu">len</span>(depth))</span>
<span id="cb121-17"><a href="#cb121-17" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb121-18"><a href="#cb121-18" aria-hidden="true" tabindex="-1"></a>  PoF_df[<span class="st">"PoF"</span>] <span class="op">=</span> np.array(PoF)</span>
<span id="cb121-19"><a href="#cb121-19" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> i <span class="kw">in</span> PoF_df.PoF:</span>
<span id="cb121-20"><a href="#cb121-20" aria-hidden="true" tabindex="-1"></a>      <span class="cf">if</span> i <span class="op">*</span> cost_fail <span class="op">&lt;</span> cost_repair:</span>
<span id="cb121-21"><a href="#cb121-21" aria-hidden="true" tabindex="-1"></a>          cost.append(i <span class="op">*</span> cost_fail)</span>
<span id="cb121-22"><a href="#cb121-22" aria-hidden="true" tabindex="-1"></a>          action.append(<span class="st">"No action"</span>)</span>
<span id="cb121-23"><a href="#cb121-23" aria-hidden="true" tabindex="-1"></a>      <span class="cf">else</span>:</span>
<span id="cb121-24"><a href="#cb121-24" aria-hidden="true" tabindex="-1"></a>          cost.append(cost_repair)</span>
<span id="cb121-25"><a href="#cb121-25" aria-hidden="true" tabindex="-1"></a>          action.append(<span class="st">"Repair"</span>)</span>
<span id="cb121-26"><a href="#cb121-26" aria-hidden="true" tabindex="-1"></a>  PoF_df[<span class="st">"cost"</span>] <span class="op">=</span> np.array(cost)</span>
<span id="cb121-27"><a href="#cb121-27" aria-hidden="true" tabindex="-1"></a>  PoF_df[<span class="st">"action"</span>] <span class="op">=</span> np.array(action)</span>
<span id="cb121-28"><a href="#cb121-28" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span>(PoF_df)</span>
<span id="cb121-29"><a href="#cb121-29" aria-hidden="true" tabindex="-1"></a>  </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</div>
</div>
</div>
<p>The decision analysis consists of identifying the expected optimal repairs to perform, based on an expected repair cost of <span class="math inline">\(\$10,000\)</span> and an expected failure cost, per anomaly of <span class="math inline">\(\$100,000\)</span>.</p>
<div id="chunk_load_packages" class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-31-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-31-1" role="tab" aria-controls="tabset-31-1" aria-selected="true" href="">Python</a></li></ul>
<div id="chunk_load_packages" class="tab-content">
<div id="tabset-31-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-31-1-tab">
<p>Solving the prior decision problem identifies for which anomalies a repair is expected to be worthwhile, as shown in <a href="#tbl-corrosion_model_inputs">Table&nbsp;3</a>. The total cost is the prior expected cost.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb122"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb122-1"><a href="#cb122-1" aria-hidden="true" tabindex="-1"></a>model_data <span class="op">=</span> gen_model_data(insp_data)</span>
<span id="cb122-2"><a href="#cb122-2" aria-hidden="true" tabindex="-1"></a>cgr_results <span class="op">=</span> corrosion_model(data <span class="op">=</span> model_data)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb123"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb123-1"><a href="#cb123-1" aria-hidden="true" tabindex="-1"></a>costs_df <span class="op">=</span> get_costs(insp_df <span class="op">=</span> insp_data, results_df <span class="op">=</span> cgr_results)</span>
<span id="cb123-2"><a href="#cb123-2" aria-hidden="true" tabindex="-1"></a>prior_exp_cost <span class="op">=</span> costs_df.cost.<span class="bu">sum</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<div class="cell-output-display">
<div id="tbl-corrosion_model_inputs" class="anchored">
<table class="table table-sm table-striped">
<caption>Table 3: Expected Optimal Repair Plan for 10 Corrosion Anomalies</caption>
<thead>
<tr class="header">
<th style="text-align: right;">Anomaly</th>
<th style="text-align: right;">Cost, £</th>
<th style="text-align: left;">Expected optimal action</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">1</td>
<td style="text-align: right;">0</td>
<td style="text-align: left;">No action</td>
</tr>
<tr class="even">
<td style="text-align: right;">2</td>
<td style="text-align: right;">0</td>
<td style="text-align: left;">No action</td>
</tr>
<tr class="odd">
<td style="text-align: right;">3</td>
<td style="text-align: right;">10000</td>
<td style="text-align: left;">Repair</td>
</tr>
<tr class="even">
<td style="text-align: right;">4</td>
<td style="text-align: right;">4200</td>
<td style="text-align: left;">No action</td>
</tr>
<tr class="odd">
<td style="text-align: right;">5</td>
<td style="text-align: right;">10000</td>
<td style="text-align: left;">Repair</td>
</tr>
<tr class="even">
<td style="text-align: right;">6</td>
<td style="text-align: right;">0</td>
<td style="text-align: left;">No action</td>
</tr>
<tr class="odd">
<td style="text-align: right;">7</td>
<td style="text-align: right;">0</td>
<td style="text-align: left;">No action</td>
</tr>
<tr class="even">
<td style="text-align: right;">8</td>
<td style="text-align: right;">5600</td>
<td style="text-align: left;">No action</td>
</tr>
<tr class="odd">
<td style="text-align: right;">9</td>
<td style="text-align: right;">100</td>
<td style="text-align: left;">No action</td>
</tr>
<tr class="even">
<td style="text-align: right;">10</td>
<td style="text-align: right;">3400</td>
<td style="text-align: left;">No action</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<div class="cell">
<div class="cell-output-display">
<div id="fig-cgr" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="DCE_guidance_files/figure-html/fig-cgr-1.png" class="img-fluid figure-img" width="672"></p>
<p></p><figcaption class="figure-caption">Figure 20: Probabilistic Estimate of Corrosion Growth Rate, mm/year</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>The estimated corrosion growth rate, as shown in <a href="#fig-cgr">Figure&nbsp;20</a>, was estimated using the measurements from the inspection data. As shown in <a href="#fig-corrosion_depths">Figure&nbsp;21</a> the precision with which the corrosion anomalies have been sized varied between the inspections. However, in both cases, there is less uncertainty about the size of a measured extent of damage, than an imputed extent.</p>
<p>The imputed corrosion depth at anomaly 4 was jointly estimated with the corrosion growth rate in the <code>Stan</code> model. It is a probabilistic estimate consistent with the data that <em>is</em> available, i.e.&nbsp;the inspection measurements from the other anomalies and the below prior model.</p>
<p><span class="math display">\[
d_{A 4, insp. 2} \sim LogNormal(\mu = 10, \sigma = 6)
\]</span></p>
<p>This is an example of how a prior can be identified for a value that is intended to be measured by using other available, relevant information. This method is known as missing data imputation <span class="citation" data-cites="Reg&amp;OtherStories">(<a href="#ref-Reg&amp;OtherStories" role="doc-biblioref"><strong>Reg&amp;OtherStories?</strong></a>)</span>.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-corrosion_depths" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="DCE_guidance_files/figure-html/fig-corrosion_depths-1.png" class="img-fluid figure-img" width="576"></p>
<p></p><figcaption class="figure-caption">Figure 21: Probabilistic Models for Imputed and Measured Corrosion Damage</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>Quantifying the expected value of returning the location of anomaly 4 and completing this measurement, requires sampling from the imputed prior model which effectively describes what is expected to be measured.</p>
<p>Another important feature of this model is that there is some defined precision of the measurement activity. The data that will be obtained is imperfect. The impact of this on the calculation is that for each hypothesised measurement (sample from the prior model), the imperfect data is combined with the prior to produce a probabilistic posterior distribution of the extent of the damage at anomaly 4. The associated corrosion growth rate is also calculated, now using the updated inspection data, and the subsequent forecasting and decision analysis is completed.</p>
<p>This example is based on a published calculation <span class="citation" data-cites="DiFrancesco2022">(<a href="#ref-DiFrancesco2022" role="doc-biblioref"><strong>DiFrancesco2022?</strong></a>)</span>, which also considers other imperfect features of inspection data, such as reliability. Imperfect data will always be less valuable than perfect data, but perfect data is never available in practice. Increasingly precise and reliable data will have a higher (or at least an equivalent) expected value to a decision-maker and value of information analysis can be used to identify when it is expected to be worth paying more for <em>better quality</em> data.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb124"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb124-1"><a href="#cb124-1" aria-hidden="true" tabindex="-1"></a>depths_i1 <span class="op">=</span> np.array(model_data[<span class="st">"depth_i1"</span>])</span>
<span id="cb124-2"><a href="#cb124-2" aria-hidden="true" tabindex="-1"></a>depths_i2 <span class="op">=</span> np.array(model_data[<span class="st">"depth_i2"</span>])</span>
<span id="cb124-3"><a href="#cb124-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-4"><a href="#cb124-4" aria-hidden="true" tabindex="-1"></a>prepost_df <span class="op">=</span> pd.DataFrame()</span>
<span id="cb124-5"><a href="#cb124-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> depth <span class="kw">in</span> np.sort(cgr_results[<span class="st">"depth_true_i2[4]"</span>]):</span>
<span id="cb124-6"><a href="#cb124-6" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb124-7"><a href="#cb124-7" aria-hidden="true" tabindex="-1"></a>    model_data_iter <span class="op">=</span> model_data<span class="op">;</span> insp_data_iter <span class="op">=</span> insp_data</span>
<span id="cb124-8"><a href="#cb124-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-9"><a href="#cb124-9" aria-hidden="true" tabindex="-1"></a>    depths_i2[<span class="dv">3</span>] <span class="op">=</span> depth    </span>
<span id="cb124-10"><a href="#cb124-10" aria-hidden="true" tabindex="-1"></a>    model_data_iter[<span class="st">"depth_i2"</span>] <span class="op">=</span> depths_i2</span>
<span id="cb124-11"><a href="#cb124-11" aria-hidden="true" tabindex="-1"></a>    model_data_iter[<span class="st">"ex_2"</span>] <span class="op">=</span> np.repeat(a <span class="op">=</span> <span class="dv">0</span>, repeats <span class="op">=</span> <span class="bu">len</span>(depths_i2))</span>
<span id="cb124-12"><a href="#cb124-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-13"><a href="#cb124-13" aria-hidden="true" tabindex="-1"></a>    insp_data_iter.depth <span class="op">=</span> np.concatenate((depths_i1, depths_i2))</span>
<span id="cb124-14"><a href="#cb124-14" aria-hidden="true" tabindex="-1"></a>    insp_data_iter.depth[<span class="dv">13</span>] <span class="op">=</span> depth</span>
<span id="cb124-15"><a href="#cb124-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-16"><a href="#cb124-16" aria-hidden="true" tabindex="-1"></a>    prepost_df <span class="op">=</span> pd.concat((prepost_df, </span>
<span id="cb124-17"><a href="#cb124-17" aria-hidden="true" tabindex="-1"></a>                            pd.DataFrame(data <span class="op">=</span> {<span class="st">"d_insp"</span>: depth, </span>
<span id="cb124-18"><a href="#cb124-18" aria-hidden="true" tabindex="-1"></a>                                                 <span class="st">"cost"</span>: get_costs(insp_df <span class="op">=</span> insp_data_iter, </span>
<span id="cb124-19"><a href="#cb124-19" aria-hidden="true" tabindex="-1"></a>                                                                   results_df <span class="op">=</span> corrosion_model(data <span class="op">=</span> model_data_iter)).cost.<span class="bu">sum</span>()}, </span>
<span id="cb124-20"><a href="#cb124-20" aria-hidden="true" tabindex="-1"></a>                                        index <span class="op">=</span> [<span class="dv">0</span>])))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">

</div>
<p>The expected value of (an imperfect) inspection at the site of corrosion anomaly 4, can then be calculated:</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb125"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb125-1"><a href="#cb125-1" aria-hidden="true" tabindex="-1"></a>VoInsp <span class="op">=</span> prior_exp_cost <span class="op">-</span> prepost_df.cost.mean()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</div>
</div>
</div>
</section>
</section>
</section>
</section>
<section id="summary" class="level1" data-number="5">
<h1 data-number="5"><span class="header-section-number">5</span> Summary</h1>
<p>Key concepts:</p>
<ul>
<li>Due to the complexity of materials, geometries, system inter-dependencies, and the limitations in measurement technologies, there will inevitably be uncertainties associated with engineering calculations.</li>
<li>These uncertainties can be described using probability distributions, which combine and interact in probabilistic models. Giving these models starting points (priors) based on existing knowledge within engineering teams can greatly benefit these models, particularly when there is limited information in available data.</li>
<li>After defining, checking, fitting (and evaluating) these models, they can be used to help formally identify expected optimal risk management decisions, using computational tools, such as influence diagrams.</li>
<li>These methods explicitly link the engineering models and data analysis, to the underlying decision problem that they are intended to solve. This results in a transparent and replicable (auditable) workflow, and allows for some useful calculations to be performed, such as quantifying the expected value of further data collection.</li>
<li>The expected value of, for instance; installing a sensor, performing a measurement, or completing a calculation, can then be compared to the associated cost for the activity. When the expected value to an organisation exceeds the cost they are required to pay for the data, the investment can be justified.</li>
<li>The calculations provided in this document show examples that can broadly be categorised as data requirements for risk management of the built environment. However, the principles are generic, as demonstrated by the variety of methods that have been used to solve them using relatively small amounts of code in freely available software.</li>
<li>Moving towards principled, quantitative, replicable engineering decision support is expected to be an important step in integrating computational statistics in data-centric engineering.</li>
</ul>
<p><!-- - When data is abundant, the benefit of UQ, prior knowledge, and model structure may sometimes diminish, and greater performance may be obtained from *black-box* type models, such as neural networks. These models are still compatible with decision analysis, but quantification of the expected value of additional data collection requires a generative structure that describes what is expected to be measured, and where this prospective data fits in the context of solving the decision problem. --></p>
<p>Please feel free to contact <a href="ddifrancesc@turing.ac.uk">Domenic Di Francesco</a>, or in the <a href="">Github page</a> if you have any queries or comments.</p>
</section>
<section id="acknowledgements" class="level1" data-number="6">
<h1 data-number="6"><span class="header-section-number">6</span> Acknowledgements</h1>
<p>list all contributors, reviewers, and funding</p>
<p>…</p>
<!-- -->


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" role="doc-bibliography">
<div id="ref-Gelman2014" class="csl-entry" role="doc-biblioentry">
Gelman, Andrew, John B B Carlin, Hal S S Stern, and Donald B B Rubin. 2014. <em><span>Bayesian Data Analysis</span></em>. Edited by Francesca Dominici, Julian J. Faraway, Martin Tanner, and Jim Zidek. 3rd ed. Chapman &amp; Hall / CRC. <a href="https://doi.org/10.1007/s13398-014-0173-7.2">https://doi.org/10.1007/s13398-014-0173-7.2</a>.
</div>
<div id="ref-Gelman2020" class="csl-entry" role="doc-biblioentry">
Gelman, Andrew, Jennifer Hill, and Aki Vehtari. 2020. <em><span class="nocase">Regression and Other Stories</span></em>. Edited by R. Michael Alvarez, Nathaniel L. Beck, Stephen L. Morgan, and Lawrence L. Wu. First. Cambridge University Press. <a href="https://doi.org/10.1017/9781139161879">https://doi.org/10.1017/9781139161879</a>.
</div>
<div id="ref-Ghahramani2015" class="csl-entry" role="doc-biblioentry">
Ghahramani, Zoubin. 2015. <span>“<span class="nocase">Probabilistic machine learning and artificial intelligence</span>.”</span> <em>Nature</em> 521 (7553): 452–59. <a href="https://doi.org/10.1038/nature14541">https://doi.org/10.1038/nature14541</a>.
</div>
<div id="ref-copula" class="csl-entry" role="doc-biblioentry">
Hofert, Marius, Ivan Kojadinovic, Martin Maechler, and Jun Yan. 2022. <span>“Copula: Multivariate Dependence with Copulas.”</span> <a href="https://CRAN.R-project.org/package=copula">https://CRAN.R-project.org/package=copula</a>.
</div>
<div id="ref-Jaynes2003" class="csl-entry" role="doc-biblioentry">
Jaynes, Edwin T. 2003. <em><span class="nocase">Probability Theory: The Logic of Science</span></em>. First. New York: Cambridge University Press.
</div>
<div id="ref-Jordaan2005" class="csl-entry" role="doc-biblioentry">
Jordaan, Ian. 2005. <em><span class="nocase">Decisions under Uncertainty</span></em>. Cambridge University Press. <a href="https://doi.org/10.1017/CBO9780511804861">https://doi.org/10.1017/CBO9780511804861</a>.
</div>
<div id="ref-McElreath2019" class="csl-entry" role="doc-biblioentry">
McElreath, Richard. 2020. <em><span class="nocase">Statistical Rethinking : A Bayesian Course with Examples in R and Stan</span></em>. 2nd ed. Chapman &amp; Hall / CRC. <a href="https://xcelab.net/rm/statistical-rethinking/">https://xcelab.net/rm/statistical-rethinking/</a>.
</div>
<div id="ref-Melchers2018" class="csl-entry" role="doc-biblioentry">
Melchers, Robert E., and André T. Beck. 2018. <em><span class="nocase">Structural Reliability Analysis and Prediction</span></em>. Third Edit. John Wiley &amp; Sons Ltd.
</div>
<div id="ref-Rainforth2017" class="csl-entry" role="doc-biblioentry">
Rainforth, Tom. 2017. <span>“<span class="nocase">Automating Inference, Learning, and Design using Probabilistic Programming</span>.”</span> PhD thesis, University of Oxford. <a href="http://www.robots.ox.ac.uk/$\sim$twgr/assets/pdf/rainforth2017thesis.pdf">http://www.robots.ox.ac.uk/$\sim$twgr/assets/pdf/rainforth2017thesis.pdf</a>.
</div>
</div></section></div></main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      let href = ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<pre class="markdown" data-shortcodes="false"><code>---
title: "Data-Centric Engineering"
subtitle: "Guidance on the Use of Probabilistic Methods for Identifying Data Requirements"
author: "Domenic Di Francesco, PhD, CEng"
date: "November 2022"
format:
  html:
    knitr: true 
    theme: 
      - simplex
    highlight-style: atom-one
    html-math-mathod: mathjax
    toc: true
    # toc-location: top
    number-sections: true
    code-copy: true
    code-fold: true
    code-tools: true
    code-overflow: scroll
    monofont: Fira Code
    mermaid-format: js
execute:
  message: false
  warning: false
bibliography: references.bib
---

# Introduction

## Purpose of this Document

The various new methods of collecting and analysing data that are increasingly available to engineers can contribute to improvements in the safety and efficiency of the built environment. However, understanding the quantity and quality of data required will continue to be a challenge to engineers. For instance:

 * Should sensing systems be retrofit to existing structures? 
 * If so, how precise and how reliable do they need to be? 
 * How can we value data from smart meters? 
 * To what extent does measuring building occupancy help mitigate the risk of infection from airborne disease?

The principles of data-centric engineering are not new. Engineers have always had to rely on empirical models that are supported by tests to demonstrate that systems are reliable and safe. However, given the recent advancements in the availability of free, open-source software tools for data analysis and statistical inference, there is an opportunity to improve engineering workflows. The guidance presented here is intended to be pragmatic and introductory. Example problems are presented `r #(with reference to Eurocodes, Standards and Material Specifications)` alongside accompanying code implementations. There is a focus on answering meaningful questions, supporting decision making, and ensuring reproducible and reliable results.

&lt;q&gt; Uncertainty accompanies our lives. Coherent modelling of uncertainties for decision-making is essential in engineering and related disciplines.

[@Jordaan2005]

## How to use this document

This is a computational document that includes chunks of `Python`, `R`, and `Julia` code necessary to analyse the data, and solve the decision problems in the various examples. To achieve this, various libraries/packages have been used, and these will need to be installed and loaded for the code to run.

::: {#chunk_load_packages .panel-tabset}
## Load Python Packages

quarto-executable-code-5450563D

```python
import cmdstanpy, requests, os, multiprocessing, math
import numpy as np, pandas as pd
from scipy import stats

```

## Load R Packages

quarto-executable-code-5450563D

```R
library(tidyverse); library(fitdistrplus); library(boot)
library(cmdstanr); library(copula); library(ggthemes)
library(lhs); library(parallel); library(TruncatedNormal)

```

## Load Julia Packages

quarto-executable-code-5450563D

```julia
using CSV, DataFrames, DataFramesMeta, Printf
using Random, Distributions, Bootstrap, Copulas, LatinHypercubeSampling
using JuMP, HiGHS, DecisionProgramming, Turing, LinearAlgebra

```

:::

:::{.callout-tip collapse="true"}
## Tip: Loading packages
In `R`, `Python` and `Julia` packages first need to be installed. Guidance on installing packages can be found [here](https://support.rstudio.com/hc/en-us/articles/201057987-Quick-list-of-useful-R-packages) (for `R`),  [here](https://pypi.org/project/pip/) (for `Python`), and [here](https://docs.julialang.org/en/v1/stdlib/Pkg/) for `Julia`. 

Packages only need to be installed once (unless they are uninstalled), but then need to be loaded each time you want to make direct use of the functions or data they contain. This document will not detail the workings of each package, but such information can be found online, for example [here](https://pandas.pydata.org) is the website for the `Python` 'pandas' package.
:::

In addition, some statistical models that have been written in the probabilistic programming language `Stan` have been used. The data used in the examples, as well as the code used for each exercise can be freely downloaded from this [public Github repository](https://github.com/DomDF/DCE_guidance).

Such calculations could also be performed using spreadsheet software. The primary reasons for not providing accompanying spreadsheet files to run the example calculations, are as follows:

 - When running challenging simulations, or working with large amounts of data, spreadsheets may become unmanageably slow.
 - Spreadsheet software has reproducibility challenges. Data can be difficult to distinguish from calculated quantities, and the sequence of calculations can also be difficult to identify. 
 - Calculations using spreadsheets are often unreliable. Errors *arise* in spreadsheets for many reasons, such as obscuring (or deleting) data, incorrect assumptions regarding data types, uninterpretable functions, and automatic filling. Errors often *remain* in spreadsheets due to the challenges associated with testing, documenting and version control.

Some notable examples of high consequence spreadsheet errors are recorded by the European Spreadsheet Risks Interest Group [(EuSpRiG)](http://www.eusprig.org) and further discussion on the incompatibility of spreadsheets and good data management (in the context of research) can be found in a presentation from Monash University, [here](https://www.youtube.com/watch?v=-NuTlczV72Q&amp;t=35s).

## Some other Published Guidance for Engineers

 - The UK Health &amp; Safety Executive produced a guidance document on the use of probabilistic methods in engineering [@HSE2002]. This is perhaps the most similar to this document regarding the aim and intended use. It provides an overview of limitations of probabilistic methods, however many of the criticisms can be resolved (at least to some extent) using some of the computational approaches in this document.
 - BS 7910 is a widely used industrial standard for assessing damage in welded steel structures [@BSI2015]. The evolution of this standard over recent decades is an interesting example of how more complex approaches have been gradually introduced to industry, in line with the increasing demands from structures, and increasing availability of computational resources to engineers. A recent addition has been Annex K, which considers probabilistic methods. However, evaluating the reliability of a damaged structure and completing a pass/fail type (deterministic) assessment using conservative inputs are two fundamentally different approaches. There is not currently sufficient guidance in this standard to model uncertainty in a helpful or meaningful way. Similarly, a guidance document for the nuclear industry [@NuclearWorkingGroup] has similar limitations.
 - The most comprehensive guidance on modelling uncertainty in the built environment can be found in the probabilistic model code, developed by the joint committee of structural safety [@JCSS]. This series of documents considers uncertainties in applied loads, material properties, measurements, and model predictions. Much of this guidance was incorporated in the COST Action TU1402 project case studies on quantifying the expected value of structural health monitoring systems [@COSTActionTU1402]. This document is intended to provide some more interactive examples than those included by the JCSS, by including example code. It also addresses some of the challenges identified by the JCSS, specifically regarding characterisation of dependencies in multi-variate probabilistic models, and interpretation of results of structural reliability analysis.
 - As well as documents that are intended to be used in industry, there are also several engineering textbooks that introduce concepts in uncertainty quantification, and decision support in the context of engineering challenges [@Benjamin2014, @Jordaan2005, @Faber2012]. These books all consider, to some extent, quantification of the expected value of data to engineers.

# Uncertainty in the Built Environment

Engineering standards acknowledge the presence of variability in the quantities they are dealing with, but do not always provide guidance on how to apply models of variability, particularly in supporting decision making. For example, repeated strength tests of specimens from the same material, using the same machine, in the same lab will produce differing, (though hopefully similar) results. Any decision on whether a material is safe to use must therefore account for this variability somehow.

Historically, structural engineers have used deterministic approaches to perform conservative assessments. In this example a *safe* or *characteristic* value of strength may be taken, such as the minimum from a set of measurements. The premise of this approach is that, if the lowest measurement meets a requirement, then it is expected to be OK. These kind of heuristics do not tell us how many tests are needed to be confident that the lowest measurement is representative, since each new measurement provides an opportunity to find a new lowest strength. As a result, unquantified and implicit margins of conservatism are introduced, making it very difficult to find the best estimates of risk that are required to justify spending consistently and coherently.

This can be resolved by using probability to formally quantify uncertainty, and various examples of this are presented in this document. Statistical models of variability can describe how many uncertain quantities can be dependent, how uncertainty can increase when making predictions over various time frames, and how uncertainty can decrease when new data becomes available. Uncertainty quantification therefore allows for many other types of analysis, such as identifying where, when and how additional data should be collected, which is the focus of this document.

While data will generally always provide some value, provided that it is relevant, it will not always represent a good investment. There are various costs associated with collecting engineering data, including hiring/purchasing specialised measurement equipment, the storage costs of high-volume streaming data, and occasionally the risk associated with exposing personnel to hazardous environments to collect data. Justifying these costs require engineers to link data collection to the improved decision making that it facilitates. 

Without formal methods of uncertainty quantification, engineers may differ in opinion about data collection strategy. Quantitative approaches will be preferable because they are auditable. As demonstrated in the examples in this document, these approaches do not remove engineering input from this process, but rather include expert knowledge in a formal way. Unless both available data, and subject matter expertise are used to inform decisions, then some information is not being taken advantage of.

# Quantifying Uncertainty

As described in the below note, there are many appealing reasons to use probability to describe variability.

:::{.callout-note collapse="true"}
## Thought: Using Probabilities

It has been proposed that since probability is the mathematical language of randomness, it should be used to model the uncertainties that arise [@Gelman2014]. Another compelling argument is that the practical meaning of probability is intuitive. Probabilities can be assigned to possible (uncertain) outcomes in decision problems.

Understanding how to estimate these probabilities as well as how to use them allows for coherent and replicable (auditable) decision making. The statistics presented in this document are with the intention of providing this kind of pragmatic guidance.

:::

There are many established probability distributions, and some reasonable question regarding their application in engineering calculations, include:

-   Where do distributions come from?
-   When are they useful, or unhelpful in describing variability in engineering quantities?

One common method of visualising of the Normal distribution is using a [Galton board](https://en.wikipedia.org/wiki/Galton_board). A number of beads hit a series of pegs as they fall to the base of the board. When they arrive at the base, they can be seen to approximate a Normal distribution. This can also be replicated using computer simulations, but in any case, it suggests that distribution functions are not arbitrary. 

A similar example is presented in [@McElreath2019], where the author counts the number of possible arrangements of items that are hidden under buckets. Because there are more ways to hide these items evenly under the buckets, this is considered the most likely outcome (without any additional information). Running simulations (or other experiments) using this example will produce a Uniform distribution.

Both the Galton board and hidden items example show how a distribution can represent the most likely outcome of some event(s). They are said to be *Max*imum *Ent*ropy (MaxEnt) solutions for those problems. Using this principle is often recommended for deciding on a statistical model with very limited information about the problem [@Jaynes2003]. Some mathematical proofs of various MaxEnt models are presented in [@Jordaan2005].

More generally though, engineers may need to impose some additional features and constrains in their models (to represent their knowledge of the system being analysed). Probability distributions can then be considered as helpful tools to represent uncertainty. Prior predictive checks (see Section X) can be used to ensure that the selected distribution are resulting in appropriate results on an intuitive outcome scale. 

## Working with Probability Distributions

Modern programming languages have many functions for evaluating, integrating, sampling, and estimating parameters from probability distributions. The below examples show how $10$ independent samples can be drawn from a normal distribution, with a mean value of $0$ and a standard deviation of $1$.

::: panel-tabset
## Python (using SciPy)

quarto-executable-code-5450563D

```python
stats.norm.rvs(size = 10, loc = 0, scale = 1)

```

## R

quarto-executable-code-5450563D

```R
rnorm(n = 10, mean = 0, sd = 1)

```

## Julia (using Distributions, Random)

quarto-executable-code-5450563D

```julia
Normal(0, 1) |&gt; x -&gt; rand(x, 10)

```
:::

Many more samples are typically required for them to be considered a sufficient characterisation of the distribution. Various *variance reduction* methods have been developed, so that sampling problems can be solved using fewer samples, therefore requiring less computational effort. These include *importance sampling*, and *latin hypercube sampling*, and examples of the latter are presented below.

::: panel-tabset
## Python (using SciPy)

quarto-executable-code-5450563D

```python
def lhs(n_samples, dim = 1):
  probs = stats.qmc.LatinHypercube(dim).random(n_samples)
  return probs
  
stats.norm.ppf(lhs(10), loc = 0, scale = 1)

```

## R (using lhs)

quarto-executable-code-5450563D

```R
lhs &lt;- function(n_samples, dim){
  randomLHS(n = n_samples, k = dim) 
}

(lhs(10, 1) |&gt; qnorm(mean = 0, sd = 1))[,1]

```
## Julia (using LatinHypercubeSampling)

quarto-executable-code-5450563D

```julia
function draw_lhs(dist, n::Int)
    samples = randomLHC(n + 2, 1) |&gt;
        x -&gt; scaleLHC(x, [(0, 1)]) |&gt;
        x -&gt; quantile(dist, x)[:,1] |&gt;
        x -&gt; filter(!∈((-Inf, Inf)), x)
    return samples
end

draw_lhs(Normal(0, 1), 10)
```
:::

Latin hypercube sampling ensures more evenly spaced samples than standard (inverse-transform, Monte Carlo sampling) [@Olsson2003]. The effect of this is shown in  in @fig-it_lhs.

quarto-executable-code-5450563D

```R
#| echo: false
#| label: fig-it_lhs
#| fig-cap: "Effect of sample size on methods of approximating a standard normal distribution"

set.seed(seed = 1008); sampling_df &lt;- tibble()

for(n_samples in c(20, 100, 1000)){

    probs &lt;- lhs::randomLHS(n = n_samples, k = 1)
    lhs_df &lt;- tibble(samples = qnorm(p = probs[,1]), method = "LH Sampling", n = n_samples)
    ind_df &lt;- tibble(samples = rnorm(n = n_samples), method = "IT Sampling", n = n_samples)

    sampling_df &lt;- bind_rows(sampling_df, lhs_df, ind_df)

}

ggplot(data = sampling_df |&gt; 
    mutate(n = paste(n, "samples")) |&gt;
    mutate(n = forcats::as_factor(n)), 
    mapping = aes(x = samples))+
    geom_histogram(mapping = aes(y = after_stat(x = density)), 
                  col = 'black', alpha = 1/2, bins = 15, position = position_dodge())+
    facet_grid(method ~ n)+
    stat_function(fun = dnorm, geom = 'line', mapping = aes(col = 'True function, Normal(0, 1)'))+
    labs(x = "", y = "Probability density")+
    ggthemes::theme_base(base_family = "Atkinson Hyperlegible", base_size = 11)+
    theme(legend.title = element_blank(), legend.position = 'top', plot.background = element_rect(colour = NA))

```

Sampling from distributions converts mathematically challenging statistical problems to simpler data analysis problems. Consider the basic problem of structural reliability, where an engineer is tasked with identifying the probability of an uncertain load, $L$, exceeding a components uncertain resistance, $R$, to that load. This would represent the probability of the component failing, due to this load - a very important quantity for supporting inspection and maintenance decisions!


$$
\Pr(fail) = \Pr(L \geq R)
$$
The probability of failure defined by the convolution integral, which only has analytical solutions for some simple examples: 

$$
\Pr(L \geq R) = \int_{L \geq R} \int f(r, s) \; dr \; ds
$$

Alternatively, the solution can be approximated by counting the number of samples from the load model that exceed samples from the resistance model. Each set of samples can be considered as a possible outcome (realisation) from the models, so the proportion of samples where the load exceeds the resistance therefore represents the probability of failure. 

Using `Python`, `R` or `Julia`, it is now possible run millions of such simulations relatively quickly (though this will depend on the complexity of the load and resistance models), and this allows engineers to find solutions that could be difficult to obtain mathematically.

As a simple example, consider the series (or 'weakest link') arrangement of components in @fig-series_system.

quarto-executable-code-5450563D

```mermaid
%%| label: fig-series_system
%%| fig-cap: "Diagram of Structural Components in Series Connection"

graph LR
        START[ ] --- A[Component 1]
        A --- B[Component 2]
        B --- C[Component 3]
        C --- STOP[ ]

        style START fill:#FFFFFF, stroke:#FFFFFF;
        style STOP  fill:#FFFFFF, stroke:#FFFFFF;
          
```

Such systems will fail when any of the components fail. If the below distributions describe the uncertainty in the applied loads and resistances, then it is possible the estimate the probability of failure by sampling from these distributions and evaluating the proportion of simulations associated with failure. 

$$
R_{1} \sim Normal(\mu = 17, \sigma = 2)
$$

$$
R_{2} \sim Normal(\mu = 16, \sigma = 3/2)
$$

$$
R_{3} \sim LogNormal(log\mu = 2.7, log\sigma = 0.07)
$$

::: panel-tabset
## Python (using SciPy)

quarto-executable-code-5450563D

```python
# TBC

```

## R

quarto-executable-code-5450563D

```R
set.seed(seed = 240819); n_samples &lt;- 10^6

# TBC

```
## Julia (using Distributions, Random)

quarto-executable-code-5450563D

```julia
#| output: false
#| 
L = Normal(10, 2)
R₁ = Normal(17, 2); R₂ = Normal(16, 3/2); R₃ = LogNormal(2.70, 0.07)

prng = MersenneTwister(240819); n_samples = 10^6
β_df = DataFrame(R₁ = rand(prng, R₁, n_samples), 
    R₂ = rand(prng, R₂, n_samples),
    R₃ = rand(prng, R₃, n_samples),
    L = rand(prng, L, n_samples))

β_df.fail = (β_df.L .&gt;= β_df.R₁) .| (β_df.L .&gt;= β_df.R₂) .| (β_df.L .&gt;= β_df.R₃) 

pof = sum(β_df.fail) / n_samples

```

quarto-executable-code-5450563D

```julia
#| echo: false
pof
```
:::

## Multi-Variate Distributions

In the above, the resistance parameters of the components are independent. This means that knowing that the resistance of Component A is relatively high, does not provide any information about the likely resistance of the other components. However, if the factors influencing the resistance were common, then a relatively high value for one component would suggest that a relatively high value for the other components were more likely. In such cases, this dependency should be accounted for in the probabilistic model.

One method for achieving this is to use copula functions [@copula]. There are various types of copula, but in each case they describe the dependency between the different constituent (marginal) components of a multi-variate probabilistic model.

Copulas can be used to model complex dependency, for example weakly dependent at relatively low values and highly dependent at relatively high values (or vice versa). In this case a Gaussian copula is used, which can only model linear dependency using correlation coefficients $\rho$. Note that copulas (including Gaussian copulas) can be used to describe dependency between parameters, for any uni-variate (marginal) distributions. The resulting distribution may not be possible to define, and use in calculations, without copulas.

$$
\rho_{R_{1}, R_{2}} = 0.8
$$

$$
\rho_{R_{1}, R_{3}} = 0.6
$$
$$
\rho_{R_{1}, R_{2}} = 0.4
$$

::: panel-tabset
## Python (using SciPy)

quarto-executable-code-5450563D

```python
# TBC

```

## R

quarto-executable-code-5450563D

```R
set.seed(seed = 240819); n_samples &lt;- 10^6

# TBC

```

## Julia (using Distributions, Random, Copulas)

quarto-executable-code-5450563D

```julia
#| output: false
#| 
function convert_logsd(log_μ, log_σ)
    σ = exp(log_μ + 1/2 * log_σ^2) * sqrt(exp(log_σ^2) - 1)
    return(σ)
    end

function convert_logmean(log_μ, log_σ)
    μ = exp(log_μ + 1/2 * log_σ^2)
    return(μ)
    end

ρ₁₂ = 0.8; ρ₁₃ = 0.6; ρ₂₃ = 0.4

R₃_μ = convert_logmean(2.70, 0.07); R₃_σ = convert_logsd(2.70, 0.07)

Σ = [R₁.σ^2 ρ₁₂*R₁.σ*R₂.σ ρ₁₃*R₁.σ*R₃_σ
     ρ₁₂*R₁.σ*R₂.σ R₂.σ^2 ρ₂₃*R₂.σ*R₃_σ
     ρ₁₃*R₁.σ*R₃_σ ρ₂₃*R₂.σ*R₃_σ R₃_σ^2]

copula = GaussianCopula(Σ)
MVR = SklarDist(copula, (R₁, R₂, R₃))

prng = MersenneTwister(240819); n_samples = 10^6
mv_df = rand(prng, MVR, n_samples) |&gt; 
    x -&gt; transpose(x) |&gt;
    x -&gt; DataFrame(x, ["R₁", "R₂", "R₃"])

pof = sum((β_df.L .&gt;= mv_df.R₁) .| (β_df.L .&gt;= mv_df.R₂) .| (β_df.L .&gt;= mv_df.R₃)) / n_samples 
```

quarto-executable-code-5450563D

```julia
#| echo: false
pof
```
:::

Note that the probability of failure reduces when accounting for this dependency. Since failure is defined by the resistance of the components being lower than an applied load, ensuring that low resistances occur together result in fewer simulations that predict failure. Conversely, if multiple components were connected in parallel (where system failure requires all of the components to fail) increasing the dependency in the resistance properties increases the probability of failure as weak components occurring together is relatively more common with this model.
 
A comprehensive introduction to structural reliability methods is presented in [@Melchers2018]. This book also includes some perceived challenges which are discussed later in this document.

## Statistical Uncertainty

So far this document has introduced the use of probabilistic models to describe uncertainty inherent to simple systems (sometimes called *aleatory* uncertainty). The second key source of uncertainty in engineering calculations is the statistical uncertainty associated with small, or otherwise imperfect datasets (sometimes called *epistemic* uncertainty).

This example considers how to interpret a set of measurements of material strength, accounting for statistical uncertainty. The data is presented in @tbl-strength_data. This data can be downloaded using the below code, which also shows the first few rows.

::: panel-tabset
## Python (using pandas)

quarto-executable-code-5450563D

```python
strength_df = pd.read_csv(filepath_or_buffer = "data_files/strength_data.csv")

strength_df.head(n = 3)

```

## R (using readr)

quarto-executable-code-5450563D

```R
strength_df &lt;- read_csv(file = "data_files/strength_data.csv")

strength_df |&gt; head(n = 3)

```
## Julia (using CSV, DataFrames)

quarto-executable-code-5450563D

```julia
#| output: false
strength_df = CSV.read("data_files/strength_data.csv", DataFrame)
first(strength_df, 3)

```

quarto-executable-code-5450563D

```julia
#| echo: false

first(strength_df, 3)
```

:::

The results indicate some variability even though each row presents the result of the same test, using the same machine, on a tensile specimen from the same material. This variability can be attributed to:

-   **Material heterogeneity**. Manufacturing processes used to make structural steel results in local hard spots, laminations, inclusions and other anomalies that can locally influence the strength of the material. The presence of such anomalies in the microstructure of a testing specimen will influence the measured properties.

-   **Imperfect measurement data**. There is no manufacturing process that creates perfectly homogeneous steel, and there is no measurement of an engineering quantity that will tell us everything we want to know. In this example, the machine used to perform the tests will output results with some precision, which has been quantified by the manufacturers.

Shown here as a table:

quarto-executable-code-5450563D

```R
#| echo: false
#| label: tbl-strength_data
#| tbl-cap: "Tensile Test Data of Steel"

strength_df |&gt; 
  rename('Test ID' = 'id', 'Yield Strength, MPa' = 'yield', 'Tensile Strength, MPa' = 'tensile') |&gt; 
  knitr::kable()

```

There is a range of `r paste(signif(x = strength_df$yield |&gt; max() - strength_df$yield |&gt; min(), digits = 3), "MPa")`. There are many ways that this can be interpreted. Since no value was recorded less than `r paste(strength_df$yield |&gt; min() |&gt; floor(), "MPa")`, can it be assumed that lower yield strengths are not credible?

:::{.callout-note collapse="true"}
## Thought: Dealing with variability

Engineers need to incorporate uncertainty in quantities like material properties to ensure safety and efficiency. Using a *worst-case* or *conservative* value as as a threshold is convenient as it does not complicate the calculation, but it doesn't fully solve the problem because there may not be an obvious threshold value to take. Using the lowest yield strength value measured so far may incentivise minimal testing, as the value will only decrease (or remain constant) as more data is collected.

One attempt to get around this, is provided in the guidance on identifying a suitable value of fracture toughness in a widely used structural integrity management standard [@BSI2015]. It introduces the procedure for a Minimum Of Three Equivalent (MOTE), estimate. When $3 \to 5$ measurements are available, engineers are advised to take the lowest value, then the second lowest value of $6 \to 10$ measurements, and the third lowest of $10 \to 15$ values.

By running some simulations of fracture toughness tests, below, it can be shown that even by using the MOTE value, there is generally more uncertainty with fewer tests. This results in relatively higher probabilities of non-conservative values such as those greater than the mean (indicated by the dashed line in @fig-MOTE) being selected.

::: panel-tabset
## Julia (using Distributions, Random)

quarto-executable-code-5450563D

```julia
#| output: false
true_strength = Normal(130, 20)

function MOTE(samples::Vector{Float64})
    n = length(samples)
    if n &lt; 3 || n &gt; 15
        print("Between 3 and 15 samples required")
    else 
        MOTE = sort(samples)[Int(ceil(n/5))]
    end
    return MOTE
end

MOTE_df = DataFrame()
for i in 1:100
    meas_strength = rand(MersenneTwister(i), true_strength, 15)
    for j in 3:length(meas_strength)
        append!(MOTE_df, 
                DataFrame(sim = i, 
                          n_tests = j, 
                          MOTE = MOTE(meas_strength[begin:j])))
    end
end
```

quarto-executable-code-5450563D

```julia
#| echo: false
@rput(MOTE_df); @rput(true_strength)
```

:::

quarto-executable-code-5450563D

```r
#| echo: false
#| label: fig-MOTE
#| fig-cap: "Effect of Number of Tests on BS 7910 MOTE Estimate of Fracture Toughness"

y_min &lt;- 50; y_max &lt;- 180; 

MOTE_plot &lt;- ggplot(data = MOTE_df)+
  geom_point(mapping = aes(x = n_tests, y = MOTE), alpha = 1/8)+
  geom_hline(mapping = aes(yintercept = true_strength$μ), alpha = 1/2, lty = 2)+
  scale_x_continuous(name = "Number of Toughness Measurements", 
                     breaks = seq(from = min(MOTE_df$n_tests), to = max(MOTE_df$n_tests), by = 1))+
  scale_y_continuous(name = expression(paste("MOTE, N·",~mm^{-3/2})), limits = c(y_min, y_max))+
  ggthemes::theme_base(base_family = "Atkinson Hyperlegible", base_size = 11)+
  theme(legend.title = element_blank(), plot.background = element_rect(colour = NA))

dist_plot &lt;- ggplot(data = NULL)+
  geom_function(fun = dnorm, args = list(mean = true_strength$μ, sd = true_strength$σ))+
  geom_vline(mapping = aes(xintercept = true_strength$μ), alpha = 1/2, lty = 2)+
  xlim(y_min, y_max)+
  coord_flip()+
  theme_void()

library(patchwork)
(MOTE_plot + dist_plot) + plot_layout(widths = c(4, 1))

```

:::

This variability can be approximated using probability distributions. Below, shows how a Normal distribution can be used to approximate the uncertainty in material strength, based on the data in @tbl-strength_data. 

::: panel-tabset
## Python (using SciPy)

quarto-executable-code-5450563D

```python
stats.norm.fit(data = strength_df['yield'].values, method = 'MLE')

```

## R (using fitdistrplus)

quarto-executable-code-5450563D

```R
fitdist(data = strength_df$yield, distr = 'norm', method = 'mle')

```

## Julia (using Distributions)
quarto-executable-code-5450563D

```julia
fit_mle(Normal, strength_df.yield)

```
:::

These distribution parameters (mean, $\mu$ and standard deviation, $\sigma$) represent those with the highest score (likelihood) of the range considered. If the standard deviation was any higher, the likelihood of any values near the mean would be reduced, and if it was any lower the likelihood of any data at the tails would be reduced. Similarly, if the mean was any higher, the likelihood of any lower values would be reduced. So there is a trade-off here, and maximum likelihood estimates will provide the values that maximise the product of the likelihoods (or the sum of the log-likelihoods) for the data that is being used to fit the distribution.

However, there may often not be a clear maximum likelihood, particularly when estimating distribution parameters from a small dataset. In these cases the *statistical* uncertainty results in many possible values being credible (or having a similar likelihood). These should not be dismissed, and certainly not before there is enough evidence for a model to be confident of it's maximum likelihood estimates.

:::{.callout-note collapse="true"}
## Thought: Collecting Data Reduces Uncertainty
The reason engineers pay for material tests, inspection activities and sensing systems is because the data that they provide can be used to estimate some uncertain quantity of interest. In general, the more data that is available, the less uncertainty will be associated with the prediction. 

For instance, a linear model with a straight line that approximately goes through two or three points is much less compelling than a straight line that approximately goes through hundreds of points (when the errors are the same).

The uncertainty that is associated with limited amounts of data is often referred to as *statistical* or *epistemic* uncertainty. It is distinct from *aleatory* uncertainty, which is the variability that is inherent in the problem, no matter how many measurements are available.

Consider how the maximum likelihood estimates of distribution parameters in the above code chunk evolve, as more data is made available. As shown in @fig-MLE, the mean value changes significantly before converging, but the standard error does not diminish.

::: panel-tabset
## R (using fitdistrplus)

quarto-executable-code-5450563D

```r
mle_df &lt;- tibble()
for(n in seq(from = 2, to = nrow(strength_df), by = 1)){
  available_data &lt;- strength_df$yield[1:n]
  mle &lt;- fitdist(data = available_data, distr = 'norm', method = 'mle')
  mle_df &lt;- bind_rows(mle_df, tibble(n_tests = n, 
                                     mean = mle$estimate[1], sd = mle$estimate[2],
                                     mean_se = mle$sd[1], sd_se = mle$sd[2]))
}

```

quarto-executable-code-5450563D

```r
#| echo: false
#| label: fig-MLE
#| fig-cap: "Effect of Number of Tests on Maximum Likelihood Estimate of Distribution Parameters"

ggplot(data = mle_df |&gt;
         pivot_longer(cols = c(mean, sd), names_to = "Parameter") |&gt;
         mutate(error = case_when(
           Parameter == "mean" ~ mean_se,
           Parameter == "sd" ~ sd_se)) |&gt; dplyr::select(-c(mean_se, sd_se)) |&gt;
         mutate(Parameter = case_when(
           Parameter == "mean" ~ "\u03bc",
           Parameter == "sd" ~ "\u03c3")),
       mapping = aes(x = n_tests, y = value))+
  geom_pointrange(mapping = aes(ymin = value - error, ymax = value + error, 
                                shape = "MLE ± std. error"), alpha = 1/2)+
  scale_shape_manual(values = c(1))+
  geom_line(alpha = 1/4)+
  facet_wrap(facets = ~ Parameter, scales = "free_y")+
  scale_x_continuous(name = "Number of Strength Measurements")+
  scale_y_continuous(name = "Maximum Likelihood Estimate, MPa")+
  ggthemes::theme_base(base_family = "Atkinson Hyperlegible", base_size = 11)+
  theme(legend.title = element_blank(), plot.background = element_rect(colour = NA),
        strip.text = element_text(family = "Cambria"), legend.position = "top")

```
:::

A distribution based on the maximum likelihood estimates, which could be used for prediction, varies a lot. Rather than using point values of parameters that move around as more data becomes available, it is preferable to quantify the statistical uncertainty in these estimates so that the effect of collecting additional data can be accounted for, allowing for the identification of when it is expected to be worthwhile paying for more data. 

The example calculations in this document, though presented in various levels of detail, are all based on the premise that collecting data reduces statistical uncertainty, and it is possible to check when this is (and is not) expected to be useful, by pushing the results through a decision analysis.
:::

Statistical uncertainty in estimates of yield strength will be relatively high when only very few measurements are available. Maximum likelihood estimates will therefore not produce reliable predictions, since they could change significantly after including just a few more tests. It is especially important to understand this variability in cases like this to help distinguish a highly uncertain model with a highly informed model. Failing to do so can result in placing too much belief in a prediction, and so this distinction is important when using models for decision support. 

One method of quantifying variability in a maximum likelihood estimate is to find confidence intervals. Confidence intervals can be obtained by repeating the calculation many times using different samples of the data, and identifying the range within which some proportion of results are contained in. The below code finds the 95% confidence intervals for the maximum likelihood estimate of the mean yield strength, based on the tensile test data in @tbl-strength_data.

Some further detail on confidence intervals can be found in [@Gelman2020], but essentially, the below result should be interpreted as: in repeated experiments, the mean yield strength will lie somewhere within this range 95% of the time. How that fact can be used to support decision making is not clear, so this document considers a more intuitive method of describing this uncertainty.

::: panel-tabset
## Python (using SciPy)

quarto-executable-code-5450563D

```python
yield_data = (strength_df['yield'].values,)

def get_MLE_mean(data):
  return stats.norm.fit(data = data, method = 'MLE')[0]
  
bootstrap_mean = stats.bootstrap(data = yield_data, statistic = get_MLE_mean, vectorized = False, 
confidence_level = 0.95, n_resamples = 1000, method = "basic")

bootstrap_mean.confidence_interval

```

## R (using boot)

quarto-executable-code-5450563D

```R
get_MLE_mean &lt;- function(x, id) {fitdist(x[id], distr = 'norm')$estimate[1]}

bootstrap_mean &lt;- strength_df$yield |&gt;
  boot(statistic = get_MLE_mean, R = 1000) |&gt;
  boot.ci(conf = 0.95)

bootstrap_mean$basic |&gt; as_tibble() |&gt; 
  dplyr::select(c(conf, V4, V5)) |&gt;
  rename(lower_bound = V4, upper_bound = V5)

```

## Julia (using Distributions, Bootstrap)

quarto-executable-code-5450563D

```julia
function get_MLE_mean(data)
    Distributions.fit_mle(LogNormal, data).μ
end

bootstrap(get_MLE_mean, strength_df.yield, BasicSampling(1_000)) |&gt;
    x -&gt; confint(x, BasicConfInt(0.95))
```
:::

## Probabilistic Programming

### Introduction

Probabilistic programming is used to describe a statistical model, and then automate the inference (estimation of the unknown and uncertain parameters) [@Rainforth2017]. Sometimes known as probabilistic machine learning [@Ghahramani2015], inferring unknown parameters, while also accounting for the uncertainty, including statistical uncertainty, is a desirable characteristic of a calculation. One reason for this is because it can be used to demonstrate how additional data can reduce uncertainty, and this can be used as the basis for intelligently collecting data.

There are now many probabilistic programming languages available to engineers, but the one that is used in the examples in this document is `Stan`. The primary justification for this is that it runs a state of the art sampling algorithm, and (unlike many alternatives) it can be used with many other languages. In these examples, pre- and post-processing of data will be done in `R` and `Python`.

Firstly, loading the Stan model for quantifying uncertainty in material strength:

::: panel-tabset
## Python

quarto-executable-code-5450563D

```python
strength_model = cmdstanpy.CmdStanModel(stan_file = "stan_models/yield_strength_model.stan")

```

## R

quarto-executable-code-5450563D

```R
strength_model &lt;- cmdstan_model(stan_file = "stan_models/yield_strength_model.stan", stanc_options = list("O1"))

```
:::

The data block in the `Stan` file indicates the data that it is expecting. In `Python` this data is provided to the `Stan` model in the form of a dictionary, and in `R` it is a list.

::: panel-tabset
## Python

quarto-executable-code-5450563D

```python
#| output: false
strength_data = {"n_strength" : strength_df.shape[0], 
                 "strength_meas" : strength_df["yield"].values,
                 "error" : 5, "m_s" : 350, "sd_s" : 50, "rate_s" : 0.1}

n_par = multiprocessing.cpu_count()
n_chains = 4; n_draws = 1000; n_warmup = 2000

strength_fit = strength_model.sample(data = strength_data, seed = 1234, 
                                     chains = n_chains, parallel_chains = n_par, 
                                     iter_warmup = n_warmup, iter_sampling = n_draws)

```

## R

quarto-executable-code-5450563D

```R
#| output: false
strength_data = list(n_strength = nrow(strength_df),
                     strength_meas = strength_df$yield,
                     error = 3,
                     m_s = 350, sd_s = 50, rate_s = 0.1)

n_par &lt;- parallel::detectCores()
n_chains &lt;- 4; n_draws &lt;- 1000; n_warmup &lt;- 2000

strength_fit &lt;- strength_model$sample(data = strength_data, seed = 1234,
                                      chains = n_chains, parallel_chains = n_par, 
                                      iter_warmup = n_warmup, iter_sampling = n_draws)

```
:::

This model estimates the mean and standard deviation of the strength together. It also accounts for some measurement uncertainty, which is simple to incorporate. The model can be described using statistical language, as shown below.

Firstly, the measured yield strength, $\sigma_{Ym}$ can be described as normally distributed with a mean equal to the true yield strength, $\sigma_{Y}$ plus some bias (which is assumed to be zero here), and a standard deviation, $\epsilon$, which describes the variation from $\sigma_{Y}$, due to the measurement process. Here, $\epsilon$ (or a similar measure) could be quoted from the tensile testing machine manufacturer, or the organisation that performed the testing. Note that in the above code, a value of $5 MPa$ has been used.

$$
\sigma_{Ym} \sim N(\sigma_{Y}, \epsilon)
$$

Secondly, $\sigma_{Y}$ is described as normally distributed, with a mean, $\mu$, and a standard deviation, $\sigma$. 

$$
\sigma_{Y} \sim N(\mu, \sigma)
$$

This could be a fully defined model, but there is also ab opportunity to provide a starting point. Rather than requiring the model to narrow down it's estimate from all possible values, engineers may wish to point it in a helpful direction since they will have some idea of what the measurements will be even before seeing them. Whilst acknowledging that there can be a lot of variation in the quality of structural steel, a yield strength of the order of hundreds of $MPa$ is far more credible than billions, or millions. Engineers may also want to constrain the values to be positive.

In this example, some *prior* models (starting points) for the mean and standard deviation of the yield strength are shown below. These, like all other details about the structure of this model, are a subjective feature, but sampling from these priors can be a helpful tool in agreeing suitable values [@Gabry2020]. An example of this is provided later in this document.

$$
\mu \sim N(\mu = 350 MPa, \sigma = 50 MPa), \mu \ge 0 MPa
$$
$$
\sigma \sim \exp(\lambda = \frac{1}{10}), \sigma \ge 0 MPa
$$

Once the model has converged, samples can be drawn from the distribution of parameters ($\mu$ and $\sigma$). However, it is first necessary to extract (and process) the results. Below are some suggested methods of achieving this.

::: panel-tabset
## Python

quarto-executable-code-5450563D

```python
class Stan_Posterior:
    def __init__(self, fit):
        self.fit = fit
        self.draws_per_chain = self.fit.draws().shape[0]
        self.n_chains = self.fit.draws().shape[1]
        self.n_pars = self.fit.draws().shape[2]
        self.draws_tot = self.draws_per_chain * self.n_chains
        
    def draws_df(self):
        posterior_df = pd.DataFrame(columns = self.fit.column_names + ("Chain", "Iteration"))
        for c in range(self.n_chains):
            posterior_df = pd.concat([posterior_df,
                      (pd.DataFrame(self.fit.draws()[:,c,:], columns = self.fit.column_names).
                      assign(Chain = "Chain {}".format(1 + c),
                      Iteration = 1 + np.arange(self.draws_per_chain)))])
        return(posterior_df)
      
    def tidy_draws_df(self):
        posterior_df_tidy = self.draws_df().melt(id_vars = ("Chain", "Iteration"))
        return(posterior_df_tidy)
```

which allows for...

quarto-executable-code-5450563D

```python
strength_posterior = Stan_Posterior(fit = strength_fit)

strength_posterior_df = strength_posterior.tidy_draws_df()
strength_posterior_df.tail(n = 3)
```

## R

quarto-executable-code-5450563D

```R
strength_data_df &lt;- DomDF::tidy_mcmc_draws(cmdstan_fit = strength_fit)
tail(strength_data_df)

```
:::

:::{.callout-note collapse="true"}
## Thought: Data vs. Information
It is widely acknowledged that not all data are equally informative. Engineering data often consists of some indirect measurements of a complex physical phenomena, sometimes in challenging environments. As a result, it will always be associated with some precision, bias and reliability.

It may be necessary to conduct some calibration experiments to quantify these properties. Higher quality (more precise, less biased, more reliable) data will always be at least as useful as lower quality data, and will sometimes be worth paying much more for.

Risk based inspection standards (such as API 580) often acknowledge this difference in quality. A visual inspection is not considered as good as an ultrasonic inspection for damage, and is therefore recommended to be completed more frequently to manage risk. The calculations in this document account for data quality more accurately. Rather than relying on simple heuristics, statistical models are used to relate the information content to the raw data. 
:::

There are many alternative probabilistic programming languages available to engineers. One example is the `Turing` library, written for `Julia` users. The model can be specified using the `@model` macro, as shown below:

::: panel-tabset
## Julia (using Turing)

quarto-executable-code-5450563D

```julia
@model function yield_model(yield_strength_meas::Vector{Float64}, ϵ::Float64 = 5.0)
    
    # Priors
    σ ~ Exponential(10)
    μ ~ Normal(350, 50)
    
    # Gaussian model
    yield_strength ~ Normal(μ, σ)

    # Relating yield strength to imprecise test data
    n_samples = length(yield_strength)
    for n ∈ n_samples
        yield_strength_meas[n] ~ Normal(yield_strength, ϵ)
    end

end
```

Which can then be run to generate a data frame of samples from the joint posterior distribution:

quarto-executable-code-5450563D

```julia
n_draws = 1000; n_chains = 4; sampler = NUTS()
posterior_df = yield_model(strength_df.yield) |&gt;
    x -&gt; sample(x, sampler, MCMCThreads(), n_draws, n_chains) |&gt;
    x -&gt; DataFrame(x) |&gt;
    x -&gt; @select(x, :chain, :iteration, :σ, :μ)

```

:::

The joint distribution of parameters can then be used to sample from predictive distributions of other quantities. Any subsequent structural reliability analysis using this distribution of yield strength will account for the statistical uncertainty due to the limited amount of test data. This additional uncertainty, particularly for probabilities of very low values of strength, may be a more principled approach for dealing with the so-called *tail-sensitivity problem* [@Melchers2018, @Palmer2012].

:::{.callout-note collapse="true"}
## Thought: Statistical Uncertainty in Monte Carlo Sampling
Monte Carlo sampling of rare events, such as failure may require a large amount of simulations, only very few of which may predict failure. As proposed in [this article](https://eracons.com/resources/mcs-post-processing), statistical uncertainty can be accounted for in this estimate to provide a distribution of credible probabilities of failure, rather than a single maximum likelihood point.

This can be achieved using probabilistic programming, but this may require some re-scaling. Many MCMC sampling algorithms may find it challenging to sample from the very narrow distribution of probabilities of failure. All the values will be very small, the sampling will be highly sensitive to the parameters that govern the sampling. However, sampling from the negative index of $\beta_{R}$ will provide a more management scale, likely to be in the region of $0$ - $10$. This could be further reparameterised if required, but would then lose some immediate interpretability.
:::

The `Stan` and `Turing.jl` probabilistic models of yield strength defines a joint distribution of the mean and standard deviation of yield strength. This means that, as well as quantifying the uncertainty in both parameters, the inter-dependencies are also accounted for. 

For instance, consider the samples from the `Stan` model in @fig-MCMC_post_sigmaY. All of the relatively low values of standard deviation (coloured in red) correspond to a narrow range of possible mean values, wheras the relatively high values (coloured in green) were sometimes associated with much higher or lower values for the mean. One way to rationalise this is that, whilst there is some uncertainty in the estimate of the mean value of yield strength, for low or high values to be consistent with the available data, they may need to be associated with a greater variance. A low standard deviation that was associated with a very low mean value would correspond to a narrow distribution that did not greatly overlap with the test data, which us why we do not see this combination in @fig-MCMC_post_sigmaY. 

Being able to push these uncertainties and dependencies into predictions, is why modern probabilistic models can provide useful, informative results, even with small amounts of imperfect data.

quarto-executable-code-5450563D

```r
#| echo: false
#| label: fig-MCMC_post_sigmaY
#| fig-cap: "Samples from Joint Distribution of Parameters in Probabilistic Yield Strength Model"

strength_fit |&gt; DomDF::tidy_mcmc_draws() |&gt;
  dplyr::filter(grepl(pattern = "_post_pred|_m|_sd", x = Parameter)) |&gt;
  pivot_wider(id_cols = c(Chain, Iteration), names_from = Parameter, values_from = value) |&gt;
  mutate(ind = case_when(
    strength_sd &lt;= 20 ~ "Low",
    strength_sd &gt;= 35 ~ "High",
    T ~ "Med"
  )) |&gt;
  ggplot()+
  geom_point(mapping = aes(x = strength_m, y = strength_sd, fill = ind), shape = 21, alpha = 1/2)+
  scale_fill_manual(values = c("forestgreen", "firebrick", "white"))+
  scale_x_continuous(name = "Mean Yield Strength, MPa")+
  scale_y_continuous(name = "Standard Deviation of Yield Strength, MPa")+
  ggthemes::theme_base(base_family = "Atkinson Hyperlegible", base_size = 11)+
  theme(legend.title = element_blank(), legend.position = "none",
        plot.background = element_rect(colour = NA))

```

&lt;!-- Heat loss (in $W$) through building elements, such as walls and windows (with cross-sectional area in $m^2$) is characterised a *U-value*, standardised to represent a $1 \deg K$ change in temperature. A low U-value indicates a better insultaed building element, that loses less heat. --&gt;

&lt;!-- For a wall, the $U$-value can be calculated using the below equation: --&gt;

&lt;!-- $$ --&gt;
&lt;!-- U = \dfrac{1}{\frac{1}{h_{i}} + \sum_{j = 1}^{J layers} \frac{s_{j}}{\lambda_{j}} + \frac{1}{h_{e}}} --&gt;
&lt;!-- $$ --&gt;
&lt;!-- ...where $s_{i}$ and $\lambda_{i}$ are the thickness and thermal conductivity of each layer in the wall, and $h_{i}$ and $h_{e}$ are respectively the internal and external convective heat transfer coefficients. --&gt;

&lt;!-- U-values are specified in building regulations [@PartL_2022]. For example for a new dwelling, the minimum U values for the roof, walls and floor are specified as $0.11$, $0.18$ and $0.13 W m^{-2} K^{-1}$, respectively. --&gt;

&lt;!-- U-values for new buildings are typically calculated using the above equation. However for retrofit of existing buildings it may be necessary to measure U-values, particularly if construction details are not known. --&gt;

## Sampling Outcomes 

*Example of prior predictive sampling, and posterior predictive sampling for heat loss in buildings*

Consider a test to better understand the performance of a sensing technology. One feature that may need to be characterised is the probability of detection. Here, small signals are generally less likely to be reliably detected by the sensor and signal processing. The relationship between the size of the input $X$ and the probability of detection, $\Pr(det)$ can be modelled using a logistic regression [@HSE2006, @Harding2008], as shown below:

$$
\Pr(det)  = \dfrac{\exp(\alpha + \beta \times X)}{1 + \exp(\alpha + \beta \times X)}
$$
This model has the benefit of producing values between $0$ and $1$, and the distribution parameters $\alpha$ and $\beta$ describe how $\Pr(det)$ increases (or decreases) with input size, $X$. If this was a new crack detection technology for use in inspections, $X$ may represent the extent (size) of a crack.


::: panel-tabset
## R (using purrr, TruncatedNormal, tibble)
quarto-executable-code-5450563D

```r
logistic_fun &lt;- function(alpha, beta, x){
  exp(alpha + beta * x) / (1 + exp(alpha + beta * x))
}

n_prior_samples &lt;- 100; x_start &lt;- 0; x_end &lt;- 5

alpha_prior_mean &lt;- -3; alpha_prior_sd &lt;- 1/2
beta_prior_mean &lt;- 2; beta_prior_sd &lt;- 1

set.seed(seed = 1234)

prior_pred_df &lt;- tibble(alpha_prior = rnorm(n = n_prior_samples, mean = alpha_prior_mean, sd = alpha_prior_sd),
                        beta_prior = rtnorm(n = n_prior_samples, mu = beta_prior_mean, sd = beta_prior_sd, lb = 0, ub = Inf), 
                        X = seq(from = x_start, to = x_end, length.out = n_prior_samples)) |&gt;
  mutate(prior_Pr_det = purrr::pmap(.l = list(alpha_prior, beta_prior, X),
                                    .f = ~logistic_fun(..1, ..2, ..3)) |&gt; unlist())

```

## Python (using SciPy, NumPy, Math, Pandas)
quarto-executable-code-5450563D

```python
def logistic_fun(alpha, beta, x):
  logistic_x = np.exp(alpha + beta * x) / (1 + np.exp(alpha + beta * x))
  return logistic_x

n_prior_samples = 100; x_start = 0; x_end = 5

alpha_prior = stats.norm.rvs(loc = -3, scale = 1/2, size = n_prior_samples, random_state = 1234)
beta_prior = stats.truncnorm.rvs(loc = 2, scale = 1, a = 0, b = math.inf, size = n_prior_samples, random_state = 1234)
X = np.linspace(start = x_start, stop = x_end, num = n_prior_samples)
prior_Pr_det = logistic_fun(alpha_prior, beta_prior, X)

d = {'X': X, 'alpha_prior': alpha_prior, 'beta_prior': beta_prior, 'prior_Pr_det': prior_Pr_det}
prior_pred_df = pd.DataFrame(data = d)

```

## Julia (using Random, Distributions, DataFrames, DataFramesMeta)
quarto-executable-code-5450563D

```julia
function logistic_fun(α::Float64, β::Float64, X::Float64)
    return exp(α + β * X) / (1 + exp(α + β * X))
end

logistic_fun(-3.0, 2.0, 1.0)

n_prior_samples = 100; x_start = 0; x_end = 5; prng = MersenneTwister(1234)

α_pr = Normal(-3, 1/2); β_pr = Normal(2, 1); x = LinRange(x_start, x_end, n_prior_samples)

prior_df = DataFrame(X = x,
                     α_pr = rand(prng, α_pr, n_prior_samples),
                     β_pr = rand(prng, β_pr, n_prior_samples)) |&gt;
    x -&gt; @rtransform(x, :prior_Pr_det = logistic_fun(:α_pr, :β_pr, :X))

```
:::

The reason for sampling from the priors of the parameters is to better understand their meaning in the context of the full model. It is not necessarily intuitive to find helpful values for $\alpha$ and $\beta$ in the above logistic function, but there will be some intuition regarding what predictions from a probability of detection model will look like.

For instance, the plots in @fig-prior_pred_PoD show how higher variance priors (on the left) and lower variance, more informative priors (on the right) compare in their associated predictions after being pushed through the model. Some features of the predictions from the more informative priors include:

 * The probability of detection increases as the size of the damage increases.
 * There remains significant uncertainty in the predictions, which is expected to decrease as data is added to the model.

This kind of graphical check, where the results are shown on an understandable outcome scale, can be used to find helpful starting points for probabilistic models.

quarto-executable-code-5450563D

```r
#| echo: false
#| label: fig-prior_pred_PoD
#| fig-cap: "Prior Predictive Checks for a Probability of Detection Model"

set.seed(seed = 1234)
unsuitable_prior_df &lt;- tibble(alpha_prior = rnorm(n = n_prior_samples, mean = 0, sd = 100),
                              beta_prior = rnorm(n = n_prior_samples, mean = 0, sd = 100))

prior_pred_plot &lt;- ggplot(NULL)+
  scale_x_continuous(name = "Crack depth, mm", limits = c(0, 5), breaks = scales::pretty_breaks())+
  scale_y_continuous(name = "Prior Probability of Detection", limits = c(0, 1), breaks = scales::pretty_breaks())+
  ggthemes::theme_base(base_family = "Atkinson Hyperlegible", base_size = 11)+
  theme(legend.title = element_blank(), plot.background = element_rect(colour = NA),
        legend.text = element_text(family = "Cambria"), legend.position = "top") -&gt; unsuitable_prior_plot

prior_pred_plot &lt;- prior_pred_plot + labs(subtitle = "More informative priors: a useful start")+
  theme(axis.title.y = element_blank(), axis.ticks.y = element_blank(), axis.text.y = element_blank())
unsuitable_prior_plot &lt;-  unsuitable_prior_plot + labs(subtitle = "Uninformative priors: an unhelpful start")

for (i in seq(from = 1, to = n_prior_samples, by = 1)){
  prior_pred_plot &lt;- prior_pred_plot +
    stat_function(alpha = 1/5, fun = logistic_fun, 
                  args = list(alpha = prior_pred_df$alpha_prior[i], 
                              beta = prior_pred_df$beta_prior[i]),
                  mapping = aes(lty = "Prior Predictive Samples \n \u03b1 ~ N(-3, 1/2), \u03b2 ~ N (2, 1)"))
  
  unsuitable_prior_plot &lt;- unsuitable_prior_plot +
    stat_function(alpha = 1/5, fun = logistic_fun, 
                  args = list(alpha = unsuitable_prior_df$alpha_prior[i], 
                              beta = unsuitable_prior_df$beta_prior[i]),
                  mapping = aes(lty = "Prior Predictive Samples \n \u03b1 ~ N(-3, 100), \u03b2 ~ N (2, 100)"))
  
}

library(patchwork)
(unsuitable_prior_plot + prior_pred_plot)

```

# Supporting Decision Making

## Existing Challenges

Engineering analysis, whether it is a fracture mechanics assessment, a stress analysis, or an environmental forecast is completed with the intention of supporting decision making. And yet, these calculations are often performed separately from the underlying decision problem, and by a different team.

This interpretation of a calculation by a decision-maker can introduce subjective judgement that is not formally reported. As a result, it may be difficult to repeatedly arrive at the same decision (conditional on the same information), or even explain how the decision was made in an audit. This message is made in the below extract, in the context of pipeline engineering:

&lt;q&gt; ...you don't need anything at all! You don't need qualified engineers, you don't need quality systems, you don't need risk management, you don't need safety audits, you don't need inspections, you don't need training. You don't need anything! Until something happens... then you need everything.... Got the message? 

[@Hopkins2002]

The reason an engineer will recommend a higher strength than their *best estimate* of what will be required is they are accounting for the consequences of their best estimate being too low. The cost of an in-service failure will generally be much greater than the additional cost in design of upgrading the strength requirements. But how much higher the decision-maker chooses to go will depend on their perception of the magnitude of the consequences of the various outcomes, and the reliability of the stress analysis i.e. how uncertain is the prediction.

A decision analysis will not remove subjectivity, since the costs of the consequences may be different, depending on who is asked, and the analysis should reflect the beliefs of the personnel responsible for making the decision. However, what decision analysis does offer is the formalisation of propagating uncertain predictions from engineering models through various possible outcomes, so that expected consequences can be quantified, and decision alternatives can be ranked, in a transparent, and replicable way.

The decision problems that this document focusses on, is whether or not to pay to collect some data. The method is commonly described as *value of information*, but is also often referred to as *pre-posterior* analysis in engineering textbooks [@Benjamin2014, @Jordaan2005, @Melchers2018] and some statistics textbooks too [@Berger].

:::{.callout-note collapse="true"}
## Thought: The Expected Value of Data ...*Before* Collecting it
A key challenge in estimating the expected value of a prospective data collection activity, is that it is performed before the data is available to include in models - the purpose of the analysis is to help decide whether it is worth collecting.

Instead, the method considers all of the information that will be available at the time of making this decision. Engineers will be able to predict, with some (and perhaps a lot of!) uncertainty, what they expect the value to be. They will also know, generally from the contractor, is the quality of data that will be provided. For instance, inspection technologies are calibrated by service providers before they are brought to market, and so along with a quotation, a performance specification can be provided explaining how precise the data will be.

A value of information analysis uses all of this available information and, in the context of the decision problem that the data is intended to support, quantifies on a meaningful, monetary scale, the expected value of the data to the engineer.
:::

### Decision-Event Trees

Decision problems can be represented as decision-event trees, such as the example shown in @fig-example_tree. It is conventional for decisions to be drawn as square nodes, uncertainties as round nodes, and costs/utilities as triangle or diamond nodes.

In @fig-example_tree, two arrows are drawn from the decision node, indicating that two decision alternatives are being considered. Either $D1$ or $D2$ can be selected, but not both. The two arrows emerging from each of the uncertain nodes mean that two outcomes, $A$ or $B$, can occur. Since these are the only outcomes, the probabilities of each of them (conditional on the decision) must sum to give $1$, i.e. $\Pr(O = A | d = D1) + \Pr(O = B | d = D1) = 1$. Each outcome has a different utility, should it occur.

quarto-executable-code-5450563D

```mermaid
%%| label: fig-example_tree
%%| fig-cap: "Example Structure of a Decision-Event Tree"

flowchart LR
  d1[Decision] -- D1 --&gt; o1((Uncertain \noutcome, \nD1))
  d1[Decision] -- D2 --&gt; o2((Uncertain \noutcome,  \nD2))
  
  o1 --O = A --&gt; c1a{Utility, \nO = A, d = D1}
  o1 --O = B --&gt; c1b{Utility, \nO = B, d = D1}
  o2 --O = A--&gt; c2a{Utility, \nO = A, d = D2}
  o2 --O = B--&gt; c2b{Utility, \nO = B, d = D2}
  
```

The expected utility associated with making decision $d1$, $\mathbb{E}\Big[ u(d1) \Big]$ can be calculated as follows:

$$
\mathbb{E}\Big[ u(d1) \Big] = \Pr(O = A) * u(O = A, d = D1) + \Pr(O = B) * u(O = B, d = D1)
$$

Here, the utilities (or costs) are being weighted by the probabilities that they will occur. The expected utility associated with making decision $D2$ can be calculated in the same way, and the expected optimal decision will be the option that has the highest expected utility, or lowest expected cost.

&lt;!-- Formally, ... --&gt;

&lt;!-- $$ --&gt;
&lt;!-- a^{*} = \arg \max_{a \in A} E \Big[ u(a, \theta) \Big] --&gt;
&lt;!-- $$ --&gt;

&lt;!-- On the basis that the expected optimal action is selected, the expected utility is $E \Big[ u(a^{*}, \theta) \Big]$. --&gt;

### Graphical Models (Influence Diagrams)

Approximating real engineering systems using decision-event trees will require many more nodes than those presented in @fig-example_tree. This would lead to very large diagrams. Consequently, they are often represented more concisely, using *influence diagrams*.

Influence diagrams do not show every possible event path graphically (rather, these are stored as tables behind each node.) An influence diagram representation of @fig-example_tree is shown in @fig-example_id.

quarto-executable-code-5450563D

```mermaid
%%| label: fig-example_id
%%| fig-cap: "Example Structure of an Influence Diagram"

flowchart LR
  d1[Decision] --&gt; o1((Uncertain \noutcome))
  d1 --&gt; c1{Utility}
  o1 --&gt; c1

```

The arrows in an influence diagram are also causal (like in a Bayesian network). The arrows in @fig-example_id imply that the selected decision influences the uncertain outcome, and that the utility is conditional on both of these parameters. Drawing a useful influence diagram therefore requires some knowledge of the system that it is designed to represent.

:::{.callout-note collapse="true"}
## Thought: Drawing Upon Engineering Know-How
Drawing a graphical model can simply follow on, from a description of an engineering system.

If tasked with describing a corrosion protection system as an influence diagram, to help identify whether a data collection activity is expected to be worthwhile, it would be recommended to consult a corrosion specialist.

If a pipeline integrity engineer provided the following, basic information about the protection system for external corrosion of a buried pipeline:

 - The rate of corrosion will depend on the type of soil in which the pipeline is buried, amongst other factors.
 - The primary external protective system is a protective coating, which provides a physical barrier between the steel and the soil. 
 - The pipeline is also protected by a Cathodic Protection (CP) system, which helps protect any exposed steel by ensuring it is sufficiently cathodic to prevent the oxidising corrosion reaction.
 - Insufficient current from the CP system will mean that exposed steel (for example at locations of coating damage) will corrode. Excessive current can lead to disbondment of the coating from pipeline surface, meaning there may be a corrosive environment between the pipeline and the coating, which is shielded from any CP protection.
 - A Direct Current Voltage Gradient (DCVG) survey, can provide us with some information about the presence of damage in the coating.

This information can be shown graphically, using the influence diagram shown in @fig-id_cr. This representation allows for information on any of the uncertain parameter can be propagated through the network. It also describes how decision/actions can affect specific parameters in a model (and therefore also in the outcomes of interest, i.e. external corrosion rate). 

Using a model to predict how a system will respond to various interventions, as facilitated by influence diagrams, is often described as the goal of *digital twins*.

quarto-executable-code-5450563D

```mermaid
%%| label: fig-id_cr
%%| fig-cap: "Influence Diagram Showing Factors Affecting Corrosion Rate of a Buried Pipeline"

flowchart LR
 
  dcoat[Complete \nDCVG Survey?] --&gt; coat((Coating \nCondition))
  cp((CP \nPerformance)) --&gt; corr((Corrosion \nRate))
  coat --&gt; corr
  dcoat --&gt; ccoat{DCVG \n Costs}
  
  cp --&gt; ccp{CP costs}
  cp --&gt; coat
  
  soil((Soil Type)) --&gt; corr
  corr --&gt; ccorr{Corrosion \ncosts}
  
```

:::

## Example Calculations

### Expected Value of Perfect Information

#### Energy Generation Asset Portfolio 

In designing an energy system for a region, using some combination of nearshore and offshore wind, and solar. The combination (portfolio) should be selected such that the some system requirements are met, namely:

 - The minimum annual TWhrs of generation, $\alpha$ must be met.
 - Fewer than $\gamma$ GWhrs can be dropped below the threshold of $\beta$ GW

This problem is based on (normalised) power time series data for the three assets, which are read below.

::: {#chunk_load_packages .panel-tabset}

## Julia (using DataFrames)

quarto-executable-code-5450563D

```julia
#| output: false
power_df = CSV.File("data_files/power_data.csv",
                    dateformat = "dd-mm-yyyy HH:MM") |&gt;
  DataFrame |&gt; x -&gt; rename(x, :Column1 =&gt; :time)

α = 10; β = 2; γ = 1 * 0.1 * 24 * 365
assets = names(power_df)[2:end]

```

Viewing the first few items...

quarto-executable-code-5450563D

```julia
first(power_df, 3)

```

:::

Due to land availability, solar power can only supply either $0\%$ or $20\%$ of the total capacity. Similarly, nearshore wind can only provide either $0\%$, $25\%$  or $50\%$. The offshore wind asset is sufficiently flexible to be able to provide the remaining capacity. This leads to $6$ competing strategies, which can be evaluated, subject to the aforementioned constraints to identify how much power each asset is required to provide for each option.

::: {#chunk_load_packages .panel-tabset}

## Julia (using JuMP, HiGHS)

quarto-executable-code-5450563D

```julia
#| output: false
asset_norm_power_series = [power_df.solar; 
                           power_df.offshore; 
                           power_df.nearshore] |&gt;
        x -&gt; reshape(x, (nrow(power_df), 3)) |&gt;
        x -&gt; transpose(x)

total_energies = sum(asset_norm_power_series, dims = 2)

strategies = [[0 1 0],
              [0 0.75 0.25],
              [0 0.5 0.5],
              [0.2 0.8 0],
              [0.2 0.55 0.25],
              [0.2 0.3 0.5]]

capacities = Vector{Float64}()

for strategy ∈ strategies
  
  energy_gen = JuMP.Model(HiGHS.Optimizer)
  
  @variable(energy_gen, capacity &gt;= 0)
  @variable(energy_gen, ϕ[i = 1:nrow(power_df)] &gt;= 0)
  
  @constraints(energy_gen, begin
               capacity * *(strategy, total_energies) .&gt;= α * 24 * 365
               sum(ϕ) &lt;= γ
               ϕ .&gt;= β .- transpose(capacity * *(strategy, asset_norm_power_series))
               end)
  
  @objective(energy_gen, Min, capacity)
  optimize!(energy_gen)
  
  append!(capacities, [value(capacity)])

end

```

The results of this optimisation problem are shown below:

quarto-executable-code-5450563D

```julia
#| output: false
nₛ = length(strategies)

energy_df = DataFrame(strategy = [i for i ∈ strategies],
                      solar_GW = [(capacities .* strategies)[i][1] for i ∈ 1:nₛ],
                      offshore_GW = [(capacities .* strategies)[i][2] for i ∈ 1:nₛ],
                      nearshore_GW = [(capacities .* strategies)[i][3] for i ∈ 1:nₛ])
```

quarto-executable-code-5450563D

```julia
#| echo: false
energy_df

```

:::

The different options can then be evaluated using forecast costs, to identify which option is expected to minimise costs. The uncertainty in forecast costs of the different assets are described by the below probabilistic models:

$$
C_{solar} \sim N(\mu = 125 \times 10^{6}, \sigma = 25 \times 10^{6})
$$
The prior model for the cost of wind power includes a correlation between nearshore and offshore assets i.e. in cases where the cost of generating offshore wind power is relatively high, the cost of generating nearshore wind is also expected to be higher (and vice versa). 

Rather than use a copula model, a multivariate normal distribution can be used, since both marginal distributions are also normal, and there is no non-linear dependency to consider.

$$
C_{wind} \sim MVN \Bigg( \mu = \begin{pmatrix} \mu_{nearshore} \\ \mu_{offshore} \end{pmatrix}, \Sigma = \begin{pmatrix} \sigma_{nearshore}^2 &amp; \rho \cdot \sigma_{nearshore} \cdot \sigma_{offshore} \\ \rho \cdot \sigma_{nearshore} \cdot \sigma_{offshore} &amp;  \sigma_{offshore}^2 \end{pmatrix} \Bigg)
$$
$$
\mu_{nearshore}  = 275 \times 10^{6}, \: \mu_{offshore}  = 325 \times 10^{6}
$$
$$
\sigma_{nearshore}  = 75 \times 10^{6}, \: \sigma_{offshore}  = 75 \times 10^{6}
$$
$$
\rho = 0.6
$$
::: {#chunk .panel-tabset}

## Julia

quarto-executable-code-5450563D

```julia
#| output: false
mean_costs = Dict("solar" =&gt; 125.0 * 10^6, "offshore" =&gt; 325.0 * 10^6, "nearshore" =&gt; 275.0 * 10^6)
sd_costs = Dict("solar" =&gt; 25.0 * 10^6, "offshore" =&gt; 75.0 * 10^6, "nearshore" =&gt; 75.0 * 10^6)

function get_prior_decision(;input_df::DataFrame, mean_costs = mean_costs)
  power_df = input_df[!, names(input_df, Float64)]
  expected_costs = Vector{Float64}()

  for row in eachrow(power_df)
    append!(expected_costs, Vector{Any}(row) .* [get(mean_costs, i, "unknown") for i in assets] |&gt; x -&gt; sum(x))
  end

  input_df[!, :prior_costs] = expected_costs
  
  minimum_prior_cost = minimum(input_df.prior_costs)
  prior_df = @subset(input_df, :prior_costs .== minimum_prior_cost)
  
  return(prior_df)
end
```

The result is shown below:

quarto-executable-code-5450563D

```julia
#| echo: false
prior_decision_df = get_prior_decision(input_df = energy_df)
```

:::

If forecasting models could be improved, so that the uncertainty could be removed, what would this mean for the expected cost of delivering the identified strategies? This question can be answered using a value of information analysis.

In this case, this is achieved by sampling from the prior distributions of costs. Here each sample provides an imagined result of a study to identify the costs more precisely. For each result the expected optimal strategy (and associated cost) is evaluated, and an average of the samples are required, to account for the various possible results of the study.

quarto-executable-code-5450563D

```mermaid
%%| label: fig-prepost_id_energy_portfolio
%%| fig-cap: "Influence Diagram for Estimating the Expected Value of an Energy Forecasting Model"

flowchart LR
  d0[System \ndesign] --&gt; ons((Nearshore wind \ngeneration))
  d0[System \ndesign] --&gt; oos((Offshore wind \ngeneration))
  d0[System \ndesign] --&gt; os((Solar \ngeneration))

  ons --&gt; c_s
  oos --&gt; c_s
  os --&gt; c_s 

  d1[Forecast \nmodel] --&gt; ec((Energy \nprices))
  ec --&gt; c_s{Implementation \ncosts}

  d1 --&gt; c_m{Modelling \ncosts}

```


::: {#chunk_load_packages .panel-tabset}

## Julia

quarto-executable-code-5450563D

```julia
#| output: false
function cov_mat_3_params(sd_costs::Vector{Float64}, ρ::Vector{Float64})
    C = [sd_costs[1]^2 ρ[1]*sd_costs[1]*sd_costs[2] ρ[2]*sd_costs[1]*sd_costs[3];
        ρ[1]*sd_costs[1]*sd_costs[2] sd_costs[2]^2  ρ[3]*sd_costs[3]*sd_costs[3];
        ρ[2]*sd_costs[1]*sd_costs[3] ρ[3]*sd_costs[3]*sd_costs[3] sd_costs[3]^2]
    return C
end

prng = MersenneTwister(1234)

function get_prepost_decision(;input_df::DataFrame, n_samples::Int64, mean_costs = mean_costs, sd_costs = sd_costs, ρ = [0, 0, 0.6])
  power_df = input_df[!, names(input_df, Float64)]

  costs = MvNormal([get(mean_costs, i, "unknown") for i in assets], 
                 cov_mat_3_params([get(sd_costs, i, "unknown") for i in assets], ρ)) |&gt;
    x -&gt; rand(prng, x, n_samples)
  
  expected_costs =  Array{Float64}[] |&gt; x -&gt; reshape(x, n_samples, 0)
  
  for row in eachrow(power_df)
    expected_costs = hcat(expected_costs,
                          *(Vector{Float64}(row) |&gt; x -&gt; transpose(x),
                          costs) |&gt; x -&gt; transpose(x))
  end
  
  prepost_df = DataFrame(strat_opt = Int[], exp_cost = Float64[])
  
  for i in 1:size(expected_costs)[1]
      append!(prepost_df, 
              DataFrame(strat_opt = argmin(expected_costs[i, :]),
                        exp_cost = minimum(expected_costs[i, :])))
  end
  
  return(prepost_df)
end
```

:::

quarto-executable-code-5450563D

```julia
#| echo: false
prepost_decision_df = DataFrame(strategy = [i for i ∈ strategies],
          solar_GW = [(capacities .* strategies)[i][1] for i ∈ 1:nₛ],
          offshore_GW = [(capacities .* strategies)[i][2] for i ∈ 1:nₛ],
          nearshore_GW = [(capacities .* strategies)[i][3] for i ∈ 1:nₛ]) |&gt;
  x -&gt; get_prepost_decision(input_df = x, n_samples = 10^5)
```

Again, the expected value of perfect information is the difference between the expected prior and preposterior costs. In this case, it is estimated to be just over two million pounds:

quarto-executable-code-5450563D

```julia
#| output: false
VoI = prior_decision_df.prior_costs[1] .- mean(prepost_decision_df.exp_cost)
```
quarto-executable-code-5450563D

```julia
@printf "VoPI = GBP %.6e" VoI
```

Recall that this represents the expected value of removing uncertainty in forecasting electricity generation costs for various technologies. It can therefore be interpreted as (an upper-bound estimate of) how much the project should be willing to invest in improving modelling of cost forecasting.

For the near-term planning of energy system asset development, the calculated expected value of perfect cost forecasting can inform the decision maker whether it is financially worthwhile to undertake an initial asset development contracting process, such as a *contract for difference auction*, prior to the design of the energy system. Such a contracting process would provide the system designer with exact information on the cost of the assets that would be developed, via the clearing price of the auction to which the developers agree, after which an informed decision on the optimal system design could be made, but would incur a significant time and administrative cost. For the long-term planning of future energy systems, this analysis can be used to determine whether and to what extent Research and Development (R&amp;D) and the purchase of expert opinion on future asset costs (either internal or contracted) should be used to assist the creation of energy system development strategies. 

However, neither R&amp;D or the expert opinions of consultants provide perfect information on future costs, and determining models for their efficacy is required to identify a more realistic expected value of imperfect information, which will be lower than the value predicted here. This challenge is discussed in a different context in the below example.

&lt;!-- Therefore, a system designer will not be willing to pay the full EVPI for such improvements in the estimation of future costs, though if the EVPI is sufficiently large it may provide justification for taking such actions nonetheless. For these 'measurement actions' the EVPI may be used to assist a more qualitative judgement on their economic suitability. Though, expenditure on R&amp;D projects also has the potential to reduce the future costs of renewable generation assets, providing additional advantage. --&gt;


### Sensitivity Analysis: Influence of Prior Knowledge

#### Example: Energy Use in Buildings

Consider the problem of heating a residential building. Inefficiencies in ageing heaters can result in increased electricity costs to deliver energy requirements. This performance degradation can be mitigated by maintenance work.

The problem is described by the influence diagram in @fig-prior_id_heat_pumps. Here, heat pump parameters, $\alpha$ and $\beta$ describe the degradation and improvements to the performance of a heat pump, respectively.

Heat pump efficiency, characterised by a Seasonal Performance Factor (SPF), is calculated based on how the system degrades with age (using $\alpha$), and how maintenance activities can improve, or restore, the performance (using $\beta$).

quarto-executable-code-5450563D

```mermaid
%%| label: fig-prior_id_heat_pumps
%%| fig-cap: "Influence Diagram for Identifying Expected Optimal Maintenance Schedule of Heating System"

flowchart LR
  d2[Maintenance \nfrequency] --&gt; o2((SPF))

  o0((Heating \nload)) --&gt; o1((SPF))
  o2(("#946;")) --&gt; o1((SPF))
  o3(("#945;")) --&gt; o1((SPF))

  o1 --&gt; c1{Electricity \ncost}
  d2 --&gt; c2{Maintenance \n cost}

```

The model that will be used is as follows:

$$
\beta = \frac{\beta_{A} * N_{m}^\gamma}{\beta_{B} + N_{m}^{\gamma}}
$$
$$
\alpha \sim N(\mu = 1.6 \times 10^{-2}, \sigma = 1.6 \times 10^{-3})
$$
Where: $\beta_{A} = 0.05$, $\beta_{B} = 2.5$, and $\gamma = 1.4$. The cost of a heat pump is taken to be £$110472.50$, and the cost of  maintenance is equal to $1$% of this cost, multiplied by the number of activities, $N_{m}$.

The cost of electricity for the system, $C_{e}$ is calculated, using the heating load in kWh, $L_{H}$, the price per kWh, in GBP $p_{e}$, and the SPF:
$$
C_{e} = \frac{L_{H} \times p_{e}}{SPF}
$$

The inputs for the problem are defined below. These result in a decreasing efficacy of maintenance activities, when many are scheduled, see @fig-n_maint_beta.

::: {#chunk_load_packages .panel-tabset}

## R

quarto-executable-code-5450563D

```R
get_beta &lt;- function(n_maintenance){
  a &lt;- 0.05; b &lt;- 2.5; gamma &lt;- 1.4
  # a &lt;- 1/4; gamma &lt;- 2; b &lt;- 10
  (a * n_maintenance^gamma) / (b + n_maintenance^gamma)
}

n_samples &lt;- 1e3; alpha &lt;- rnorm(n = n_samples, mean = 1.6e-2, sd = 1.6e-3)

SPF_initial &lt;- 3

max_n_maint &lt;- 12; n_maint &lt;- seq(from = 0, to = max_n_maint, by = 1)

heat_pump_cost_GBP &lt;- 441890/4; heating_load_kWh &lt;- 1753914; GBP_per_kWh &lt;- 0.51
```

:::

quarto-executable-code-5450563D

```R
#| echo: false
#| label: fig-n_maint_beta
#| fig-cap: "Effect of Increasing Number of Scheduled Maintenance Activities on Heat Pump Performance Improvement Factor"

tibble(x = n_maint) |&gt;
  mutate(beta = get_beta(n_maintenance = x)) |&gt;
  ggplot(mapping = aes(x, beta))+
  geom_point(shape = 1, size = 1)+
  geom_line(alpha = 1/4)+
  scale_x_continuous(name = 'Number of scheduled maintenance activities per year')+
  scale_y_continuous(name = expression(beta))+
  ggthemes::theme_base(base_size = 12, base_family = "Atkinson Hyperlegible")+
  theme(plot.background = element_rect(color = NA),
        legend.title = element_blank(), legend.position = 'top')
```

As shown in @fig-prior_heat_pump_decision, increasing the number of maintenance activities initially decreases the total cost (sum of electricity and maintenance costs), before no longer expecting to be worthwhile.

quarto-executable-code-5450563D

```r
#| echo: false
#| output: false

alpha_sd &lt;- 0.25

lnorm_params &lt;- DomDF::lnorm_params(norm_mean = 0.16, norm_sd = alpha_sd)

# Often predicted from weather forecasts
Lh_Le &lt;- (1 + 2 * rbeta(n_samples, 6, 2))

alpha_i &lt;- 0.16; SPF_i &lt;- 3

alpha_new &lt;- function(alpha, Lh_Le){
  Lh_Le / alpha
}

SPF_new &lt;- function(SPF, alpha){
  (1 - alpha) * SPF
}
```

::: {#chunk_load_packages .panel-tabset}

## R (using purrr)

quarto-executable-code-5450563D

```R
prior_decision_df &lt;- function(n_maint_range){
  
  tibble(n_maint = n_maint_range, alpha = list(alpha)) |&gt;
  mutate(beta = get_beta(n_maintenance = n_maint),
         SPF = SPF_initial,
         maint_cost = n_maint * heat_pump_cost_GBP * 3e-2,
         SPF_coeff = map2(.x = alpha, .y = beta,
                          .f = function(.x, .y){(1 - .x) * (1 + .y)}),
         SPF = map2(.x = SPF, .y = SPF_coeff,
                    .f = function(.x, .y){lag(x = .x, n = 1, default = SPF_initial) * .y}),
         elec_cost = map(.x = SPF,
                         .f = function(.x){GBP_per_kWh * heating_load_kWh / .x}),
         total_cost = map2(.x = elec_cost, .y = maint_cost,
                           .f = function(.x, .y){ .x + .y})) |&gt; 
    group_by(n_maint) |&gt;
    mutate(exp_cost = mean(unlist(total_cost))) |&gt;
    ungroup()

  }
```

:::

quarto-executable-code-5450563D

```R
#| echo: false
#| label: fig-prior_heat_pump_decision
#| fig-cap: "Identification of Number of Expected Optimal Heat Pump Maintenance Activities"

prior_df &lt;- prior_decision_df(n_maint_range = n_maint)

ggplot(data = prior_df |&gt;  
              tidyr::unnest(cols = total_cost) |&gt;
              mutate(id = rep(x = seq(from = 1, to = n_samples, by = 1), times = max_n_maint + 1)), 
       mapping = aes(x = n_maint, y = total_cost))+
  geom_line(mapping = aes(group = id), alpha = 1/50)+
  scale_x_continuous(name = 'Number of scheduled maintenance activities per year', 
                     breaks = seq(from = 0, to = 12, by = 1))+
  scale_y_continuous(name = 'Total (annual) operational costs, £', labels = scales::comma)+
  geom_vline(lty = 2, alpha = 1/2, 
             mapping = aes(color = 'Expected minimum cost',
                           xintercept = prior_df[which.min(prior_df$exp_cost),]$n_maint))+
  ggthemes::theme_base(base_size = 12, base_family = "Atkinson Hyperlegible")+
  theme(plot.background = element_rect(color = NA),
        legend.title = element_blank(), legend.position = 'top')

```

The expected optimal number of maintenance activities to schedule (that which is associated with the lowest expected cost) is `r prior_df[which.min(prior_df$exp_cost),]$n_maint`, with an associated expected cost of £`r prior_df[which.min(prior_df$exp_cost),]$exp_cost |&gt; signif(digits = 4)`.

How can a smart meter assist in solving this decision problem? As shown in @fig-prepost_id_heat_pumps, the data that a smart meter provides can be used to reduce uncertainty about the degradation parameter, $\alpha$.

quarto-executable-code-5450563D

```mermaid
%%| label: fig-prepost_id_heat_pumps
%%| fig-cap: "Influence Diagram for Estimating the Expected Value of Smart Meters"

flowchart LR
  d2[Maintenance \nfrequency] --&gt; o2((SPF))
  
  o4((Electical \nload)) --&gt; o3(("#945;"))

  o2(("#946;")) --&gt; o1((SPF))
  o3 --&gt; o1((SPF))
  o0((Heating \nload)) --&gt; o3

  o1 --&gt; c1{Electricity \ncost}
  d2 --&gt; c2{Maintenance \ncost}

  d3[Smart \nmeter] --&gt; c3{Meter \ncost}
  d3 --&gt; o4


```

::: {#chunk_load_packages .panel-tabset}

## R (using purrr)

quarto-executable-code-5450563D

```R
prepost_decision_df &lt;- function(n_maint_range){
  
  tibble(alpha = alpha, n_maint = list(n_maint_range)) |&gt;
  mutate(beta = map(.x = n_maint, 
                    .f = function(.x){get_beta(.x)}),
         SPF = SPF_initial,
         maint_cost = map(.x = n_maint,
                          .f = function(.x) {.x * heat_pump_cost_GBP * 1e-2}),
         SPF_coeff = map2(.x = alpha, .y = beta,
                          .f = function(.x, .y){(1 - .x) * (1 + .y)}),
         SPF = map2(.x = SPF, .y = SPF_coeff,
                    .f = function(.x, .y){
                      lag(x = .x, n = 1, default = SPF_initial) * .y}),
         elec_cost = map(.x = SPF,
                         .f = function(.x){GBP_per_kWh * heating_load_kWh / .x}),
         total_cost = map2(.x = elec_cost, .y = maint_cost,
                           .f = function(.x, .y){ .x + .y})) |&gt;
    mutate(exp_cost = map(.x = total_cost, 
                          .f = function(.x) {min(unlist(.x))}),
           exp_cost = unlist(exp_cost))
}
```

:::

quarto-executable-code-5450563D

```R
#| echo: false
prior_df &lt;- tibble(alpha_sd = double(), ec_pr = double(), a_pr = integer())
prepost_df &lt;- tibble(alpha_sd = double(), ec_prepost = double())

for (alpha_sd in c(0.01, 0.05, 0.1, 0.125, 0.15, 0.175, 0.2, 0.25)){
  
  set.seed(seed = 240819)
  
  alpha &lt;- randomLHS(n = n_samples, k = 1) |&gt; qnorm(mean = 1/2, sd = alpha_sd)
  
  df_pr &lt;- prior_decision_df(n_maint_range = n_maint)
  
  prior_df &lt;- bind_rows(prior_df, 
                        tibble(alpha_sd = alpha_sd, ec_pr = df_pr[which.min(df_pr$exp_cost),]$exp_cost, a_pr = df_pr[which.min(df_pr$exp_cost),]$n_maint))
    
  df_pp &lt;- prepost_decision_df(n_maint_range = n_maint)
  
  prepost_df &lt;- bind_rows(prepost_df, 
                          tibble(alpha_sd = alpha_sd, ec_prepost = df_pp$exp_cost |&gt; mean()))
  
}
  
VoPI_df &lt;- prior_df |&gt;
  left_join(y = prepost_df, by = 'alpha_sd') |&gt;
  mutate(VoPI = ec_pr - ec_prepost)

```

In @fig-voi_smart_meter_alpha_sensitivity the effect of the prior variance on $\alpha$ is shown. Moving from left to right along the x-axis indicates an increase in prior uncertainty about how the heat pumps will degrade. The less well this is known, the more value there is expected to be in collecting data from a smart meter.

quarto-executable-code-5450563D

```R
#| echo: false
#| label: fig-voi_smart_meter_alpha_sensitivity
#| fig-cap: "Effect of Prior Uncertainty on Expected Value of Smart Meter Data"
ggplot(data = VoPI_df, mapping = aes(x = alpha_sd, y = VoPI))+
  geom_point(shape = 1, size = 1) + geom_line(alpha = 1/4)+
  geom_text(mapping = aes(label = paste("£", VoPI |&gt; signif(digits = 3))), 
            family = "Atkinson Hyperlegible", size = 3, vjust = -1)+
  scale_x_continuous(name = expression(paste('Uncertainty (std. dev.) in prior model of ', alpha)))+
  scale_y_continuous(name = 'Expected value of (perfect) smart meter data, £', labels = scales::comma, limits = c(0, VoPI_df$VoPI |&gt; max() + 3e3))+
  ggthemes::theme_base(base_size = 12, base_family = "Atkinson Hyperlegible")+
  theme(plot.background = element_rect(color = NA))
```

The above examples have used bespoke code to represent the decision that needed to be solved. Though this can be helpful for prototyping initial calculations, small changes to the problem may require large amounts of code to be re-written.

### Influence Diagram Representation

#### Example A: Measuring Temperature for Forecasting Crop Sales

An environment for growing various produce, such as the underground farm project [@Ward2022], requires monitoring of features that will impact crop survival. Being able to forecast availability of crops is important when agreeing future sales.

In this challenge, a buyer is willing to purchase at one of multiple levels. In response, the operator can agree to sell at one of these levels (earning payment for sufficient delivery, or paying a penalty if insufficient crops are available), or to not engage with the market at this time (at no risk, with no reward). 

A model predicting crop availability from the local temperature can be linked to this decision making under uncertainty problem, as shown in the influence diagram in @fig-prior_id_farm.

quarto-executable-code-5450563D

```mermaid
%%| label: fig-prior_id_farm
%%| fig-cap: "Influence Diagram for Identifying Expected Optimal Crop Sales Commitment"

flowchart LR
  
  t((Estimated \nTemperature)) --&gt; c((Crop \nAvailability))
  d2[Sales \nCommitment] --&gt;  c1{Utility}
  c --&gt; c1

```

::: {#chunk_load_packages .panel-tabset}

Inputs describing the levels at which the operator can commit to sell, as well as prospective reward and penalty fees are shown below. Also included in the below code chunk is the sigmoid model relating local temperature to the proportion of crops expected to be available at the time of the sale.

## Julia

quarto-executable-code-5450563D

```julia
#| output: false
delivery_options = Dict("Option_0" =&gt; 0, "Option_1" =&gt; 0.5, "Option_2" =&gt; 0.75)
delivery_states = keys(delivery_options) |&gt; x -&gt; collect(x)
delivery_values = [delivery_options[state] for state in delivery_states]

survival_states = ["met", "not_met"]

rewards = Dict("Option_0" =&gt; 0, "Option_1" =&gt; 0.4, "Option_2" =&gt; 0.6)
reward_states = delivery_states; reward_values =  [rewards[state] for state in reward_states]

penalties = Dict("Option_0" =&gt; 0, "Option_1" =&gt; -0.5, "Option_2" =&gt; -1)
penalty_states = delivery_states; penalty_values =  [penalties[state] for state in penalty_states]

function crop_survival(Temp, α = 4, β = -1/5)
    survival = 1 / (1 + exp(-(α + β * Temp)))
    return survival
end

```
:::

The [DecisionProgramming.jl](https://gamma-opt.github.io/DecisionProgramming.jl/stable/) Julia library includes intuitive syntax for creating an influence diagram, and populating the nodes with the appropriate probability, utility and decision inputs. Expected optimal actions can then be identified using one of many compatible solvers. Note that the [JuMP.jl](https://jump.dev) library used here, was also used to solve the optimisation problem in the energy generation problem. 

::: {#chunk_load_packages .panel-tabset}

## Julia (using DecisionProgramming, JuMP, HiGHS)

quarto-executable-code-5450563D

```julia
function get_exp_u(S, optimiser)

    # Initialise influence diagram
    crop_delivery = InfluenceDiagram()

    # Create structure of influence diagram
    add_node!(crop_delivery, DecisionNode("Delivery", [], delivery_states))
    add_node!(crop_delivery, ChanceNode("Survival", ["Delivery"], survival_states))
    add_node!(crop_delivery, ValueNode("Pay", ["Survival", "Delivery"]))

    generate_arcs!(crop_delivery)

    # Calculate probabilities for meeting delivery levels
    pr_S = [sum(S .&gt; delivery_values[i]) / length(S) for i in 1:length(delivery_values)]

    Pr_S = ProbabilityMatrix(crop_delivery, "Survival")
    U_p = UtilityMatrix(crop_delivery, "Pay")

    # Assigning probabilities and utilities to diagram
    Pr_S[:, "met"] = pr_S
    Pr_S[:, "not_met"] = 1 .- pr_S
    
    U_p["met", :] = reward_values
    U_p["not_met", :] = penalty_values

    add_probabilities!(crop_delivery, "Survival", Pr_S)
    add_utilities!(crop_delivery, "Pay", U_p)

    generate_diagram!(crop_delivery)

    # Define and run solver
    model = JuMP.Model(optimiser)
    z = DecisionVariables(model, crop_delivery)
    EV = expected_value(model, crop_delivery, PathCompatibilityVariables(model, crop_delivery, z))

    @objective(model, Max, EV)
    optimize!(model)

    # Process results
    Z = DecisionStrategy(z)
    U_dist = UtilityDistribution(crop_delivery, Z)

    exp_opt_decision = DataFrame(Exp_Utility = dot(U_dist.p, U_dist.u),
                             Action = delivery_states[argmax(Z.Z_d[1])])
    
    return exp_opt_decision
end

```

The prior model of temperature is a Normal distribution with a mean of $10^{\circ} C$ and a standard deviation of $5 ^{\circ} C$. This continuous model has been discretised by drawing $1000$ samples using the Latin Hypercube method.

$$
T\_{prior} \sim N(\mu = 10, \sigma = 5)
$$

quarto-executable-code-5450563D

```julia
#| output: false

prior_temp = Normal(10, 5)

function draw_lhs(dist, n::Int; reprod::Int = 240819)
    Random.seed!(reprod)
    samples = randomLHC(n + 2, 1) |&gt;
        x -&gt; scaleLHC(x, [(0, 1)]) |&gt;
        x -&gt; quantile(dist, x)[:,1] |&gt;
        x -&gt; filter(!∈((-Inf, Inf)), x) |&gt;
        x -&gt; [x[i] for i ∈ 1:length(x) if abs(x[i]) &gt;= 10^-10]
    return samples
end

temp_df = DataFrame(temp = draw_lhs(prior_temp, 1_000)) |&gt;
    x -&gt; @rtransform(x, :surv = crop_survival(:temp)) |&gt;
    x -&gt; @orderby(x, :temp)

```

The expected optimal action, conditional on the influence diagram representation of the decision problem, and the prior model of temperature can then be calculated:

quarto-executable-code-5450563D

```julia
get_exp_u(temp_df.surv, HiGHS.Optimizer)
```
:::

Considering the option of installing devices to measure the temperature (as shown in @fig-prepost_id_farm), requires the influence diagram to be solved many times (for each hypothesised outcome). The average expected utility over each of the subsequent decision analyses can then be compared to the expected prior utility, to find the expected value of (perfect) temperature measurements, in the context of supporting the crop sales decision.

quarto-executable-code-5450563D

```mermaid
%%| label: fig-prepost_id_farm
%%| fig-cap: "Influence Diagram for Calculating Expected Value of Temperature Data"

flowchart LR
  
  d1[Measure \nTemperature] --&gt; t((Estimated \nTemperature)) 
  t --&gt; c((Crop \nAvailability))
  d2[Sales \nCommitment] --&gt;  c1{Utility}
  c --&gt; c1

```

::: {#chunk_load_packages .panel-tabset}

quarto-executable-code-5450563D

```julia
#| output: false
measure_df = DataFrame()
for s_meas in temp_df.surv
    append!(measure_df, get_exp_u(s_meas, HiGHS.Optimizer))
end

prior_utility = get_exp_u(temp_df.surv, HiGHS.Optimizer).Exp_Utility[1]
prepost_utility = mean(measure_df.Exp_Utility)

VoPI = prepost_utility - prior_utility

```

quarto-executable-code-5450563D

```julia
@printf "VoPI = %.4f" VoPI
```

:::

#### Example B: Verification of a Digital Twin for Maintenance Planning

Another source of data that can be considered, is that which is obtained from verifying an existing model. There may be many reasons to complete such a study, such as to demonstrate compliance with a quality standard, or to obtain some certification, and though these can also be quantified and incorporated, this example will only consider the benefits in terms of risk management.

The source of value of verification studies arises from the propagation of the reduced uncertainty through a decision analysis i.e. the information from verification studies facilitate improved risk management. 

Consider the representation in @fig-dt_id of the decision problem regarding whether to send maintenance personnel to investigate a component. An investigation includes the repair of any defect(s), and is expected to be worthwhile if the cost of the activity is less than that associated with the risk of failure. The state/condition of the component can be estimated based on the knowledge of the operations engineers, as well as data from a digital twin, which is being used in this context to support a condition assessment.

quarto-executable-code-5450563D

```mermaid
%%| label: fig-dt_id
%%| fig-cap: "Influence Diagram of Maintenance Decision Problem"

flowchart LR
  d1[Maintenance \nPlan]  --&gt; o1((Component \nCondition))
  o2((Digital \nTwin Data))  --&gt; o1
  d2[Verification Plan \nfor Digital Twin] --&gt; o1
  d2 --&gt; o2

  d1 --&gt; c1{Maintenance \nCost} 
  o1  --&gt; c2{Failure \nRisk}
  
```

quarto-executable-code-5450563D

```r
#| echo: false
#| label: tbl-model_inputs
#| tbl-cap: "Key Inputs for Decision Analysis"

input_df &lt;- tribble(
  ~Input, ~Value, ~Units,
  "probability of defect", 0.15, NA,
  "cost of investigation", 1e5, "$",
  "cost of shut-down", 2e5, "$",
  "cost of component failure", 5e5, "$",
  "probability of failure of defective component", 1/2, NA,
  "probability of failure of undamaged component", 1e-4, NA,
  "probability of failure during shut-down", 1e-6, NA
)

input_df |&gt; knitr::kable()
```



::: {#chunk_load_packages .panel-tabset}

## Julia 

quarto-executable-code-5450563D

```julia
#| output: false

# Set up decision inputs
maint_options = Dict("no_action" =&gt; 1, "investigate" =&gt; 10^-2, "shut_down" =&gt; 10^-4)
maint_states = keys(maint_options) |&gt; x -&gt; collect(x)
maint_values = [maint_options[state] for state in maint_states]

dt_output_states = ["defect", "no_defect"]
condition_states = ["failure", "survival"]

pr_defect = 0.15; pr_fail_defect = 0.5; pr_fail_undamaged = 10^-2

cost_inv = 100_000; cost_shutdown = 200_000; cost_failure = 500_000

n_samples = 1_000; prior_β = Beta(6, 2)
reliabilities = draw_lhs(prior_β, n_samples)

```

:::


::: {#chunk_load_packages .panel-tabset}

The below function initialises the influence diagram, and defines it's structure in terms of nodes and edges:

## Julia (using DecisionProgramming, JuMP, HiGHS)

quarto-executable-code-5450563D

```julia
# Initialise influence diagram
function create_id(β::Float64)

    maint_dec = InfluenceDiagram()

    # Create structure of influence diagram
    add_node!(maint_dec, DecisionNode("Maintenance", [], maint_states))

    add_node!(maint_dec, ChanceNode("DT_output", [], dt_output_states))
    add_node!(maint_dec, ChanceNode("Condition", ["DT_output", "Maintenance"], condition_states))

    add_node!(maint_dec, ValueNode("Fail_risk", ["Condition"]))
    add_node!(maint_dec, ValueNode("Maint_cost", ["Maintenance"]))

    generate_arcs!(maint_dec)

    Pr_DT = ProbabilityMatrix(maint_dec, "DT_output")
    Pr_C = ProbabilityMatrix(maint_dec, "Condition")

    U_M = UtilityMatrix(maint_dec, "Maint_cost")
    U_f = UtilityMatrix(maint_dec, "Fail_risk")

    # Calculate probabilities of detection and failure
    pr_defect_detected = (pr_defect * β) + (1 - pr_defect) * (1 - β)
    pr_fail_det = pr_fail_defect * β + pr_fail_undamaged * (1 - β)
    pr_fail_nodet = pr_fail_undamaged * β + pr_fail_defect * (1 - β)

    # Assign probabilities and utilities to nodes
    Pr_DT["defect"] = pr_defect_detected
    Pr_DT["no_defect"] = 1 - pr_defect_detected

    for i in maint_states
        Pr_C["defect", :, "failure"] = pr_fail_det * [maint_options[i] for i in maint_states]
        Pr_C["defect", :, "survival"] = 1 .- pr_fail_det * [maint_options[i] for i in maint_states]
        Pr_C["no_defect", :, "failure"] = pr_fail_nodet * [maint_options[i] for i in maint_states]
        Pr_C["no_defect", :, "survival"] = 1 .- pr_fail_nodet * [maint_options[i] for i in maint_states]
    end

    U_M["no_action"] = 0; U_M["investigate"] = cost_inv; U_M["shut_down"] = cost_shutdown
    U_f["survival"] = 0; U_f["failure"] = cost_failure

    add_probabilities!(maint_dec, "DT_output", Pr_DT)
    add_probabilities!(maint_dec, "Condition", Pr_C)

    add_utilities!(maint_dec, "Maint_cost", U_M)
    add_utilities!(maint_dec, "Fail_risk", U_f)

    generate_diagram!(maint_dec)
    
    return maint_dec

end

```

Then the following function solves the influence diagram (identifies the expected optimal action and costs).

quarto-executable-code-5450563D

```julia
#| output: false

# Solve the influence diagram
function solve_id(; β::Float64, optimiser::DataType = HiGHS.Optimizer)

    maint_dec = create_id(β)

    # Define and run solver
    model = JuMP.Model(optimiser)
    z = DecisionVariables(model, maint_dec)
    EV = expected_value(model, maint_dec, PathCompatibilityVariables(model, maint_dec, z))

    @objective(model, Min, EV)
    optimize!(model)

    # Process results
    Z = DecisionStrategy(z)
    U_dist = UtilityDistribution(maint_dec, Z)

    opt_df = DataFrame(β = β,
        u_opt = dot(U_dist.p, U_dist.u),
        a_opt = maint_states[argmax(Z.Z_d[1])])

    return opt_df
end

```


quarto-executable-code-5450563D

```julia
#| output: false

solve_id(β = 0.8)

```

To consider the additional cost associated with the epistemic uncertainty in the digital twin reliability, a *value of information* calculation can be completed. Since we are quantifying the expected value of a verification that has not yet been completed, we must consider the range of possible results. The prior model of reliability describes what we expect a verification activity to find, and simulating possible results (and evaluating their impact of an expected optimal maintenance decision) can be used to quantify the expected value of verification in this context.

quarto-executable-code-5450563D

```julia
#| output: false

# Simulating many possible outcomes from the verification
verif_df = DataFrame()
for βᵣ in reliabilities
    append!(verif_df, solve_id(β = βᵣ))
end

```

As shown in @fig-voi_results, in instances where a verification study identifies a relatively high reliability of the digital twin, this can be used to justify deferral of a site investigation of a component. Whereas in instances where a relatively low reliability is identified, an investigation is still justified. For this particular scenario, a shut-down was never found to be the expected optimal action, despite the reduced probability of failure due to the high cost of implementation.

quarto-executable-code-5450563D

```julia
prior_cost = solve_id(β = mean(reliabilities)).u_opt[1]
prepost_cost = verif_df.u_opt |&gt; x -&gt; mean(x)

VoI = prior_cost - prepost_cost

```

:::

### Expected Value of Imprecise (Imperfect) Information: 

#### Example: Inspecting for Corrosion

One method of estimating corrosion growth rates is by comparing repeated measurements of damage at sites of active corrosion. In this example, inspection data for $10$ sites of corrosion can be analysed, so that future degradation can be forecast. Predicting when these locations will fail will inform the decision of whether to invest in repairs. An influence diagram representation of this challenge is shown in @fig-prepost_id_voi.

quarto-executable-code-5450563D

```mermaid
%%| label: fig-prepost_id_voi
%%| fig-cap: "Influence Diagram for Identifying Expected Optimal Repair Plan for Corroding Structure"

flowchart LR

    v[Inspect \nAnomaly 4] --&gt; c((Estimated \nCorrosion Rate))
    c --&gt; C_f{Failure \nRisk}

    m[Repair \nPlan] --&gt; C_f
    
    m --&gt; C_m{Repair \nCosts}

```

The available inspection data is loaded in the below `Python` code. As well as the measurement, identifiers for the inspection, and anomaly are listed. Note that the second inspection was not completed at anomaly $4$. Sometimes inspections cannot be completed due to time, weather (or other safety constraints). In this case, this instance is labelled as missing data.

::: {#chunk_load_packages .panel-tabset}

## Python (using Pandas)

quarto-executable-code-5450563D

```python
insp_data = pd.read_csv("data_files/inspection_data.csv")

years = insp_data.t.unique()
insps = insp_data.inspection.unique()
locations = insp_data.location.unique()

insp_data.head(n = 3)

```

:::

A `Stan` model has been written that estimates the corrosion growth rate, in $mm/year$ for this population as the difference in the measured extent (depth) of the damage in $mm$, divided by the time interval between the measurements, in $years$. This probabilistic estimate is then use to forecast future growth for a defined time window, so that the probabilities of failure for each of the anomalies can be calculated, for the purpose of identifying where repairs are expected to be required.

The model is set loaded below, along with some options for the sampling.

::: {#chunk_load_packages .panel-tabset}

## Python (using CmdStanPy)

quarto-executable-code-5450563D

```python
n_chains = 4; n_warmup = 2000; n_draws = int(1000/n_chains)
cgr_model = cmdstanpy.CmdStanModel(stan_file = "stan_models/corr_fp_md_c.stan")

def lnorm_params(mu, sigma):
    sdlog = math.sqrt(math.log(1 + sigma**2 / mu**2))
    meanlog = math.log(mu) - 0.5 * sdlog**2
    return {"sdlog" : sdlog, "meanlog" : meanlog}

prior_depth_params = lnorm_params(10, 6)

def gen_model_data(inspection_df):
  model_data = {
  "N": inspection_df.shape[0],
  "n_A": inspection_df.anomaly_id.nunique(),
  "n_M": inspection_df.missing.sum(),
  "ID": inspection_df.anomaly_id,
  "depth_i1": inspection_df[inspection_df.t == years[0]].depth_mm,
  "depth_i2": inspection_df[inspection_df.t == years[1]].depth_mm,
  "error_i1": inspection_df[inspection_df.inspection == insps[0]].sizing_uncertainty,
  "error_i2": inspection_df[inspection_df.inspection == insps[1]].sizing_uncertainty,
  "d_years": years.max() - years.min(),
  "ex_1": inspection_df[inspection_df.t == years[0]].missing,
  "ex_2": inspection_df[inspection_df.t == years[1]].missing,
  "mu_mu_beta": 1, "sigma_mu_beta": 1, "rate_sigma_beta": 1,
  "mu_depth_imp": prior_depth_params["meanlog"],
  "sigma_depth_imp": prior_depth_params["sdlog"]}
  return(model_data)

```

:::

The below functions are used to extract results from the model:

::: {#chunk_load_packages .panel-tabset}

## Python (using NumPy, Pandas, CmdStanPy)

quarto-executable-code-5450563D

```python
def corrosion_model(data):
  cgr_posterior = Stan_Posterior(cgr_model.sample(data = data, 
                                                  seed = 240819, 
                                                  iter_warmup = n_warmup, 
                                                  iter_sampling = n_draws, 
                                                  chains = 4, 
                                                  parallel_chains = multiprocessing.cpu_count()))
  return(cgr_posterior.draws_df())
  
def get_costs(insp_df, results_df, t = 12.7, cost_repair = 10**4, cost_fail = 10**5):
  PoF_df = pd.DataFrame(data = {"anomaly": insp_df.anomaly_id.unique()})
  PoF = []; cost = []; action = []
  for i in insp_df.anomaly_id.unique():
      id = "depth_true_i2[" + str(i) + "]"
      depth = np.array(results_df[id] + results_df["CGR_pp"])
      PoF.append((depth &gt;= t).sum() / len(depth))
  
  PoF_df["PoF"] = np.array(PoF)
  for i in PoF_df.PoF:
      if i * cost_fail &lt; cost_repair:
          cost.append(i * cost_fail)
          action.append("No action")
      else:
          cost.append(cost_repair)
          action.append("Repair")
  PoF_df["cost"] = np.array(cost)
  PoF_df["action"] = np.array(action)
  return(PoF_df)
  
```

:::

The decision analysis consists of identifying the expected optimal repairs to perform, based on an expected repair cost of $\$10,000$ and an expected failure cost, per anomaly of $\$100,000$. 

::: {#chunk_load_packages .panel-tabset}

## Python

Solving the prior decision problem identifies for which anomalies a repair is expected to be worthwhile, as shown in @tbl-corrosion_model_inputs. The total cost is the prior expected cost. 

quarto-executable-code-5450563D

```python
#| output: false

model_data = gen_model_data(insp_data)
cgr_results = corrosion_model(data = model_data)

costs_df = get_costs(insp_df = insp_data, results_df = cgr_results)
prior_exp_cost = costs_df.cost.sum()

```

quarto-executable-code-5450563D

```r
#| echo: false
#| label: tbl-corrosion_model_inputs
#| tbl-cap: "Expected Optimal Repair Plan for 10 Corrosion Anomalies"

costs_df &lt;- reticulate::py$costs_df |&gt; 
               dplyr::select(-c(PoF)) |&gt;
               rename("Anomaly" = anomaly, "Cost, £" = cost, "Expected optimal action" = action)

knitr::kable(costs_df)

```


quarto-executable-code-5450563D

```r
#| echo: false
#| label: fig-cgr
#| fig-cap: "Probabilistic Estimate of Corrosion Growth Rate, mm/year"

cgr_df &lt;- reticulate::py$cgr_results |&gt; as_tibble()

cols &lt;- colnames(cgr_df); depth_cols &lt;- cols[grepl(pattern = "depth_true", x = cols)]

depth_df &lt;- cgr_df |&gt;
  dplyr::select(depth_cols) |&gt; 
  unnest(cols = all_of(depth_cols)) |&gt;
  tidyr::pivot_longer(cols = all_of(depth_cols), names_to = "anomaly_id", values_to = "depth") |&gt;
  mutate(inspection = case_when(
    grepl(pattern = "i1", x = anomaly_id) ~ "Inspection A",
    T ~ "Inspection B"
  ),
  anomaly_id = stringr::str_match(anomaly_id, "\\[(.*?)\\]")[,2],
  anomaly_id = factor(x = anomaly_id, levels = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)),
  type = case_when(
    anomaly_id == 4 &amp; inspection == "Inspection B" ~ "Imputed",
    T ~ "Measured"
  ))

ggplot(data = cgr_df |&gt; dplyr::select(CGR_pp) |&gt; unnest())+
  geom_histogram(mapping = aes(x = CGR_pp, y = after_stat(x = density)), col = "black", alpha = 1/2)+
  scale_x_continuous(name = "Estimated corrosion growth rate, mm/year")+
  scale_y_continuous(name = "Likelihood")+
  ggthemes::theme_base(base_size = 12, base_family = "Atkinson Hyperlegible")+
  theme(plot.background = element_rect(color = NA), legend.title = element_blank(), legend.position = "top")

```
The estimated corrosion growth rate, as shown in @fig-cgr, was estimated using the measurements from the inspection data. As shown in @fig-corrosion_depths the precision with which the corrosion anomalies have been sized varied between the inspections. However, in both cases, there is less uncertainty about the size of a measured extent of damage, than an imputed extent.

The imputed corrosion depth at anomaly 4 was jointly estimated with the corrosion growth rate in the `Stan` model. It is a probabilistic estimate consistent with the data that *is* available, i.e. the inspection measurements from the other anomalies and the below prior model. 

$$
d_{A 4, insp. 2} \sim LogNormal(\mu = 10, \sigma = 6)
$$

This is an example of how a prior can be identified for a value that is intended to be measured by using other available, relevant information. This method is known as missing data imputation @Reg&amp;OtherStories.

quarto-executable-code-5450563D

```r
#| echo: false
#| fig-height: 9
#| fig-width: 6
#| label: fig-corrosion_depths
#| fig-cap: "Probabilistic Models for Imputed and Measured Corrosion Damage"
ggplot(data = depth_df)+
  geom_density(mapping = aes(x = depth, y = after_stat(x = density), alpha = type), col = "black", fill = "gray")+
  facet_grid(anomaly_id ~ inspection)+
  scale_x_continuous(name = "Estimated corrosion depth, mm")+
  scale_y_continuous(name = "Likelihood")+
  ggthemes::theme_base(base_size = 12, base_family = "Atkinson Hyperlegible")+
  theme(plot.background = element_rect(color = NA), legend.title = element_blank(), legend.position = "top")

```

Quantifying the expected value of returning the location of anomaly 4 and completing this measurement, requires sampling from the imputed prior model which effectively describes what is expected to be measured.

Another important feature of this model is that there is some defined precision of the measurement activity. The data that will be obtained is imperfect. The impact of this on the calculation is that for each hypothesised measurement (sample from the prior model), the imperfect data is combined with the prior to produce a probabilistic posterior distribution of the extent of the damage at anomaly 4. The associated corrosion growth rate is also calculated, now using the updated inspection data, and the subsequent forecasting and decision analysis is completed.

This example is based on a published calculation @DiFrancesco2022, which also considers other imperfect features of inspection data, such as reliability. Imperfect data will always be less valuable than perfect data, but perfect data is never available in practice. Increasingly precise and reliable data will have a higher (or at least an equivalent) expected value to a decision-maker and value of information analysis can be used to identify when it is expected to be worth paying more for *better quality* data. 

quarto-executable-code-5450563D

```python
#| output: false
#| eval: false

depths_i1 = np.array(model_data["depth_i1"])
depths_i2 = np.array(model_data["depth_i2"])

prepost_df = pd.DataFrame()
for depth in np.sort(cgr_results["depth_true_i2[4]"]):
    
    model_data_iter = model_data; insp_data_iter = insp_data

    depths_i2[3] = depth    
    model_data_iter["depth_i2"] = depths_i2
    model_data_iter["ex_2"] = np.repeat(a = 0, repeats = len(depths_i2))

    insp_data_iter.depth = np.concatenate((depths_i1, depths_i2))
    insp_data_iter.depth[13] = depth

    prepost_df = pd.concat((prepost_df, 
                            pd.DataFrame(data = {"d_insp": depth, 
                                                 "cost": get_costs(insp_df = insp_data_iter, 
                                                                   results_df = corrosion_model(data = model_data_iter)).cost.sum()}, 
                                        index = [0])))

```

quarto-executable-code-5450563D

```python
#| echo: false

prepost_df = pd.read_csv("data_files/VoInsp.csv")
```

The expected value of (an imperfect) inspection at the site of corrosion anomaly 4, can then be calculated:

quarto-executable-code-5450563D

```python
VoInsp = prior_exp_cost - prepost_df.cost.mean()



```

:::


# Summary

Key concepts:

 - Due to the complexity of materials, geometries, system inter-dependencies, and the limitations in measurement technologies, there will inevitably be uncertainties associated with engineering calculations.
 - These uncertainties can be described using probability distributions, which combine and interact in probabilistic models. Giving these models starting points (priors) based on existing knowledge within engineering teams can greatly benefit these models, particularly when there is limited information in available data.
 - After defining, checking, fitting (and evaluating) these models, they can be used to help formally identify expected optimal risk management decisions, using computational tools, such as influence diagrams.
 - These methods explicitly link the engineering models and data analysis, to the underlying decision problem that they are intended to solve. This results in a transparent and replicable (auditable) workflow, and allows for some useful calculations to be performed, such as quantifying the expected value of further data collection.
 - The expected value of, for instance; installing a sensor, performing a measurement, or completing a calculation, can then be compared to the associated cost for the activity. When the expected value to an organisation exceeds the cost they are required to pay for the data, the investment can be justified.
 - The calculations provided in this document show examples that can broadly be categorised as data requirements for risk management of the built environment. However, the principles are generic, as demonstrated by the variety of methods that have been used to solve them using relatively small amounts of code in freely available software.
 - Moving towards principled, quantitative, replicable engineering decision support is expected to be an important step in integrating computational statistics in data-centric engineering.

 &lt;!-- - When data is abundant, the benefit of UQ, prior knowledge, and model structure may sometimes diminish, and greater performance may be obtained from *black-box* type models, such as neural networks. These models are still compatible with decision analysis, but quantification of the expected value of additional data collection requires a generative structure that describes what is expected to be measured, and where this prospective data fits in the context of solving the decision problem. --&gt;
 
Please feel free to contact [Domenic Di Francesco](ddifrancesc@turing.ac.uk), or in the [Github page]() if you have any queries or comments.

# Acknowledgements

list all contributors, reviewers, and funding

...
</code></pre>
</div></div></div></div></div>
</div> <!-- /content -->



</body></html>